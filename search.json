[{"title":"rust实现selenium","url":"/2025/07/21/R8BYJ4.html","content":"\nselenium是基于webdriver协议的自动化测试工具，当然也能用来做爬。\n\n<!-- more -->\n\n[selenium](https://github.com/SeleniumHQ/selenium)有很多语言版本，但是没有rust版本的，仓库里的是一个rust实现的浏览器和driver下载器。\n\n目前[crates.io](https://crates.io/search?q=selenium)上的三方实现很久没有更新了，而且缺乏功能，所以选择自己实现。\n\n## 协议\n\nselenium原理并不稀奇，主要是借助一个driver操作浏览器。selenium使用http和driver通信。所以实际上最核心的功能都在由浏览器厂商实现的driver里，说selenium只是个壳子也不为过。\n\n采用的协议是[webdriver](https://www.w3.org/TR/webdriver1/)\n\n## 流程\n\n略去driver下载相关，首先需要启动driver，开发过程都是基于firefox和geckodriver。\n\n```\ngeckodriver --host 127.0.0.1 --port 2983\n```\n\n不同的driver启动参数不同。\n\n我将启动driver流程集成到了代码里，但是由于rust的特性，容易产生孤儿进程，前后改了很多次，依旧不能保证没问题，只能说只要能正常退出程序，不要中途panic，基本就能避免。\n\n---\n\n之后是创建一个session。可以简单理解一个session就是一个单独的浏览器进程，这里有一些注意事项\n\n- session不能重复创建，一个driver同时只能有一个session，也就是没法操作多个浏览器实例，只能使用多个driver\n- 必须调用quit。只有调用了quit方法，session才会被销毁，否则除非重启dervier，不然不能再创建session\n- 每个session都是新环境，历史记录插件等即不继承也不遗留，除非设置profile\n- profile会被压缩后用base64传输，所以并非是driver或者浏览器所在设备的某个路径，而是selenium程序来读取压缩的\n\n\n## 执行\n\n除了selenium提供的元素操作方法外，最好用的还是执行js代码。\n\njs执行环境为当前网页，实际效果就和在控制台里执行一样。\n\n需要注意同步和异步，同步js直接return即可，异步方法则略有不同\n\n```rust\nlet v:String = driver.execute_async_script(r#\" let callback = arguments[arguments.length - 1]; setTimeout(()=> callback(100) ,1000);  \"#,&[]).unwrap();\n```\n\njs里可以通过`arguments`获取传入的方法，最后一个值是回调函数，异步方法结束时调用返回执行结果\n\n## 突破反爬\n\n有的网站防火墙会校验浏览器是否处于webdriver协议控制下，其原理就是此时浏览器会将`window.navigator.webdriver`设置为true。\n\n---\n\n目前有两种思路避开\n\n一是 使用chrome的debug方式连接一个已打开的窗口，而非新窗口，但是时不时会出现连不上的情况。\n\n二是 使用低版本(小于68)的firefox，通过设置pref `dom.webdriver.enabled=false`\n\n三是 `options.add_experimental_option('excludeSwitches', ['enable-automation'])`\n\n## 参考资料\n\n- [webdriver](https://www.w3.org/TR/webdriver1/)\n- [selenium](https://github.com/SeleniumHQ/selenium)\n- [selenium-rs](https://github.com/inkroom/selenium-rs)","tags":["selenium","webdriver"]},{"title":"mobi格式解析","url":"/2024/08/26/2V0D1S7.html","content":"\nmobi格式或者azw格式，是亚马逊的私有格式，由于kindle不支持epub，所以准备研究一下mobi\n\n<!-- more -->\n\n# 背景知识\n\nmobi原本是mobipacket，后来被亚马逊收购，就成了私有规范，目前网上没有完整的规范文档。亚马逊在mobi的基础上加上drm也就是版权信息就成了azw格式，后续又参考epub，加入更多功能，成了azw3格式，两种格式又叫kf6和kf8\n\n# 基础结构\n\nmobi是采用[PDB](https://wiki.mobileread.com/wiki/PDB)格式封装，这个封装的意思可以理解成数据保存方式，一般格式规范有两部分，一是包括什么数据，二是数据存储方式。例如epub、docx这些就采用zip格式作为封装格式\n\n## 文件头(PDBHeader)\n\n文件开头的78个字节(byte)，是文件的一些基础元数据，包括像是文件日期，文件类型等等。这里需要注意一些关键性字段\n\n### 日期\n\n在第36、40、44(offset,下同)索引的unit32字段，这三个字段都是时间相关字段，存储的都是秒时间戳，只是起始时间不一定是1970年。具体规则如下\n\n如果拿到时间戳数字，其最高位(bit，下同)是1，这就是个无符号unit32，代表时间从1904年开始，否则从1970年开始；在我得到的mobi格式样例来看，都是从1970年开始，1904可能是其他文件类型在使用。这里给出一个判断时间的样例代码\n\n```rust\nfn do_time_format(value: u32) -> String {\n    if value & 0x80000000 == 0x80000000 {\n        crate::common::do_time_display((value & 0x7fffffff) as u64, 1904)\n    } else {\n        crate::common::time_display(value as u64)\n    }\n}\n```\n\n顺便一提，在mobi格式中，有一些规则跟数据长度息息相关，如果规范里规定了是2个字节，那么一定不要使用更大的数据格式——比如int——来存储，也要小心语言可能存在的自动向上转型\n\n\n### magic\n\n魔法值，或者魔术值，一般用来区分文件格式，绝大多数文件格式都会在文件开头几个字节里放几个固定字节，比如java里的COFFIE，jpeg的IFEF。\n\nmobi的magic值相对较远，在第52和56索引，分为两个字段，一共八个字节，固定值为`BOOKMOBI`，虽然规范分成两个字段，实际使用时不用管这个。另外azw3和mobi使用相同的magic，所以还需要判断第34索引，mobi值为6，azw3为8，也就是KF8\n\n### 书本名\n\n从第0索引开始32个字节代表文件名，通常也是书本名，但是问题是32个字节不一定够存下书名，二是calibre生成的mobi这里也是ascii，如果是中文书，这里就是拼音字母了，所以这32个字节建议直接抛弃，后续字节中有可阅读的书本名称\n\n## record\n\n除了存储文件元数据的文件头外，剩下的字节被切割成一个个的record，每个record的长度不一定相同，具体有多少个record，文件头中也有描述；这里只介绍已知用得上的几种record\n\n# 书本信息\n\n## 头信息\n\n在第0个record中，分成了两部分，第0到16(左闭右开)索引是文件存储方式相关信息，比如压缩方式，文本长度，record数量，本文取名`MOBIDOCHeader`。具体用处后面再行描述。\n\n从第16索引开始，后面的就是`MOBIHeader`，存储了一些record信息，比如文字编码方式，书本名称位置，第一张图片位置等等，一共二百多个字节的头信息中，存在相当多的unknown字段，可能是为了扩展预留字段，也可能是因为私有格式，反解析的时候实在找不到用处。\n\n## 书本名\n\n在header的第84和88索引中记录了书本名的offset和length，注意这个offset是相对于record0的offset，不是从文件开头计算的。关于长度也有一番表述，如果只是读取的话，什么拼接0字节之类的，如果只是读取的话，不用管这些，直接定位到offset，然后读取length长度，按照编码方式解析即可\n\n## 元信息\n\n在record0的第128索引，指代是否存在`EXTH`record，这是书本的元数据信息，就是作者、出版社这些，这是个可能存在的record，当`exth_flags & 0x40 == 0x40`时才有exth\n\nexth本身是不定长度的，除了record本身的信息外，其余的字节数又被分成一个个的小record，每个record通过`type`区分含义，比如作者、出版社、出版日期这类。根据具体情况不同，同一`type`可能有多个值。注意这里又有一份书本名。此外需要注意的就是封面图\n\n## 封面\n\n封面有普通封面和缩略图封面，注意二者都是可选值，不是一定有的。具体的值是offset。\n\n注意这个offset不是字节位置，而是record索引，在我们解析文件头的时候，获取到有多少个record，以及他们的offset2，这个offset2就是相对于文件头的字节索引了。\n\n另外在record0中还有一个字段是第一张图片的offset，当然也是record索引。\n\n所以这里需要将两个offset相加（所有图片的操作都要加上这个第一张图片的offset），从而找到字节索引，然后直接读取相应长度(读取record offset时会有length)的字节，就是图片本身了。\n\n注意这里是不存在图片的元数据信息的，也就是目前并不知道图片的文件名，也不知道到底有多少图片，不像epub格式会把所有的文件都列出来，想要获取所有图片，还需要读取文本信息才行\n\n\n## 文本\n\n文本的解析最为复杂，首先是文本被拆分到一个个的record里，每个record长度最大为4096，这个数字在文件头(MOBIDOCHeader)中也有记录，然后每个record还有特殊压缩编码，还有尾padding\n\n\n一共有多少个record，在`MOBIDocHeader`中有记录，假设为 record_count，此时遍历[1, record_count]，注意，左右均为闭区间；\n\n当拿到每个record的字节后，需要去除尾部的padding字节，具体有几个字节由以下规则确定\n\n### tail padding\n\n\n有`MOBIHeader`中第240索引，长度4字节字段`flag`，flag虽然是4个字节，也就是unit32，但是实际使用是unit16，也就是只有**低16bit**有用\n\n\n从低十六位的最高位开始循环，如果该位(bit)为1，则进入后续流程，注意最后一位(bit)不参与循环，伪代码如下：\n```\nfor(j = 15;j>0;j--){\n    if (flag & ( 1 << j ) >=1 ){\n        // do some thing\n    }\n}\n```\n\n每次循环中，将record的最后四个字节拿出来，从倒数第四个字节开始，如果该字节`& 0b1000_0000 >= 1`，则重置计数，否则将低七位左移合并，伪代码如下\n```\nvalue=0\nfor(byte in bytes){\n    if byte & 0b1000_0000 {\n        value = 0 \n    }\n    value = (value << 7 ) | ( byte & 0b111_1111)\n}\n```\n\n最终得到的value代表尾部需要去掉的长度，record去掉尾部数据后再次进行循环\n\n\n结束循环后，如果 `flag & 1 == 1`，则还需要去除长度，伪代码如下：\n```\nlet length = (data[data.length - 1] & 0b11)+1\ndata = data.subarr(0, -length);\n```\n\n###  uncompress\n\n解压缩，这里根据`MOBIDOCHeader`中关于压缩信息的字段值不同，有三种方案，一是不压缩，也就不解压，二是`PalmDOC compression(LZ77)`，三是`HUFF/CDIC compression`，因为我手头只有第二种的样本，暂时就只解析[第二种](https://wiki.mobileread.com/wiki/LZ77)\n\n[LZ77](https://wiki.mobileread.com/wiki/LZ77)是为了减小体积。\n\n遍历record的每一个字节，\n- 如果 byte = 0, copy it\n- 如果 byte <=8，copy从下一个字节开始共计byte个字节，同时迭代往前byte个长度\n- 如果 byte <= 0b111_1111，copy it\n- 如果 byte <= 0b1011_1111，将当前字节和下一个字节连起来，右移三位后取低11位(distance)；取下一个字节低三位后加3(length)，循环length次，每次将当前结果的倒数第distance个字节再添加到结果里，注意这里结果的长度在变，所以每次循环添加的不一定是同一个值\n- 都不符合，添加一个32，再添加 `byte ^ 0b1000_0000`\n\n最终拿到的结果即每个record的值，再把每个record相连，按照指定编码解码，即可拿到文本信息\n\n### html\n\n解析之后的文本信息是一个相对标准html文档，只有一个head和body。\n\n### 章节分页\n\nbody中包含`<mbp:pagebreak/>`，代表一个章节的结束，其中第0个章节可能是目录导航，其他都是普通的html片段。\n\n将文本分节，每节包括文本，开始字节数(start)，结束字节数(end)，这里的字节数是相对于**文本**开头，不是文件开头\n\n分节的时候要注意，因为后续使用的都是字节数，而utf8一个字符使用的字节数是不固定的，所以不能在编解码后做分节，必须使用解压缩完之后的数据，这就成了一个基本的子串查找，可以上力扣刷题了\n\n----\n\nhead中会有特殊标签`guide#reference`指向toc目录，样例如下\n```xml\n<head>\n    <guide>\n        <reference type=\"toc\" title=\"Table of Contents\" filepos=0002387139 />\n    </guide>\n</head>\n```\n\n使用filepos在章节中查找，end值大于filepos的即为对应章节，就我手头的样本，导航会被放到最后一个章节里，这个章节的意思实际是给阅读器使用的，格式固定，样本里甚至还给了宽高都是0，避免被阅读器渲染出来被读者看到，开头第0个章节那个是书籍自定义的导航，用来给读者看的，样式规范多样化，阅读器无法识别，在epub格式中也有类似的设计。\n\n这里给一个样例：\n```xml\n<mbp:pagebreak/>\n<p height=\"1em\" width=\"0pt\" align=\"center\">\n    <font size=\"7\">\n        <b>Table of Contents</b>\n    </font>\n</p>\n<p height=\"1em\" width=\"-19pt\">\n    <a filepos=0000005452>第一卷</a>\n</p>\n<blockquote height=\"0pt\" width=\"0pt\">\n    <a filepos=0000005452>插图</a>\n</blockquote>\n<blockquote height=\"0pt\" width=\"0pt\">\n    <a filepos=0000007756>第一章</a>\n</blockquote>\n<blockquote height=\"0pt\" width=\"0pt\">\n    <a filepos=0000052866>第二章</a>\n</blockquote>\n<mbp:pagebreak/>\n```\n\n### 图片\n\n每一个img标签都会被赋予一个`recindex`属性，代表的是record从1开始的索引，同时务必加上第一张图片的offset。\n\n如果有字体等资源文件，也是相同的方案，只是读取到的值处理不一样，因为我手头没有这种样本，暂时不做研究\n\n## 目录\n\n前文提到，文本章节中有目录导航，此外，当`MOBIHeader`中的第244索引值不等于`0xffffffff`，mobi存在INDX类型record，这里的解析方式较为复杂，而且缺失了目录层级信息，不建议使用该处数据，所以暂时先不解析了。\n\n# 参考资料\n\n- [mobi](https://wiki.mobileread.com/wiki/MOBI)\n- [foliate-js](https://github.com/johnfactotum/foliate-js/blob/9ff893f3e73eadfcfd64db080ff486b8a55c9a81/mobi.js)\n- [iepub](https://github.com/inkroom/iepub)","tags":["rust","mobi","电子书","kindle"]},{"title":"手动计算时间戳转日期","url":"/2024/08/06/3DR7BNH.html","content":"\nrust标准库没有时间戳转日期的方法，为了区区一个功能引入三方库又觉得划不来，于是准备自己实现\n\n<!-- more -->\n\n以前看到过转换时间戳的方法，但是这回网上找了半天都没找到想要的代码，全是各种语言调标准库或者三方库的，找来找去只有[这个](https://zhuanlan.zhihu.com/p/329686937)，但是评论区又说有bug，我看过代码好像闰年部分有点问题\n\n## 思路\n\n首先时间戳定义是1970年1月1日到指定时间的秒数，正数往后，负数往前，这里不需要考虑负数，一般采用32位存储，所以最多只能存储到2038年，又叫千年虫问题\n\n时间戳计算的难度就在闰年，闰年导致每年的秒数不一致，从而不便于定位到年。顺便一提，除了闰年还有闰秒，每隔不确定的时间，将现在时间进行减一秒或者加一秒操作，闰秒也会导致一些大公司的系统出现bug，而且闰秒是国际协会根据地球运动情况确定的，不像闰年这样规律，所以不太好弄，不过时间戳里没有闰秒概念\n\n为了确定过去到底有多少秒，最简单的办法就是把1970年到2038年每一年的秒数都累加出来，看时间戳小于哪一年，这个时间戳就是上一年的，再减去过去经过的秒数，剩下的就是在今年的秒数，确定日期和时间就很简单了。我看jdk里似乎就是这样干的，代码里把每一年的都硬编码了\n\n## 实现\n\n```rust\n//\n// 判断是否是闰年\n//\n#[inline]\nfn is_leap(year: u64) -> bool {\n    return year % 4 == 0 && ((year % 100) != 0 || year % 400 == 0);\n}\n\nfn do_time_format(value: u64) -> String {\n    // 获取当前时间戳\n    let mut time = value;\n    let per_year_sec = 365 * 24 * 60 * 60; // 平年的秒数\n\n    // 平年的月份天数\n    let mut day_of_year: [u64; 12] = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\n\n    let mut all_sec = 0;\n    // 直接算到 2038年，把每一年的秒数加起来看哪年合适\n    for year in 1970..2038 {\n        let is_leap = is_leap(year);\n\n        let before_sec = all_sec;\n        all_sec += per_year_sec;\n        if is_leap {\n            all_sec += 86400;\n        }\n        // println!(\"all={all_sec} before_sec={before_sec} year={year}\");\n        // 具体是哪一年应该是 当 小于这一年的秒数\n        if time < all_sec {\n            // 减去到上一年年底的秒数 剩下的才是这一年内的秒数\n            time = value - before_sec;\n            // 找到了 计算日期\n            let sec = time % 60;\n            time /= 60;\n            let min = time % 60;\n            time /= 60;\n            let hour = time % 24;\n            time /= 24;\n\n            // 计算是哪天，因为每个月不一样多，所以需要修改\n            if is_leap {\n                day_of_year[1] += 1;\n            }\n            let mut month = 0;\n            for (index, ele) in day_of_year.iter().enumerate() {\n                if &time < ele {\n                    month = index + 1;\n                    time += 1; // 日期必须加一，否则 每年的 第 1 秒就成了第0天了\n                    break;\n                }\n                time -= ele;\n            }\n\n            return format!(\n                \"{:04}-{:02}-{:02}T{:02}:{:02}:{:02}Z\",\n                year, month, time, hour, min, sec\n            );\n        }\n    }\n\n    String::new()\n}\n```\n\n## 改进\n\n再思索下上面的程序，可以发现一个问题，那就是即使使用了64位存储，千年虫问题依然存在，因为只计算到了2038年\n\n那怎么去掉这个上限呢？\n\n因为闰年的存在，没法简单的直接确定年份，但是如果假设只有平年，那么年份就可以做个除法获得，这个粗略值只会比精确值更晚，比如粗略值可能是1988-01-01，因为中间有闰年，所以实际年份应该是1987，而且不会出现往前走两年的情况，因为这样需要中间有365个闰年，但是粗略值本身就是除以365的结果，这里我也不知道该怎样描述更清晰明了一点。\n\n\n总之现在有个年份的粗略值，以及剩余的在年内的秒数，只需要循环判断一下1970到粗略值有多少个闰年，再用时间戳减去按平年计算的秒数和多出来的闰年的秒数，不直接用剩余秒数去减主要是考虑两种情况\n\n一是中间没有闰年的情况，比如1971年；二是时间戳除以平年刚好能整除，剩余秒数就是0。\n\n## 实现\n\n```rust\nfn do_time_format2(value: u64) -> String {\n    // 先粗略定位到哪一年\n    // 以 365 来计算，年通常只会相比正确值更晚，剩下的秒数也就更多，并且有可能出现需要往前一年的情况\n\n    let per_year_sec = 365 * 24 * 60 * 60; // 平年的秒数\n\n    let mut year = value / per_year_sec;\n    // if year * per_year_sec == value {\n    //     // 刚好是个整数倍\n    //     year -= 1;\n    // }\n    // 剩下的秒数，如果这些秒数 不够填补闰年，比如粗略计算是 2024年，还有 86300秒，不足一天，那么中间有很多闰年，所以 年应该-1，只有-1，因为-2甚至更多 需要 last_sec > 365 * 86400，然而这是不可能的\n    let mut last_sec = value - (year) * per_year_sec;\n    year += 1970;\n\n    let mut leap_year_sec = 0;\n    // 计算中间有多少闰年，当前年是否是闰年不影响回退，只会影响后续具体月份计算\n    for y in 1970..year  {\n        if is_leap(y) {\n            // 出现了闰年\n            leap_year_sec += 86400;\n        }\n    }\n    if last_sec < leap_year_sec {\n        // 不够填补闰年，年份应该-1\n        year -= 1;\n        // 上一年是闰年，所以需要补一天\n        if is_leap(year) {\n            leap_year_sec -= 86400;\n        }\n    }\n    // 剩下的秒数\n    let mut time = value - leap_year_sec - (year - 1970) * per_year_sec;\n\n    // 平年的月份天数\n    let mut day_of_year: [u64; 12] = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\n\n    // 找到了 计算日期\n    let sec = time % 60;\n    time /= 60;\n    let min = time % 60;\n    time /= 60;\n    let hour = time % 24;\n    time /= 24;\n\n    // 计算是哪天，因为每个月不一样多，所以需要修改\n    if is_leap(year) {\n        day_of_year[1] += 1;\n    }\n    let mut month = 0;\n    for (index, ele) in day_of_year.iter().enumerate() {\n        if &time < ele {\n            month = index + 1;\n            time += 1; // 日期必须加一，否则 每年的 第 1 秒就成了第0天了\n            break;\n        }\n        time -= ele;\n    }\n\n    return format!(\n        \"{:04}-{:02}-{:02}T{:02}:{:02}:{:02}Z\",\n        year, month, time, hour, min, sec\n    );\n}\n```\n\n## 验证\n\n我用java直接生成2038为止每一天，随机时间的时间戳数据，共计两万多天。用了`assert_eq!`宏来做断言，然后编译总是出错，还没有错误原因，只有一个kill 9。最后把宏换成了方法调用就可以了，怀疑就是太多宏影响了编译，毕竟两万多个宏。\n\n\n","tags":["rust"],"categories":["算法"]},{"title":"SpringBoot自定义json参数解析注入","url":"/2024/05/14/K4Q2PZ.html","content":"\n自定义请求参数注入逻辑，允许将json解析到多个参数\n\n<!-- more -->\n\n## 背景\n\nSpringBoot中接收json参数一般使用`@RequestBody`注解，基本样式如下\n\n```java\npublic Result<String> batchAdd(@RequestBody List<Product> data) \n```\n\n但是这样有个问题，那就是 `@RequestBody` 只能出现一次，也就是所有json参数必须封装到一个bean里，大多数情况下这都不是什么问题，但是如果接口很多，每个接口参数都不同的话，就会有很多个类，外带我个人不怎么喜欢使用单个类来接收参数，我更习惯使用多个参数，这样接口需要的参数更加明确\n\n\n## 原理\n\nSpring中实现参数注入使用的是`org.springframework.web.method.support.HandlerMethodArgumentResolver`类，只需要实现该类即可\n\n## 实现\n\n最早我找了一篇博客，地址找不到了，总之内容是使用fastjson手动获取内容并转换类型，较为繁琐，而且对于容器类参数没有兼容，所以我参照 `org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodArgumentResolver#readWithMessageConverters`的逻辑重写了一份。\n\n另外我还兼容了 query 传参，参数不再仅限于http body里的json格式，k=v形式一样能获取\n\n代码如下\n\n```java\nimport cn.hutool.core.io.IoUtil;\nimport com.alibaba.fastjson.JSON;\nimport com.alibaba.fastjson.JSONObject;\nimport jakarta.servlet.http.HttpServletRequest;\nimport org.springframework.core.MethodParameter;\nimport org.springframework.core.convert.ConversionService;\nimport org.springframework.core.convert.TypeDescriptor;\nimport org.springframework.http.HttpHeaders;\nimport org.springframework.http.HttpInputMessage;\nimport org.springframework.http.MediaType;\nimport org.springframework.http.converter.GenericHttpMessageConverter;\nimport org.springframework.http.converter.HttpMessageConverter;\nimport org.springframework.http.server.ServletServerHttpRequest;\nimport org.springframework.stereotype.Component;\nimport org.springframework.util.Assert;\nimport org.springframework.util.StringUtils;\nimport org.springframework.validation.DataBinder;\nimport org.springframework.web.bind.support.WebDataBinderFactory;\nimport org.springframework.web.context.request.NativeWebRequest;\nimport org.springframework.web.method.support.HandlerMethodArgumentResolver;\nimport org.springframework.web.method.support.ModelAndViewContainer;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.lang.reflect.Type;\nimport java.nio.charset.StandardCharsets;\nimport java.util.List;\n\n/**\n * 参数解析器，支持将json body注入到不同参数中，同时支持普通的form、query传参\n *\n * @author 明明如月\n * @date 2018/08/27\n */\n@Component\npublic class MultiRequestBodyArgumentResolver implements HandlerMethodArgumentResolver {\n\n    private static final String JSONBODY_ATTRIBUTE = \"JSON_REQUEST_BODY\";\n    protected final List<HttpMessageConverter<?>> messageConverters;\n\n    public MultiRequestBodyArgumentResolver(List<HttpMessageConverter<?>> messageConverters) {\n        this.messageConverters = messageConverters;\n    }\n\n    /**\n     * 设置支持的方法参数类型\n     *\n     * @param parameter 方法参数\n     * @return 支持的类型\n     */\n    @Override\n    public boolean supportsParameter(MethodParameter parameter) {\n        // 支持带@MultiRequestBody注解的参数\n        return parameter.hasParameterAnnotation(MultiRequestBody.class);\n    }\n\n    private Type getHttpEntityType(MethodParameter parameter) {\n        return parameter.nestedIfOptional().getNestedGenericParameterType();\n    }\n\n    /**\n     * 驼峰转下划线\n     *\n     * @param input\n     * @return\n     */\n    private static String humpToUnderline(String input) {\n        if (input == null) return null; // garbage in, garbage out\n        int length = input.length();\n        StringBuilder result = new StringBuilder(length * 2);\n        int resultLength = 0;\n        boolean wasPrevTranslated = false;\n        for (int i = 0; i < length; i++) {\n            char c = input.charAt(i);\n            if (i > 0 || c != '_') // skip first starting underscore\n            {\n                if (Character.isUpperCase(c)) {\n                    if (!wasPrevTranslated && resultLength > 0 && result.charAt(resultLength - 1) != '_') {\n                        result.append('_');\n                        resultLength++;\n                    }\n                    c = Character.toLowerCase(c);\n                    wasPrevTranslated = true;\n                } else {\n                    wasPrevTranslated = false;\n                }\n                result.append(c);\n                resultLength++;\n            }\n        }\n        return resultLength > 0 ? result.toString() : input;\n    }\n\n    private String getParameterName(MethodParameter parameter, MultiRequestBody parameterAnnotation) {\n        //注解的value是JSON的key\n        String key = parameterAnnotation.value();\n        // 如果@MultiRequestBody注解没有设置value，则取参数名FrameworkServlet作为json解析的key\n        if (!StringUtils.hasText(key)) {\n            // 注解为设置value则用参数名当做json的key\n            key = parameter.getParameterName();\n            // 由于整体使用下划线法，所以参数名也要转换\n            key = humpToUnderline(key);\n        }\n        return key;\n    }\n\n    @SuppressWarnings({\"all\"})\n    public <T> Object doResolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception {\n\n        HttpServletRequest servletRequest = webRequest.getNativeRequest(HttpServletRequest.class);\n        Assert.state(servletRequest != null, \"No HttpServletRequest\");\n        ServletServerHttpRequest inputMessage = new ServletServerHttpRequest(servletRequest);\n        MediaType contentType = inputMessage.getHeaders().getContentType();\n\n        MultiRequestBody parameterAnnotation = parameter.getParameterAnnotation(MultiRequestBody.class);\n        String key = getParameterName(parameter, parameterAnnotation);\n\n        Object body = null;\n        if (contentType.toString().contains(\"application/x-www-form-urlencoded\") || contentType.toString().contains(\"multipart\")) {\n            body = getFromQuery(key, mavContainer, servletRequest, binderFactory, parameter, webRequest);\n        } else {\n            Type targetType = getHttpEntityType(parameter);\n            Class<T> targetClass = (targetType instanceof Class clazz ? clazz : null);\n            Class<?> contextClass = parameter.getContainingClass();\n\n            StringHttpInputMessage message = null;\n\n            String jsonBody = getRequestBody(webRequest);\n            String v = null;\n            if (jsonBody.startsWith(\"[\") && jsonBody.endsWith(\"]\")) {\n                // 此时为一个 array，因此不支持 key，只能整个传入\n                v = jsonBody;\n            } else if (\"\".equals(jsonBody)) {\n                v = null;\n            } else {\n                JSONObject jsonObject = JSON.parseObject(jsonBody);\n                if (jsonObject == null) {\n                    v = null;\n                } else\n                    // 注明了 key 的取特定json值，否则使用整个json字符串\n                    v = \"\".equals(key) ? jsonBody : jsonObject.get(key).toString();\n            }\n            if (v != null) {\n                message = new StringHttpInputMessage(inputMessage.getHeaders(), v);\n                body = convertValue(targetClass, targetType, contextClass, contentType, message);\n            }\n        }\n\n        if (body == null) {\n            if (parameterAnnotation.required())\n                throw new IllegalArgumentException(\"require \" + key);\n\n        }\n        return body;\n    }\n\n    @SuppressWarnings({\"all\"})\n    public <T> Object convertValue(Class<T> targetClass, Type targetType, Class<?> contextClass, MediaType contentType, StringHttpInputMessage msgToUse) throws IOException {\n        Object body = null;\n        for (HttpMessageConverter<?> converter : this.messageConverters) {\n            GenericHttpMessageConverter<?> genericConverter =\n                    (converter instanceof GenericHttpMessageConverter ghmc ? ghmc : null);\n            if (genericConverter != null ? genericConverter.canRead(targetType, contextClass, contentType) :\n                    (targetClass != null && converter.canRead(targetClass, contentType))) {\n                if (msgToUse.hasBody()) {\n                    body = (genericConverter != null ? genericConverter.read(targetType, contextClass, msgToUse) :\n                            ((HttpMessageConverter<T>) converter).read(targetClass, msgToUse));\n                }\n                break;\n            }\n        }\n        return body;\n    }\n\n\n    @Override\n    @SuppressWarnings({\"all\"})\n    public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception {\n        return doResolveArgument(parameter, mavContainer, webRequest, binderFactory);\n    }\n\n    @SuppressWarnings({\"all\"})\n    private static class StringHttpInputMessage implements HttpInputMessage {\n\n        private final HttpHeaders headers;\n        private final String json;\n\n        public StringHttpInputMessage(HttpHeaders headers, String json) {\n            this.headers = headers;\n            this.json = json;\n        }\n\n        public boolean hasBody() {\n            return this.json != null;\n        }\n\n        @Override\n        public InputStream getBody() throws IOException {\n            return json == null ? InputStream.nullInputStream() : new ByteArrayInputStream(json.getBytes(StandardCharsets.UTF_8));\n        }\n\n        @Override\n        public HttpHeaders getHeaders() {\n            return headers;\n        }\n    }\n\n    private <T> Object getFromQuery(String key,\n                                    ModelAndViewContainer mavContainer, HttpServletRequest servletRequest,\n                                    WebDataBinderFactory binderFactory, MethodParameter parameter, NativeWebRequest webRequest) throws Exception {\n\n        Object v = null;\n        if (mavContainer.containsAttribute(key)) {\n            v = mavContainer.getModel().get(key);\n        } else {\n            v = servletRequest.getParameter(key);\n        }\n        if (v == null) {\n            return null;\n        }\n        DataBinder binder = binderFactory.createBinder(webRequest, null, key);\n\n        ConversionService conversionService = binder.getConversionService();\n        if (conversionService != null) {\n            TypeDescriptor source = TypeDescriptor.valueOf(String.class);\n            TypeDescriptor target = new TypeDescriptor(parameter);\n            if (conversionService.canConvert(source, target)) {\n                return binder.convertIfNecessary(v, parameter.getParameterType(), parameter);\n            }\n        }\n        return null;\n    }\n\n\n    /**\n     * 获取请求体JSON字符串\n     */\n    private String getRequestBody(NativeWebRequest webRequest) throws IOException {\n        HttpServletRequest servletRequest = ((HttpServletRequest) webRequest.getNativeRequest());\n\n        // 有就直接获取\n        String jsonBody = (String) webRequest.getAttribute(JSONBODY_ATTRIBUTE, NativeWebRequest.SCOPE_REQUEST);\n        // 没有就从请求中读取\n        if (jsonBody == null) {\n            jsonBody = IoUtil.read(servletRequest.getReader());\n            webRequest.setAttribute(JSONBODY_ATTRIBUTE, jsonBody, NativeWebRequest.SCOPE_REQUEST);\n        }\n        return jsonBody;\n    }\n}\n```\n\n注解定义\n```java\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\n\n@Target(ElementType.PARAMETER)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface MultiRequestBody {\n    /**\n     * 是否必须出现的参数\n     */\n    boolean required() default true;\n\n    /**\n     * 参数名称，默认为参数名的下划线形式，如appId -> app_id\n     */\n    String value() default \"\";\n}\n```\n\n## 使用\n\n只需要对参数使用`@MultiRequestBody`注解，样例如下\n\n```java\npublic Result<PageVO<ProductVO>> list(@MultiRequestBody PageRequest request\n            , @MultiRequestBody(value = \"app_id\", required = false) Long appId\n    );\n```\n","tags":["java","Spring"],"categories":["后端","java","SpringBoot"]},{"title":"docker使用技巧","url":"/2023/12/13/3DJZB2C.html","content":"\n总结的一些docker使用技巧\n\n<!-- more -->\n\n\n## 目的\n\n一般docker常用于搭建各种网络服务，但是也可以用于编译、开发环境搭建、命令行工具等\n\n### 编译环境\n\n各种语言需要的编译环境不尽相同，甚至可能彼此冲突。\n\n以我用过的语言来说，\n\n- java没什么问题，环境简单，但是有少数库编译会出问题；\n- node版本多变，兼容性差，不少三方库可能还会依赖c库；\n- c不常用，但是其对环境依赖最强，甚至没有包管理功能，我都不知道怎么控制依赖的版本，要是不兼容怎么办；\n- rust和c近似，有包管理，但是依旧有不少库是c的包装\n- python几乎完全不懂，环境搭建不能保证百分百成功\n- dart和flutter环境依赖不强，但是flutter更新可能会有版本兼容和依赖适配问题\n\n基于上述的种种理由，利用docker实现一个彼此隔离，可重现的编译环境非常有用，[这里](https://gist.github.com/inkroom/210cdec856ae59281602407664c5087c)是我总结的一些库的编译脚本\n\n此外，对于c、rust、go、dart等支持静态编译的语言来说，可以使用docker做到更完善纯粹的环境，比如使用**scratch**镜像，剔除所有用不到的文件，只需要保留**glibc**和可执行文件，如果有涉及https的，再保留一份**ssl**证书文件，例如我自己写的[git-lfs-server](https://github.com/inkroom/git-lfs-server-c/blob/rust/Dockerfile)。如果是rust还能更加极端，直接使用musl编译，真正实现一个文件处处运行\n\n\n---\n\n类似dart和go不支持彻底的静态编译，需要保留glibc和其他可能使用到的依赖，这里给出一个精简方案\n\ndart可以参考[这个](https://github.com/inkroom/docker-util/blob/novel_down_dart/Dockerfile)，有哪些依赖可以通过**ldd**查看\n\n还有一种[方案](https://github.com/inkroom/git-lfs-server-c/commit/1217be116c4ec4cd0c7561991aeafe191265ea86#diff-dd2c0eb6ea5cfc6c4bd4eac30934e2d5746747af48fef6da689e85b752f39557)\n\n这种方案更为繁琐。首先在静态编译完成后，执行以下脚本获取依赖\n\n```shell\nexe=\"lfs\" # 构建产物名称\ndes=\"$(pwd)/lib\" # 依赖拷贝目录\necho $des\ndeplist=$(ldd $exe | awk '{if (match($3,\"/\")){ printf(\"%s \"),$3 } }')\ncp $deplist $des\n```\n\n然后再通过以下脚本运行程序\n\n```shell\ndirname=`dirname $0`\ntmp=\"${dirname#?}\"\nif [ \"${dirname%$tmp}\" != \"/\" ]; then\ndirname=$PWD/$dirname\nfi\nLD_LIBRARY_PATH=$dirname/lib\nexport LD_LIBRARY_PATH\necho $LD_LIBRARY_PATH\n$dirname/lfs \"$@\"\n```\n\n原理就是通过指定**LD_LIBRARY_PATH**修改查找依赖的位置\n\n\n---\n\n从编译完成的镜像中获取产物有两种方案\n\n- 方案一\n\n运行起来后执行cp命令，基本格式如下\n\n```shell\ndocker run -itd --rm --name temp image_name bash && docker cp temp:/out ./ && docker stop temp\n```\n\n其中**bash**可能需要根据镜像更换成其他shell，或者换成`tail -f /dev/null`，总之就是要让镜像处于一直运行的状态\n\n- 方案二\n\n将镜像输出为tar文件，然后解压，从中获取文件，样例如下\n\n```shell\ndocker save -o mini.tar $mini_image_id\ntar xvf mini.tar\ncat manifest.json\necho \"layer:$(sed 's/\",\"/\\n/g' manifest.json | sed 's/\"]}/\\n/g' | tac | sed -n \"2,2p\")\"\ntar xvf $(sed 's/\",\"/\\n/g' manifest.json | sed 's/\"]}/\\n/g' | tac | sed -n \"2,2p\")\ncp server ../bin/server-mini\n```\n\n这里是解压最后一层layer，具体需要哪一层可查看**manifest.json**\n\n没有`tac`命令可用`tail -r`代替\n\n\n不同版本的docker导出的tar目录结构略有不同,但是好在不影响manifest.json,基本格式如下\n\n```json\n[\n  {\n    \"Config\": \"9d4c89bd4fa6947ea1ec699a1cd675b36f944cb6f661427cc1c7f9ebbb833fba.json\",\n    \"RepoTags\": [\n      \"redis:alpine\"\n    ],\n    \"Layers\": [\n      \"b93731aff72308a4aba32de5ee9f50dc3a2e702627b6893691c7f3f099132aca/layer.tar\",\n      \"0da7b4adee891f8e97c3619f3a4ac942076cb8ac84cd952c5b3427686bccc64f/layer.tar\",\n      \"86546f53d2382092a06e332014d30de2cb91ceb64e56a00a6602c944577bae17/layer.tar\",\n      \"c078df15cf9dce7fe6ffaa0e715fcf2f9eb0875e88e289330d73448ae8667937/layer.tar\",\n      \"f1b37bdd71e374c35fdb82c0d4a4703d07eb21260a078eecd7a003fd5b9b2da5/layer.tar\",\n      \"692214158801f0e9360e0addf367701d03263ac6a4f49d614a4000ce6595c3e5/layer.tar\",\n      \"87ad4eaa16e78a00b3baf73559ff63c31639d9bba4dbab2ce5b1cb862d179c14/layer.tar\"\n    ]\n  }\n]\n```\n\n\n这里的命令过于繁琐,建议使用[jq](https://jqlang.github.io/jq/manual/)代替,例如以下样例\n\n```shell\ntar xvf $(jq --raw-output '.[0].Layers[1]' manifest.json)\n```\n\n\n### 开发环境\n\n使用docker搭建开发环境有一定局限性，只适用于网络应用或者命令行工具，对于依赖硬件或者GUI的目前无法使用\n\n建议是搭配vscode的远程功能使用，如果环境部署到远程服务器，使用ssh通信，如果是本机的，可以不要ssh，同时镜像也可以使用alpine，体积更小，当然开发环境一般不差这点\n\n远程的镜像之前常用的都是**ubuntu:20.04**，但是最近有几次用这个镜像出了些奇奇怪怪的状况，所以换成**debian:12.2**了，注意这个镜像的软件源位置不一样，参考上面给出的网址\n\n还有一种方案是使用[webide](https://hub.docker.com/r/linuxserver/code-server)，直接在浏览器上使用，但是要注意可能有性能问题\n\n[这里](https://gist.github.com/inkroom/501548078a930c6f3bd98ea257409648)是我自用的开发环境脚本\n\n### 命令行工具\n\n这里一般是用别人开发的软件居多了，因为别人的软件可能用各种语言开发，总不能什么环境都装吧，只能上docker了\n\n比如我自己用的就有[epub](https://github.com/inkroom/docker-util/blob/novel_down_python/Dockerfile)，[certbot](https://eff-certbot.readthedocs.io/en/latest/install.html#running-with-docker)\n\n缺点就是命令会变得很繁琐，而且由于文件读写映射兼容，可能还需要修改源代码\n\n如果是clone源代码的，在dockerfile里最好指定tag或者commit，避免二次构建因为版本更新而失败\n\n\n## 建议\n\n### 基础镜像\n\nubuntu:20.04起步，22.04包管理器好像换了，不是很建议使用。如果有问题，就换成debian，debian还有基于日期的tag，更容易维持版本\n\n工具类建议使用**alpine**，如果可以还能使用**busybox**，甚至**scratch**，都能有效减小体积，但是可能会出各种运行问题，比如有些软件在scratch下不能响应Ctrl+C，需要在程序里自己监听信号处理\n\n### shell\n\n开发环境直接装[oh-my-zsh](https://ohmyz.sh/)，alpine只有**sh**，非常难用\n\n同时记得加入以下命令以便支持中文\n\n```Dockerfile\nENV LANG C.UTF-8\n```\n\n### 时区\n\n基本上所有官方镜像都有时区问题，需要在Dockerfile中处理\n\n例如\n\n```Dockerfile\nRUN export DEBIAN_FRONTEND=noninteractive \\\n    && apt-get update \\\n    && apt-get install -y tzdata \\\n    && ln -fs /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\\n    && dpkg-reconfigure --frontend noninteractive tzdata\n```\n\n\n```Dockerfile\nENV TZ=Asia/Shanghai\n```\n\n\n具体哪个有效，自己尝试吧\n\n\n### 减小体积\n\n\n除了换镜像外，还能通过多阶段构建，只保留构建产物，配合静态编译效果更好\n\n\n将RUN命令进行合并，减少镜像层级，下载的文件记得删除，例如以下例子\n\n```Dockerfile\nRUN wget -q https://mirrors.huaweicloud.com/openjdk/${JAVA_VERSION}/openjdk-${JAVA_VERSION}_linux-x64_bin.tar.gz  && mkdir -p ${JDK_HOME} && tar -zxvf openjdk-${JAVA_VERSION}_linux-x64_bin.tar.gz -C ${JDK_HOME} && rm -rf openjdk-${JAVA_VERSION}_linux-x64_bin.tar.gz\n```\n\n### 加速构建\n\n在测试阶段，将RUN命令尽可能分开，以便调整后续命令时能够用上之前的缓存，不用从头开始\n\n不同语言有不同的包管理方式，对于减少依赖下载次数，给出几个例子\n\n- 单文件类\n\n依赖存储于一个文件，例如node，简单的rust和java项目\n\nnode最为简单，可以直接 `RUN npm i axios`，或者提前COPY package.json，例如：\n\n```Dockerfile\nWORKDIR /app\nCOPY package.json /app/\nRUN npm i\nCOPY . /app/\n# 其他命令\n```\n\n- 多文件类\n\nrust和java的多模块项目，依赖文件可能位于不同的文件夹中，如果依旧使用上述方案的话，命令会较为繁琐，比如使用多个**COPY**命令，或者通过shell脚本修改目录结构等\n\n这里最简单的方案还是使用 **buildkit** 的[RUN挂载功能](https://docs.docker.com/engine/reference/builder/#run---mount)\n\n例如：`RUN --mount=type=cache,mode=0777,target=/root/.gradle/,id=gradle ./gradlew :spring-boot-project:spring-boot:build -x test`\n\n这里要注意缓存的目录，尽可能把后续命令中涉及的目录都归到一个父目录下\n\n另外在**mac**上遇到了必须指定**mode**参数才生效的情况\n\n\n## 资源\n\n- [常用软件源](https://gist.github.com/inkroom/f17f4ae7a2c61cc1e84f30d0a3977b1d)\n- [docker hub代理](https://github.com/DaoCloud/public-image-mirror)\n- [开发环境](https://gist.github.com/inkroom/501548078a930c6f3bd98ea257409648)\n\n","tags":["docker"]},{"title":"netty并发优化思路","url":"/2023/12/12/1F6HAFB.html","content":"\n有个基于netty的项目对并发要求较高，这里记录一下调优的过程\n\n<!-- more -->\n\n\n1. 首先放弃常用的tomcat之类的容器方案，因为其性能不够，也不方便深入优化\n\n2. Spring可以继续使用，仅使用IOC部分，不使用其web模块\n\n3. 业务逻辑本身比较简单，主要工作是写日志，第三方服务使用云厂商提供，响应速度极快，所以一次请求可以在1毫秒内完成\n\n4. 借助阿里云使用5000并发压测两分钟，刚开始请求响应在几十毫秒，后来拉到两秒，最终平均响应时间高达两秒，RTS 4000+\n\n5. Linux上使用netty的epoll，其余继续使用nio，效果不明显\n\n6. 修改linux连接数量 vim /etc/sysctl.conf，修改`net.core.somaxconn`和`net.ipv4.tcp_max_syn_backlog`，然后`sysctl -p`\n\n6. 通过多种方式排查，可以认为是线程切换影响较大，可通过`netstat 1`查看线程切换，正常在两三千左右，压测的时候直接五六万\n\n7. 使用管道减少redis交互，效果不明显\n\n8. 将redis读写改为异步，效果明显，响应时间可在一秒内，测试10000并发，RTS也在10000+\n\n9. 进一步减小线程切换，将业务handler从原本的单独Group改为直接使用io线程池\n\n10. 将io线程数量限制为核心数+1，可通过top看到所有核心都在运转，只是使用率都不算高，整体使用率也才70%左右，所以核心数比单核性能更重要\n\n11. 通过[arthas](https://arthas.gitee.io/)查看业务耗时情况，业务耗时一次不超过0.3毫秒，此时RTS依然是10000+，计算最大RTS (1000 / 0.3) * 8 = 26666，看似还有大量空间可优化，但是考虑到GC、上下文切换、其他程序竞争CPU，不好说还有多大优化空间\n\n12. 可通过[https://gceasy.io/](https://gceasy.io/)解析GC日志，jdk8可配置`-XX:-UseAdaptiveSizePolicy -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:+PrintHeapAtGC -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -Xloggc:/data/weblogs/ard-user-gc-%t.log -XX:+HeapDumpOnOutOfMemoryError` 输出GC日志\n\n\n","tags":["java","netty","并发"],"categories":["后端"]},{"title":"spring-boot启动慢","url":"/2023/12/11/1SSP84N.html","content":"\n一个简单应用，使用了springBoot框架，发现启动就需要五六秒\n\n<!-- more -->\n\n## 可能性\n\n一般情况下，启动慢是注入了太多bean，或者和网络服务建立连接慢，可以通过懒加载之类的方式优化\n\n但是我这次不一样，是由于框架本身导致的启动慢。怎么判断的呢，打开org.springframework的trace日志，发现输出的第一条日志和第二条之间差距在五六秒左右\n\n\n## 准备\n\n由于涉及底层框架，所以最好下载一份源码，修改代码做好日志打点，一点点排查。耗时问题不太适合使用debug。\n\n这里附上一份用于编译Spring-Boot的Dockerfile，最好启用buildkit使用缓存\n\n```Dockerfile\n# syntax=docker/dockerfile:1\n#FROM ubuntu:20.04\nFROM debian:12.2\n#FROM debian:stable-20231120\n#RUN echo $' \\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian-security bookworm-security main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security bookworm-security main contrib non-free non-free-firmware\\n\\' >> /etc/apt/sources.list\n\n#RUN sed -i \"s|http://deb.debian.org/debian|http://mirror.sjtu.edu.cn/debian|g\" /etc/apt/sources.list\nRUN sed -i 's/deb.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list.d/debian.sources\n\nRUN export DEBIAN_FRONTEND=noninteractive  && apt update -y && apt upgrade -y && apt install -y \\\n# autoconf \\\n# automake \\\n git \\\n# gcc \\\n# g++ \\\n# libtool \\\n# lksctp-tools \\\n# libssl-dev \\\n# lsb-core \\\n# make \\\n tar \\\n unzip \\\n wget \\\n zip\nRUN wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/aarch64/linux/OpenJDK8U-jdk_aarch64_linux_hotspot_8u392b08.tar.gz && tar zvxf OpenJDK8U-jdk_aarch64_linux_hotspot_8u392b08.tar.gz\nARG JDK_HOME=/jdk8u392-b08\nENV JAVA_HOME ${JDK_HOME}\nENV JRE_HOME $JAVA_HOME/jre\nENV CLASS_PATH=.:$JAVA_HOME/lib:$JRE_HOME/lib\nENV PATH ${PATH}:${JAVA_HOME}/bin:${JAVA_HOME}/jre/bin\nWORKDIR /app\n#RUN apt install -y clang && git clone https://github.com/spring-projects/spring-boot -b v2.7.17 /app\nCOPY . /app\n\n#RUN --mount=type=cache,mode=0777,target=/root/.gradle/,id=gradle ./gradlew build -x test\nRUN --mount=type=cache,mode=0777,target=/root/.gradle/,id=gradle ./gradlew :spring-boot-project:spring-boot:build -x test\n#RUN --mount=type=cache,mode=0777,target=/project/maven/ ls /project/maven && mvn clean package -DskipTests=true -Dcheckstyle.skip=true -Dmaven.test.skip=true -T 4 && ls /project/maven\n\n```\n\n编译通过后，拷贝`spring-boot-project/spring-boot/build/libs/spring-boot-2.7.17.jar`到项目引入即可\n\n### 打点\n\n\n最开始使用 spring的logger成员变量日志打点，但是debug后发现有些日志不会输出，很奇怪，也没功夫去研究，就索性自己写个log方法\n\n```java\npublic static void info(String m) {\n    SimpleDateFormat f = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\");\n    System.out.println(f.format(new Date()) + \" \" + m);\n}\n```\n\n再次编译后遇到代码格式校验不通过问题，几番尝试后，解决办法如下\n\n修改`spring-boot-project/spring-boot/build.gradle`\n\n原内容如下\n\n```gradle\ntasks.named(\"checkFormatMain\") {\n//\tdef generatedSources = fileTree(\"build/generated-sources/main\")\n//\t// Exclude source generated from the templates as expand(properties) changes line endings on Windows\n//\texclude { candidate -> generatedSources.contains(candidate.file) }\n//\t// Add the templates to check that the input is correctly formatted\n//\tsource(fileTree(\"src/main/javaTemplates\"))\n}\n```\n\n修改后如下\n```gradle\ntasks.named(\"checkFormatMain\") {\n//\tdef generatedSources = fileTree(\"build/generated-sources/main\")\n//\t// Exclude source generated from the templates as expand(properties) changes line endings on Windows\n//\texclude { candidate -> generatedSources.contains(candidate.file) }\n//\t// Add the templates to check that the input is correctly formatted\n//\tsource(fileTree(\"src/main/javaTemplates\"))\n\n\tenabled = false\n}\ntasks.named(\"checkstyleMain\") {\n\tenabled = false\n}\n```\n\n\n原理就是关闭两个和格式校验相关的task\n\n## 定位\n\n一通操作之后，将耗时操作定位到 `org/springframework/boot/SpringApplicationRunListeners` 的第**66**行的lamda方法内\n\n```java\nvoid environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) {\n    doWithListeners(\"spring.boot.application.environment-prepared\",\n            (listener) -> listener.environmentPrepared(bootstrapContext, environment)/* 就这一行代码 */ );\n}\n```\n\n虽然定位到耗时代码，但是这段代码的执行顺序还是挺奇怪的\n\n以下代码位于 `org/springframework/boot/SpringApplication` 第293行\n\n```java\n\tpublic ConfigurableApplicationContext run(String... args) {\n/*1*/\tlong startTime = System.nanoTime();\n    \tDefaultBootstrapContext bootstrapContext = createBootstrapContext();\n    \tConfigurableApplicationContext context = null;\n/*2*/\tconfigureHeadlessProperty();\n/*3*/\tSpringApplicationRunListeners listeners = getRunListeners(args);\n/*4*/\tlisteners.starting(bootstrapContext, this.mainApplicationClass);\n\t\ttry {\n\t\t\tApplicationArguments applicationArguments = new DefaultApplicationArguments(args);\n/*5*/\t\tConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments);// 耗时操作就在这里\n/*6*/\t\tconfigureIgnoreBeanInfo(environment);\n/*7*/\t\tBanner printedBanner = printBanner(environment);\n\t\t\tcontext = createApplicationContext();\n/*8*/\t\tcontext.setApplicationStartup(this.applicationStartup);\n\t\t\tprepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner);\n\t\t\trefreshContext(context);\n\t\t\tafterRefresh(context, applicationArguments);\n\t\t\tDuration timeTakenToStartup = Duration.ofNanos(System.nanoTime() - startTime);\n\t\t\tif (this.logStartupInfo) {\n\t\t\t\tnew StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), timeTakenToStartup);\n\t\t\t}\n\t\t\tlisteners.started(context, timeTakenToStartup);\n\t\t\tcallRunners(context, applicationArguments);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\thandleRunFailure(context, ex, listeners);\n\t\t\tthrow new IllegalStateException(ex);\n\t\t}\n\t\ttry {\n\t\t\tDuration timeTakenToReady = Duration.ofNanos(System.nanoTime() - startTime);\n\t\t\tlisteners.ready(context, timeTakenToReady);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\thandleRunFailure(context, ex, null);\n\t\t\tthrow new IllegalStateException(ex);\n\t\t}\n\t\treturn context;\n\t}\n```\n\n\n我对关键代码标注了行号，其执行顺序为：1 -> 2 -> 3 -> 4 -> 5 -> 1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 6 -> 7 -> 8 -> 启动完成\n\n由于执行顺序过于绕，可能有遗漏，总体逻辑就是 **5** 会被执行两次，而且是递归式的两次，不是并行的两次，这都是因为spring使用的listener机制，弄得人头大，然后耗时的是第二次也就是被递归调用的那一次\n\n所以接下来的思路就是理清listener的逻辑，是否前后两次执行的代码不一样\n\n## listener\n\n首先这套机制是 spring 提供的，具体到我的项目是 **spring-context** 里的 `org.springframework.context.event.SimpleApplicationEventMulticaster#multicastEvent:137`，不同的项目配置可能会有不同的listener实现，所以这里再下载一份spring源码，看看具体是哪个listener在耗时\n\n\n```Dockerfile\n# syntax=docker/dockerfile:1\n#FROM ubuntu:20.04\nFROM debian:12.2\n#FROM debian:stable-20231120\n#RUN echo $' \\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm main contrib non-free non-free-firmware\\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware\\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware\\n\\\n#deb https://mirrors.tuna.tsinghua.edu.cn/debian-security bookworm-security main contrib non-free non-free-firmware\\n\\\n#deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security bookworm-security main contrib non-free non-free-firmware\\n\\' >> /etc/apt/sources.list\n\n#RUN sed -i \"s|http://deb.debian.org/debian|http://mirror.sjtu.edu.cn/debian|g\" /etc/apt/sources.list\nRUN sed -i 's/deb.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list.d/debian.sources\n\nRUN export DEBIAN_FRONTEND=noninteractive  && apt update -y && apt upgrade -y && apt install -y \\\n# autoconf \\\n# automake \\\n git \\\n# gcc \\\n# g++ \\\n# libtool \\\n# lksctp-tools \\\n# libssl-dev \\\n# lsb-core \\\n# make \\\n tar \\\n unzip \\\n wget \\\n zip\nRUN wget https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/aarch64/linux/OpenJDK8U-jdk_aarch64_linux_hotspot_8u392b08.tar.gz && tar zvxf OpenJDK8U-jdk_aarch64_linux_hotspot_8u392b08.tar.gz\nARG JDK_HOME=/jdk8u392-b08\nENV JAVA_HOME ${JDK_HOME}\nENV JRE_HOME $JAVA_HOME/jre\nENV CLASS_PATH=.:$JAVA_HOME/lib:$JRE_HOME/lib\nENV PATH ${PATH}:${JAVA_HOME}/bin:${JAVA_HOME}/jre/bin\nWORKDIR /app\nRUN git clone https://github.com/spring-projects/spring-framework -b v5.3.30 /app\n#COPY . /app\n\nRUN --mount=type=cache,mode=0777,target=/root/.gradle/,id=gradle ./gradlew :spring-context:build -x test\n```\n\n\n输出文件位于 `spring-context/build/libs/spring-context-5.3.30.jar`\n\n\n修改代码后 同样出现和之前类似的错误\n\n```\nExecution failed for task ':spring-context:checkstyleMain'\n```\n\n解决方法一样，关闭`checkstyleMain`，这次只有这一个task\n\n\n打点后输出的多个listener执行时间如下\n\n```\n2023-12-12 09:48:11.448 listener org.springframework.cloud.bootstrap.BootstrapApplicationListener@14bee915 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.448 listener finish org.springframework.cloud.bootstrap.BootstrapApplicationListener@14bee915 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.448 listener org.springframework.cloud.bootstrap.LoggingSystemShutdownListener@1115ec15 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.448 listener finish org.springframework.cloud.bootstrap.LoggingSystemShutdownListener@1115ec15 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.448 listener org.springframework.boot.env.EnvironmentPostProcessorApplicationListener@82ea68c org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.567 listener finish org.springframework.boot.env.EnvironmentPostProcessorApplicationListener@82ea68c org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.567 listener org.springframework.boot.context.config.AnsiOutputApplicationListener@59e505b2 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.569 listener finish org.springframework.boot.context.config.AnsiOutputApplicationListener@59e505b2 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:11.569 listener org.springframework.boot.context.logging.LoggingApplicationListener@3af0a9da org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.620 listener finish org.springframework.boot.context.logging.LoggingApplicationListener@3af0a9da org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.621 listener org.springframework.boot.autoconfigure.BackgroundPreinitializer@43b9fd5 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.621 listener finish org.springframework.boot.autoconfigure.BackgroundPreinitializer@43b9fd5 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.621 listener org.springframework.boot.context.config.DelegatingApplicationListener@8e50104 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.621 listener finish org.springframework.boot.context.config.DelegatingApplicationListener@8e50104 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.622 listener org.springframework.boot.context.FileEncodingApplicationListener@74a6f9c1 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n2023-12-12 09:48:16.622 listener finish org.springframework.boot.context.FileEncodingApplicationListener@74a6f9c1 org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent[source=org.springframework.boot.SpringApplication@54eb2b70]\n```\n\n没想到拖后腿的居然是`LoggingApplicationListener`，这个类是boot提供的，兜兜转转又回来了，来看看他干了什么\n\n\n根据事件类型，定位到119行\n\n```java\n    private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) {\n        SpringApplication springApplication = event.getSpringApplication();\n        if (this.loggingSystem == null) {\n            this.loggingSystem = LoggingSystem.get(springApplication.getClassLoader());\n        }\n\n        this.initialize(event.getEnvironment(), springApplication.getClassLoader());\n    }\n```\n\n继续对方法打点\n\n\n最终定位到了`org.springframework.boot.system.ApplicationPid`第72行 `String jvmName = ManagementFactory.getRuntimeMXBean().getName();`，就慢在这个 `getName()` 上，而且只有第一次很慢。另外这行代码下面有过于耗时的一个warn日志，但是现在是在logging初始化阶段，所以这条日志没有输出，让我废了这么大功夫来定位\n\n\n简单测试一下，果真是这里，第一次执行能有四五秒\n\n```java\npublic static void main(String[] args) {\n    long s = System.currentTimeMillis();\n    RuntimeMXBean runtimeMXBean = ManagementFactory.getRuntimeMXBean();\n    System.out.println(runtimeMXBean.getName());\n\n    System.out.println((System.currentTimeMillis() - s));\n    System.out.println(runtimeMXBean.getName());\n    System.out.println((System.currentTimeMillis() - s));\n}\n```\n\n\n## 解决\n\n首先我使用的是mac mini的m2版本，所以解决方案也是针对mac系统，其他系统方法可能不通用\n\n\n首先在网上找了个方法，简化为命令行如下\n\n```shell\nHOSTNAME=$(hostname) sudo echo \"127.0.0.1  $HOSTNAME\" >> /etc/hosts\n```\n\n结果未生效\n\n继续往下深入，可定位到`InetAddress.getLocalHost()`，这是jdk的方法，没法打点了，再用这行代码为关键字检索\n\n发现了[这篇文章](https://zhuanlan.zhihu.com/p/570660615)\n\n其 hosts 文件写法和我的不一样\n\n```\n127.0.0.1   localhost Mac-mini.local\n```\n\n修改一下再测试，成功\n\n---\n\n简单测试了一下，只有文章中的写法才有效，只要单独一行都不行\n\n\n使用上述测试代码打一个可执行包，放到docker里测试一下\n\ndocker run -it --rm -v ./exec.jar:/s.jar eclipse-temurin:8-jre-ubi9-minimal java -jar /s.jar\n\n耗时正常\n\n\n","tags":["java"],"categories":["后端","java"]},{"title":"java枚举的应用","url":"/2023/08/19/19Q3283.html","content":"\n巧用枚举可以简化不少操作\n\n\n<!-- more -->\n\n\njava中的枚举我认为有以下几种用途\n\n## 限定范围\n\n这是枚举最基础的应用，作为参数或者响应可以限制取值范围，过于简单不加赘述\n\n## 存储常量\n\njava中的枚举实际上就是类的简化，所以大多数类的语法都能应用于枚举，比如成员变量和构造方法\n\n```java\n\npublic enum Demo {\n\n    FIRST(1,\"ok\"),\n\n    SECOND(2,\"fail\"),\n\n    ;\n    private int code;\n    private String msg; \n\n    private Demo(int code,String msg){\n        this.code = code;\n        this.msg = msg;\n    }\n\n}\n\n\n```\n\n和一般的常量类比起来，优点是可以将多种常量分组存放，比如http中常见的响应码由code和msg组成，各大框架一般都用枚举来存放\n\n注意，由于枚举都只有一个实例，所以不能用来存储变量。题外话，rust的枚举可以存放变量，这一点还是很好的\n\n## 实现设计模式\n\n使用枚举可以轻松实现部分设计模式\n\n### 单例模式\n\n用普通类实现的单例模式有可能会被反序列化破坏(话说什么情况下才会去反序列化单例类啊)，而使用枚举可以避免这一点\n\n\n### 策略模式\n\n策略模式是为了取代大量的if else，枚举也可以简单实现这一点\n\n因为枚举是类，所以里面也可以有方法，例如这样写\n\n\n```java\n\npublic enum Demo {\n\n    FIRST(1,\"ok\"){\n\n        public void process(){\n            // do something \n        }\n    },\n\n    SECOND(2,\"fail\"){\n\n        public void process(){\n            // do something\n        }\n\n    },\n\n    ;\n    private int code;\n    private String msg; \n\n    private Demo(int code,String msg){\n        this.code = code;\n        this.msg = msg;\n    }\n\n    public void process(){\n\n    }\n\n}\n\n\n```\n\n---\n\n常规的策略模式一般是将不同逻辑拆分到不同子类，再通过某种方式，比如工厂类来获取某个具体实现；使用枚举实现就只需要传一个枚举值就可以了；\n\n相比起策略模式动则四五个类，枚举只需要在一个文件——也只能在一个文件——内写完所有逻辑;\n\n不过缺点也很明显，枚举都是单实例，所以所有依赖都需要在方法参数上写出来，如果不同的实现需要不同的依赖，那参数表会很长，而且修改起来也比较繁琐\n\n### 责任链模式\n\n策略模式取代if else，责任链也可以说是取代循环类\n\n用枚举实现和上面的代码几乎一模一样，只是在调用的时候写成这样\n\n```java\n\nfor(Demo d: Demo.values()){\n    d.process();// 也可以自行实现责任链中断\n}\n\n```\n\n---\n\n\n相比责任链模式，可以省去注册等流程，而且顺序也可以轻松调整，缺点就是调用上稍微麻烦一些","tags":["java","设计模式"],"categories":["后端","java"]},{"title":"Github Action并行构建多架构docker","url":"/2023/07/24/3GFZG3W.html","content":"\n利用docker作为rust的开发环境，可以便捷升级，引入依赖，避免对本地环境的污染。为了便捷，使用了github action来构建docker镜像，实现了多架构和快速访问国外网络\n\n<!-- more -->\n\n## 问题\n\n在原本的构建逻辑中，使用了[build-push-action](https://github.com/docker/build-push-action/)来实现多架构构建，但是因为其原理是使用QUME来模拟arm进行串行构建，arm构建非常慢，在我构建四个架构的情况下运行时间超出了action的六小时限制\n\n\n因此需要想办法实现并行构建\n\n## 方案一\n\n\naction提供了**matrix**，可以通过提供不同的变量实现并行\n\n[简单配置一下](https://github.com/inkroomtemp/util/commit/31c06616160e93bfba2de0bd375fc68328e32814)\n\n```yml\n  dev:\n    runs-on: ubuntu-20.04\n    permissions: write-all\n    needs: [version]\n    if: needs.version.outputs.u == 'true'\n    strategy:\n      matrix:\n        platform: [linux/386, linux/amd64, linux/arm/v7, linux/arm64]\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n      - name: Checkout Runtime\n        run: |\n          git clone https://gist.github.com/inkroom/501548078a930c6f3bd98ea257409648 runtime\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      - name: Log in to the Container registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      - name: Log in to the Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKER_HUB_USERNAME }}\n          password: ${{ secrets.DOCKER_HUB_PASSWORD }}\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          images: |\n            ghcr.io/${{ github.repository_owner }}/rust\n            ${{ secrets.DOCKER_HUB_USERNAME }}/rust\n          tags: |\n            type=raw,value=${{ needs.version.outputs.ve }}\n          labels: |\n            org.opencontainers.image.description=rust开发环境-${{ needs.version.outputs.ve }}\n            org.opencontainers.image.title=rust-${{ needs.version.outputs.ve }}\n      - name: Build Docker image\n        uses: docker/build-push-action@v4\n        with:\n          context: runtime\n          file: runtime/Dockerfile.rust\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: ${{ matrix.platform }}\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          build-args: |\n            RUST_VERSION=${{ needs.version.outputs.ve }}\n\n```\n\n---\n\n结果就成了每构建成功一个架构，docker hub里面对应tag就会被替换成新镜像，之前push的就会丢失\n\n## 方案二\n\n之前的方案之所以会这样，是因为分开构建的镜像不被认为属于同一个tag\n\n所以尝试使用manifast实现镜像合并\n\n将不同架构push到不同的tag，然后使用命令实现合并\n\n\n[新增](https://github.com/inkroomtemp/util/commit/6192641a1fcf32a5e9d5add85d273062d4718a40)一个**combine**任务\n\n```yml\n  combine:\n    runs-on: ubuntu-20.04\n    permissions: write-all\n    needs: [version, dev]\n    # 直接push  会导致 新推送覆盖旧推送，所以只能分开推送到不同tag，最后才采取合并\n    if: needs.version.outputs.u == 'true'\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n      - name: Log in to the Container registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      - name: Log in to the Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKER_HUB_USERNAME }}\n          password: ${{ secrets.DOCKER_HUB_PASSWORD }}\n      - name: Create Manifest\n        run: |\n          docker manifest create --insecure ghcr.io/${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ghcr.io/${{ github.repository_owner }}/rust:amd64 ghcr.io/${{ github.repository_owner }}/rust:386 ghcr.io/${{ github.repository_owner }}/rust:arm-v7 ghcr.io/${{ github.repository_owner }}/rust:arm64\n          \n          docker manifest annotate  ghcr.io/${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ghcr.io/${{ github.repository_owner }}/rust:amd64 --os linux --arch amd64 \n          docker manifest annotate  ghcr.io/${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ghcr.io/${{ github.repository_owner }}/rust:386 --os linux --arch 386\n          docker manifest annotate  ghcr.io/${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ghcr.io/${{ github.repository_owner }}/rust:arm-v7 --os linux --arch arm --variant v7\n          docker manifest annotate  ghcr.io/${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ghcr.io/${{ github.repository_owner }}/rust:arm64 --os linux --arch arm64\n          docker manifest push --insecure ghcr.io/${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }}\n          \n                 \n          docker manifest create --insecure ${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ${{ github.repository_owner }}/rust:amd64 ${{ github.repository_owner }}/rust:386 ${{ github.repository_owner }}/rust:arm-v7 ${{ github.repository_owner }}/rust:arm64\n     \n          docker manifest annotate  ${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ${{ github.repository_owner }}/rust:amd64 --os linux --arch amd64 \n          docker manifest annotate  ${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ${{ github.repository_owner }}/rust:386 --os linux --arch 386\n          docker manifest annotate  ${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ${{ github.repository_owner }}/rust:arm-v7 --os linux --arch arm --variant v7\n          docker manifest annotate  ${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }} ${{ github.repository_owner }}/rust:arm64 --os linux --arch arm64\n\n          docker manifest push --insecure ${{ github.repository_owner }}/rust:${{ needs.version.outputs.ve }}\n\n```\n\n---\n\n执行后出现以下[错误](https://github.com/inkroomtemp/util/actions/runs/5608340637/job/15200531959)\n\n```\nghcr.io/inkroomtemp/rust:amd64 is a manifest list\n```\n\n\n猜测是因为构建出来的镜像已经是一个 manifest list，而非manifest，所以不能再套娃了\n\n## 方案三\n\n\n研究一番后，发现[build-push-action](https://github.com/docker/build-push-action/)在readme里提供了一个并行构建的[样例](https://docs.docker.com/build/ci/github-actions/multi-platform/)\n\n\n---\n\n[结果](https://github.com/inkroomtemp/util/actions/runs/5617649190)是不能**push by digest**\n\n到处都找不到这个配置的文档，只能放弃\n\n## 方案四\n\n这个方案来自[issues](https://github.com/docker/build-push-action/issues/846)\n\n思路是并行构建产物作为缓存，**combine**里引入缓存，完整执行一次普通构建，因为有缓存，所以速度很快，不会超出时间限制\n\n有一点需要处理，每个matrix构建出的缓存都是一个整体，后面使用的时候需要进行一次合并，就是把缓存目录合并，同时把index.json进行[合并](https://github.com/inkroomtemp/util/commit/f75bf5be54b0abb7dce60e98b841baf67cc74475)\n\n---\n\n结果很不理想，构建依然没用上缓存\n\n## 最终方案\n\n研究半天，最终还是回到方案三\n\n发现最开始的错误原因是我在初步构建的时候给了tag和image，这个和outputs里的配置冲突了，去掉就可以正常使用了\n\n\n## 2024-04-03\n\n\n使用中发现一个奇怪的问题:使用qemu模拟i386,dockerfile中使用命令`arch`返回的是x86_64,但是包管理器和命令`dpkg --print-architecture`能返回i386\n\n没找到原因和解决方案,只能不构建这个架构\n\n\n","tags":["rust","github"]},{"title":"自建git-lfs-server","url":"/2023/02/27/10J1G9S.html","content":"\ngit-lfs是git对于二进制文件管理的一种扩展，可以减小仓库体积。\n\n<!-- more -->\n\n## 背景\n\n我的[图片库](https://github.com/inkroom/image)由于存放了大量的图片，发现仓库本身高达**5G**，其中 **.git** 目录就占了一半，应该是每一个二进制文件就会有个备份，再加上被删除的文件。\n\n尝试过重建commit历史，但是依然没减小。\n\n后来了解到[git-lfs](https://github.com/git-lfs/git-lfs)，github的lfs仓库就给**1G**，等于没有，于是准备自建一个。\n\n由于个人的兴趣爱好原因，准备使用**C**来实现\n\n## 项目搭建\n\n经过一通搜索，找到了一个C的web框架[facil.io](https://facil.io)，正常情况下，应该没什么人会用纯C写web，起码也要用C++，所以能找到一个框架真不容易\n\nC的编译可以命令行，本次选择使用**CMake**。\n\n开发软件使用[VSCode](https://code.visualstudio.com/)\n\n开发环境搭建使用之前搞出来的[docker镜像](https://gist.github.com/inkroom/501548078a930c6f3bd98ea257409648)，再用VSCode远程开发\n\n由于我对CMake完全不熟悉，所以用了一个[插件](https://marketplace.visualstudio.com/items?itemName=ChenPerach.c-cpp-cmake-project-creator)来新建项目。\n\n----\n\n插件本身只是创建基础的目录结构，启动脚本之类的。源代码初始化需要使用**facil**提供的[脚本](https://github.com/boazsegev/facil.io)\n\n```shell\nbash <(curl -s https://raw.githubusercontent.com/boazsegev/facil.io/master/scripts/new/app) appname\n```\n\n上面的两个步骤需要两个单独的文件夹，之后把脚本创建的目录里的 **.c** 和 **.h** 复制到插件目录里。\n\n为了引入**facil**依赖，将其源码作为git子模块引入\n\n```shell\ngit submodule add https://github.com/boazsegev/facil.io\n```\n\n最后目录结构如下\n\n```\n . \n ├── CMakeLists.txt \n ├── LICENSE\n ├── README.md\n ├── facil.io\n ├── include\n │   ├── cli.h\n │   ├── http_service.h\n │   └── main.h\n └── src\n     ├── cli.c\n     ├── http_service.c\n     └── main.c\n```\n\n\n\n## 协议文档\n\n本次要实现一个最简单的lfs服务器，相关文档可以查看[lfs仓库](https://github.com/git-lfs/git-lfs/tree/main/docs/api)\n\n\n\n## 路由\n\nfacil是个基础的web框架，没有路由功能，不过没有正好，本来也不需要那些功能。\n\n这里只需要实现一个 **Batch** 接口，只需要以下代码就能判断url\n\n```c\nstatic void on_http_request(http_s *h)\n{\n  /* set a response and send it (finnish vs. destroy). */\n\n  fio_str_info_s path = fiobj_obj2cstr(h->path);\n\n  fio_str_info_s method = fiobj_obj2cstr(h->method);\n\n  fio_str_info_s body = fiobj_obj2cstr(h->body);\n\n  if (strcmp(path.data, LFS_BATCH_URL_PATH) == 0)\n  {\n    batch_request(h);\n  }\n  else\n  {\n  }\n}\n```\n\n`LFS_BATCH_URL_PATH`是一个字符串宏，具体内容是：\n\n```c\n#define LFS_BATCH_URL_PATH \"/objects/batch\"\n```\n\n\nc语言作为早期的高级语言，功能比较原始。比如字符串是用字符数组——实际上很多更高级的语言也是这样——实现的，所以很多库都需要自己用结构体来定义字符串，上面的`fio_str_info_s`是**facil**定义的，之后还有别的库定义的字符串\n\n## 逻辑\n\n```c\n\nvoid _batch_request(http_s *h, FIOBJ jsonBody, lfs_item_each each)\n{\n\n    printf(\"request 1\\n\");\n    FIOBJ objectsKey = fiobj_str_new(\"objects\", strlen(\"objects\"));\n    FIOBJ objects = fiobj_hash_get(jsonBody, objectsKey);\n\n    if (!fiobj_type_is(objects, FIOBJ_T_ARRAY))\n    {\n        printf(\"not allowed json body \");\n\n        fio_free(objects);\n        fio_free(objectsKey);\n\n        return;\n    }\n    printf(\"request 2\\n\");\n\n    // 构建要返回的数据结构\n    FIOBJ res = fiobj_hash_new2(3);\n    FIOBJ transferKey = fiobj_str_new(\"transfer\", strlen(\"transfer\"));\n    FIOBJ basic = fiobj_str_new(\"basic\", strlen(\"basic\"));\n\n    FIOBJ hash_algo_key = fiobj_str_new(\"hash_algo\", strlen(\"hash_algo\"));\n    FIOBJ sha256 = fiobj_str_new(\"sha256\", strlen(\"sha256\"));\n    fiobj_hash_set(res, transferKey, basic);\n    fiobj_hash_set(res, hash_algo_key, sha256);\n\n    size_t count = fiobj_ary_count(objects);\n    printf(\"request 3\");\n\n    // FIOBJ authenticated = fiobj_str_new(\"true\", strlen(\"true\"));\n\n    int i = 0;\n    for (i = 0; i < count; i++)\n    {\n        FIOBJ item = fiobj_ary_index(objects, i);\n        printf(\"request 4\\n\");\n\n        each(item);\n        printf(\"request 5\\n\");\n\n        // fio_free(item);\n    }\n\n    fiobj_hash_set(res, objectsKey, objects);\n    FIOBJ f = fiobj_obj2json(res, 1);\n    fio_str_info_s res_str = fiobj_obj2cstr(f);\n    fiobj_free(f);\n\n    printf(\"res %s\\n\", res_str.data);\n    FIOBJ contentTypeKey = fiobj_str_new(\"Content-Type\", strlen(\"Content-Type\"));\n    FIOBJ contentType = fiobj_str_new(\"application/vnd.git-lfs+json\", strlen(\"application/vnd.git-lfs+json\"));\n    int r = http_set_header(h, contentTypeKey, contentType);\n    printf(\"set content type %d\\n\", r);\n    http_send_body(h, res_str.data, res_str.len);\n\n    fiobj_free(objects);\n    fiobj_free(objectsKey);\n\n    fiobj_free(contentTypeKey);\n    fiobj_free(contentType);\n\n    fiobj_free(hash_algo_key);\n    fiobj_free(sha256);\n\n    fiobj_free(transferKey);\n    fiobj_free(basic);\n\n    fiobj_free(res);\n\n    // fio_free(oidKey);\n    // fio_free(sizeKey);\n    // fio_free(objects);\n    // fio_free(objectsKey);\n}\n```\n---\n\n`lfs_item_each`是一个函数指针，upload和download有不同的实现，由于逻辑本身很简单，不再贴代码了，要看可以直接去[仓库](https://github.com/inkroom/git-lfs-server-c)\n\n\n## 存储\n\n**git-lfs**本身不负责存储，只是负责提供存储相关的API。本次采用[腾讯云COS](https://github.com/tencentyun/cos-c-sdk-v5)作为存储\n\n需要调用两个核心方法**cos_gen_presigned_url**和**cos_gen_object_url**；一个是上传用url，一个是下载用url。\n\nCOS库本身的编译安装这里略过不提\n\n\n由于引入了第三方库，所以需要修改**CMakeLists.txt**，参考cos提供的demo里的，直接把内容拷贝过来，最后就是这样\n\n```CMake\ncmake_minimum_required(VERSION 3.14)\n\n\nset(PROJECT_N lfs)\nproject(${PROJECT_N} VERSION 1.0)\n\nset(CMAKE_C_STANDARD 99)\nset(CMAKE_C_STANDARD_REQUIRED True)\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 最好只在debug下生成这个，或者 -DCMAKE_EXPORT_COMPILE_COMMANDS=on\n\n# if (WIN32 OR MSVC)\n#     set(CMAKE_FIND_LIBRARY_SUFFIXES \".lib\")\n# elseif (UNIX)\n#     # 仅查找静态库，强制后缀为 .a\n#     set(CMAKE_FIND_LIBRARY_SUFFIXES \".a\")\n\n#     # 如果只是优先查找静态库，保证 .a 后缀在前面即可，把默认的后缀加上\n#     # set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES})\n# endif()\n\n\nfile(GLOB_RECURSE SRCS ${PROJECT_SOURCE_DIR}/src/*.c)\n\n# a macro that gets all of the header containing directories. \nMACRO(header_directories return_list includes_base_folder extention)\n    FILE(GLOB_RECURSE new_list ${includes_base_folder}/*.${extention})\n    SET(dir_list \"\")\n    FOREACH(file_path ${new_list})\n        GET_FILENAME_COMPONENT(dir_path ${file_path} PATH)\n        SET(dir_list ${dir_list} ${dir_path})\n    ENDFOREACH()\n    LIST(REMOVE_DUPLICATES dir_list)\n    SET(${return_list} ${dir_list})\nENDMACRO()\n# a macro that gets all of the header containing directories.\nheader_directories(INCLUDES ${PROJECT_SOURCE_DIR}/include/ h)\n\n# include(FetchContent)\n# FetchContent_Declare(curl\n#         GIT_REPOSITORY https://github.com/curl/curl.git\n#         GIT_TAG 7.88.1)\n# FetchContent_MakeAvailable(curl)\n\n# add_subdirectory(cos-c-sdk-v5)\n\n\n# find_package(libcos_c_sdk)\n\n\n\nFIND_PROGRAM(APR_CONFIG_BIN NAMES apr-config apr-1-config PATHS /usr/bin /usr/local/bin /usr/local/apr/bin/)\nFIND_PROGRAM(APU_CONFIG_BIN NAMES apu-config apu-1-config PATHS /usr/bin /usr/local/bin /usr/local/apr/bin/)\n\nIF (APR_CONFIG_BIN)\n    EXECUTE_PROCESS(\n        COMMAND ${APR_CONFIG_BIN} --includedir\n        OUTPUT_VARIABLE APR_INCLUDE_DIR\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    EXECUTE_PROCESS(\n        COMMAND ${APR_CONFIG_BIN} --cflags\n        OUTPUT_VARIABLE APR_C_FLAGS\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    EXECUTE_PROCESS(\n        COMMAND ${APR_CONFIG_BIN} --link-ld\n        OUTPUT_VARIABLE APR_LIBRARIES\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\nELSE()\n    MESSAGE(FATAL_ERROR \"Could not find apr-config/apr-1-config\")\nENDIF()\n\nIF (APU_CONFIG_BIN)\n    EXECUTE_PROCESS(\n        COMMAND ${APU_CONFIG_BIN} --includedir\n        OUTPUT_VARIABLE APR_UTIL_INCLUDE_DIR\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    EXECUTE_PROCESS(\n        COMMAND ${APU_CONFIG_BIN} --cflags\n        OUTPUT_VARIABLE APU_C_FLAGS\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    EXECUTE_PROCESS(\n        COMMAND ${APU_CONFIG_BIN} --link-ld\n        OUTPUT_VARIABLE APU_LIBRARIES\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\nELSE()\n    MESSAGE(FATAL_ERROR \"Could not find apu-config/apu-1-config\")\nENDIF()\n\n#curl-config\nFIND_PROGRAM(CURL_CONFIG_BIN NAMES curl-config)\n  \nIF (CURL_CONFIG_BIN)\n    EXECUTE_PROCESS(\n        COMMAND ${CURL_CONFIG_BIN} --libs\n        OUTPUT_VARIABLE CURL_LIBRARIES\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n        )\nELSE()\n    MESSAGE(FATAL_ERROR \"Could not find curl-config\")\nENDIF()\n# set(CURL_LIBRARY \"-lcurl\") \n# find_package(CURL REQUIRED) \n\ninclude_directories (${APR_INCLUDE_DIR})\ninclude_directories (${APR_UTIL_INCLUDE_DIR})\ninclude_directories (${MINIXML_INCLUDE_DIR})\ninclude_directories (${CURL_INCLUDE_DIR})\n# include_directories(\"include/curl\")\n# message(\"url ${CURL_INCLUDE_DIRS}\")\ninclude_directories (\"/usr/local/include/cos_c_sdk\")\n\nfind_library(APR_LIBRARY apr-1 PATHS /usr/local/apr/lib/)\nfind_library(APR_UTIL_LIBRARY aprutil-1 PATHS /usr/local/apr/lib/)\nfind_library(MINIXML_LIBRARY mxml)\nfind_library(CURL_LIBRARY curl)\nfind_library(COS_LIBRARY cos_c_sdk PATHS /usr/local/lib/)\n\nadd_subdirectory(facil.io)\nmessage(STATUS ${SRCS})\nadd_executable(${PROJECT_N} ${SRCS})\n\ntarget_include_directories(${PROJECT_N} PUBLIC include )\ntarget_link_libraries(${PROJECT_N} facil.io)\n# target_link_libraries(${PROJECT_N} PRIVATE  cos_c_sdk::cos_c_sdk)\ntarget_link_libraries(${PROJECT_N} ${COS_LIBRARY})\ntarget_link_libraries(${PROJECT_N} ${APR_UTIL_LIBRARY})\ntarget_link_libraries(${PROJECT_N} ${APR_LIBRARY})\ntarget_link_libraries(${PROJECT_N} ${MINIXML_LIBRARY})\n\n# target_link_libraries(${PROJECT_N} curl)\ntarget_link_libraries(${PROJECT_N} ${CURL_LIBRARY})\n\n```\n\n\n## docker镜像\n\nC程序过于依赖环境，所以最好使用docker镜像来运行构建产物。\n\n采用docker**多阶段构建**，对docker版本要求较高，公司的测试服务器版本就很低，不支持该特性\n\n\n```Dockerfile\nFROM ubuntu:20.04\nENV TZ=Asia/Shanghai\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone && export DEBIAN_FRONTEND=noninteractive\n# libapr1-dev\nRUN sed -i \"s@http://.*archive.ubuntu.com@http://mirrors.huaweicloud.com@g\" /etc/apt/sources.list \\\n    && sed -i \"s@http://.*security.ubuntu.com@http://mirrors.huaweicloud.com@g\" /etc/apt/sources.list \\\n    && apt update -y && apt upgrade -y\nRUN apt install -y cmake g++  libaprutil1-dev libcurl4-openssl-dev curl wget git libssl-dev\nRUN wget https://github.com/michaelrsweet/mxml/releases/download/v3.3.1/mxml-3.3.1.tar.gz \\\n    && tar -zxf mxml-3.3.1.tar.gz && cd mxml-3.3.1 && ./configure  && make && make install\nRUN wget https://dlcdn.apache.org/apr/apr-1.7.2.tar.gz \\\n    && tar -zxf apr-1.7.2.tar.gz && cd apr-1.7.2 && ./configure  && make && make install\nRUN wget https://github.com/tencentyun/cos-c-sdk-v5/archive/refs/tags/v5.0.16.tar.gz \\\n    && tar -zxf v5.0.16.tar.gz && cd cos-c-sdk-v5-5.0.16 && cmake .  && make && make install\nRUN wget https://curl.se/download/curl-7.88.1.tar.gz\nRUN apt install -y libssl-dev\nRUN tar -zxf curl-7.88.1.tar.gz && cd curl-7.88.1/ && ./configure --disable-ldap --disable-ldaps --with-openssl && make && make install\n\nADD . /data\nRUN cd /data && git submodule update --init --recursive && mkdir /data/build && cd /data/build && cmake .. && make && chmod +x lfs && cp ../entrypoint.sh ./ && chmod +x entrypoint.sh  && cp ../pack.sh ./  && mkdir lib && sh pack.sh  \nRUN \n\n\n\n\n\nFROM ubuntu:20.04\nCOPY --from=0  /data/build/ /lfs\nEXPOSE 3000\nENTRYPOINT [\"/lfs/entrypoint.sh\"]\n```\n\n---\n\n\n有几点需要注意，现在都是动态编译的，单个文件无法运行，需要一堆.so动态库，所以需要使用`pack.sh`来拷贝依赖，`entrypoint.sh`来运行程序\n\n**pack.sh**\n\n```shell\nexe=\"lfs\" # 这里是最终构建的可执行程序的名字\ndes=\"$(pwd)/lib\"\necho $des\ndeplist=$(ldd $exe | awk '{if (match($3,\"/\")){ printf(\"%s \"),$3 } }')\ncp $deplist $des\n```\n\n**entrypoint.sh**\n\n```shell\n#!/bin/sh\ndirname=`dirname $0`\ntmp=\"${dirname#?}\"\nif [ \"${dirname%$tmp}\" != \"/\" ]; then\ndirname=$PWD/$dirname\nfi\nLD_LIBRARY_PATH=$dirname/lib\nexport LD_LIBRARY_PATH\necho $LD_LIBRARY_PATH\n$dirname/lfs \"$@\"\n```\n\n基础原理就是告诉Linux系统去哪里找对应的动态库文件。\n\n但是上面拷贝的动态库实际上是不全的，缺少**glibc**，这一部分一般由操作系统提供，所以最终使用的运行镜像是**Ubuntu:20.04**，不能使用诸如**alpine**、**busybox**之类的精简镜像，因为没有匹配的环境\n\n\n## 静态编译\n\n由于动态库下最终镜像体积高达**87MB**，实在是太大了，所以尝试使用静态编译，然后更新精简镜像来缩小体积\n\n\n想要实现动态编译，就要告诉CMake去查找 **.a** 文件，可以添加以下代码\n\n```CMake\nif (WIN32 OR MSVC)\n    set(CMAKE_FIND_LIBRARY_SUFFIXES \".lib\")\nelseif (UNIX)\n    # 仅查找静态库，强制后缀为 .a\n    set(CMAKE_FIND_LIBRARY_SUFFIXES \".a\")\n\n#     # 如果只是优先查找静态库，保证 .a 后缀在前面即可，把默认的后缀加上\n#     # set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES})\nendif()\n\n```\n注意 cos 库的 .a 文件名与常规命名规则不同，修改一下\n\n```CMake\nfind_library(COS_LIBRARY libcos_c_sdk_static.a PATHS /usr/local/lib/)\n```\n\n---\n\n由于我不知道的原因，静态编译需要把动态编译下不需要关心的依赖的依赖也给加进来，这里主要是 **liburl** 的一些依赖\n\n```CMake\n\nfind_library(IDN_LIBRARY idn)\nfind_library(SSL_LIBRARY ssl)\nfind_library(C_LIBRARY crypto)\nfind_library(DL_LIBRARY dl)\n\n\ntarget_link_libraries(${LIBRARY_N} ${IDN_LIBRARY} ${SSL_LIBRARY} ${C_LIBRARY} ${DL_LIBRARY} ${THREAD_LIBRARY})\n\n```\n\n\nDocker镜像可以使用**busybox**，我还调整curl编译参数，去掉一些不需要的功能。最终产物就只有**12.1MB**了，比较完美\n\n\n## 其他\n\n可以使用github actions来构建docker镜像，并发布到github packages，这里不再赘述\n\n\n\n\n\n\n\n## 参考资料\n\n- [git-lfs](https://github.com/git-lfs/git-lfs)\n- [自行构建GIT LFS服务](https://zhuanlan.zhihu.com/p/511750788)\n- [https://zhuanlan.zhihu.com/p/437865866](https://zhuanlan.zhihu.com/p/437865866)\n","tags":["git","lfs","cmake","c"],"categories":["后端"]},{"title":"使用github actions更新存储库","url":"/2023/02/17/X0B93.html","content":"\n我在我的[图片存储库](https://github.com/inkroom/image)里搞了个列表用于存储文件列表，由于每次上传图片后需要手动执行一些操作，比较繁琐，最终想到利用github actions来实现\n\n<!-- more -->\n\n## 背景\n\n在我的[图片库](https://github.com/inkroom/image)里，有个list文件夹，按上传顺序存储图片列表和对应的图床地址。\n\n实际上，这个图片存储方案改过几次了。\n\n最早存在云服务oss里，自己写个web服务用于上传、浏览，但是后来云服务器到期了，这套方案就没法用了。\n\n然后又使用github pages服务，把图片存在仓库里，然后写个静态页面，借用github pages服务，和github的api，实现了完全免费的图片相册。\n\n但是github访问速度比较慢，因此考虑过gitee，但是图片库体积超过了gitee的限制。借着服务器打折的机会，又买了服务器，这次采用的方案是把网站和图片备份放到服务器上，然后再通过webhook的方式同步图片库，这样速度上去了，也不用担心服务器故障导致图片丢失。\n\n但是又有新问题，图片列表如果调用github的api的话，排序规则不由我决定，不能实现新上传的图片在前面。\n\n最终方案是在图片库里新建文件夹专门存放图片列表，这样顺序就有了。后来又搞了一个图床用作缩略图，还是把数据放这个文件夹里。\n\n----\n\n于是上传操作就变得比较繁琐。\n\n首先添加要上传的图片，然后手动上传到图床，接着修改list文件，最后push。后面的同步借用webhook机制，不用管\n\n## actions\n\n后来比较偶然的机会知道了github actions，其实还有别的免费自动化CI/CD，但是需要到第三方网站使用，不如github本身的便捷\n\n相关代码比较简单，直接参考[仓库](https://github.com/inkroom/image/blob/master/.github/workflows/list.yml)\n\n为了限定获取到上传的文件的commit范围，每次成功后会写入一个**commit sha**到 **.sha** 文件\n\n\n需要注意的是，想要在github actions里push代码，需要配置 **GITHUB_TOKEN** 的权限，在[https://github.com/inkroom/image/settings/actions](https://github.com/inkroom/image/settings/actions)的 **Workflow permissions** 选中 **Read and write permissions**\n\n\n借用 github actions 有个好处是不用关注网络问题了，不需要镜像，不需要代理\n\n最后只需要添加图片后**push**就行了\n\n\n## 其他\n\n\n这里顺便提供一份配置，用于重建仓库以减小仓库体积\n\n在 **.github/workflows/** 下新建**clean.yml**\n\n由于需要使用ssh，还需要将ssh私钥配置到actions secrets\n\n```yaml\nname: clean\n\n# Controls when the workflow will run\non:\n  # Triggers the workflow on push or pull request events but only for the \"main\" branch\n  push:\n    branches: [ \"master\" ]\n  pull_request:\n    branches: [ \"master\" ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n  clean:\n    # The type of runner that the job will run on\n    runs-on: ubuntu-20.04\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Encoding\n        run: |\n          git config --global i18n.logoutputencoding utf-8\n          git config --global i18n.commitencoding utf-8\n          git config --global core.quotepath false\n          git config --global http.version HTTP/1.1\n          git config --global http.postBuffer 524288000\n          export LESSCHARSET=utf-8\n      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it\n      - name: Checkout\n        uses: actions/checkout@v3\n        with:\n          ssh-key: ${{  secrets.SSH_PR }}\n          # We need to fetch all branches and commits so that Nx affected has a base to compare against.\n          fetch-depth: 0\n      # - name: Last Success SHA\n      #   uses: nrwl/nx-set-shas@v3\n      #   id: sha\n      #   with:\n      #     main-branch-name: \"master\"\n      - name: Clean\n        run: |\n          git remote set-url origin git@github.com:/inkroom/image.git\n          git config http.version HTTP/1.1\n          git config http.postBuffer 5242880000\n          git checkout --orphan clean\n          rm .github/workflows/clean.yml\n          git config user.email \"enpassPixiv@protonmail.com\"\n          git config user.name \"inkbox\"\n          #  因为一次全部commit会超出github限制,所以需要分成多次提交 首先把单独的文件都提交了\n          git rm --cached -f -r .\n          for file in *\n          do\n            if [ -f \"$(pwd)/$file\" ]\n            then\n              echo \"添加文件 $file\"\n              git add \"$file\"\n            fi\n          done\n\n          git commit -m \"clean\"\n          git branch -D master\n          git branch -m master\n          git push -f origin master\n\n          ## 文件夹依次提交\n\n          for file in *\n          do\n            if [ -d \"$(pwd)/$file\" ]\n            then\n              if [ \"$file\" != '.git' ]\n              then\n                echo \"添加文件夹 $file\"\n                git add \"$file\"\n                git commit -m \"clean:$file\"\n           #     git push origin master\n              fi\n            fi\n          done\n\n          echo $(git show -s --format=%H) > .github/.sha\n          git add .github/.sha\n          git commit -m \"clean:sha\"\n          git log\n          git push origin master\n\n\n```\n","tags":["github","node"]},{"title":"james源码解析（四）","url":"/2022/11/15/0A214P.html","content":"\n在测试过程中发现了james一个不那么友好的地方，略微做一些修改\n\n<!-- more -->\n\n\n在测试james的过程中，我尝试向**general-subscribe@james.apache.org**（james的一个邮件列表）发送邮件，结果邮件始终无法送达，debug之后发现是apache服务器拒绝了命令\n\n拒绝的是 helo命令和echo 命令会传输一个 hostname，默认情况取得是主机名称，因此给拒绝了。\n\n修改 **mailetcontainer.xml**中的**RemoteDelivery**，添加一个属性 **heloName**，最终结果如下：\n\n```xml\n<processor state=\"relay\" enableJmx=\"true\">\n    <mailet match=\"All\" class=\"RemoteDelivery\">\n        <outgoingQueue>outgoing</outgoingQueue>\n        <delayTime>5000, 100000, 500000</delayTime>\n        <maxRetries>3</maxRetries>\n        <maxDnsProblemRetries>0</maxDnsProblemRetries>\n        <deliveryThreads>10</deliveryThreads>\n        <sendpartial>true</sendpartial>\n        <bounceProcessor>bounces</bounceProcessor>\n        <heloName>smtp.domain.com</heloName>\n    </mailet>\n</processor>\n```\n\n本以为这样就可以了，继续测试发现出现了另一个错误\n\n> Client host rejected: cannot find your reverse hostname\n\n\n查了一下该问题无解，因为要解决该问题，需要给出口ip做反向域名解析，绑定到**heloName**上，然而这是一项收费服务，而且还很贵。\n\n\n----\n\n\n邮件发不出去没关系，但是消息提醒需要有啊，在测试过程中，我确实收到过一次错误邮件，但是邮件内容只有以下信息有用\n\n> Error message:\n> Too many retries failure. Bouncing after 3 retries.\n\n\n意思是重试了三次依然失败，但是没有错误原因，这就很不方便。因此我准备改造一下\n\n\n---\n\n\n投递出错的处理在`DeliveryRunnable`的第153行 `handleTemporaryFailure`\n\n```java\n@VisibleForTesting\nvoid attemptDelivery(Mail mail) throws MailQueue.MailQueueException {\n    ExecutionResult executionResult = mailDelivrer.deliver(mail);\n    switch (executionResult.getExecutionState()) {\n        case SUCCESS:\n            outgoingMailsMetric.increment();\n            configuration.getOnSuccess()\n                .ifPresent(Throwing.consumer(onSuccess -> mailetContext.sendMail(mail, onSuccess)));\n            break;\n        case TEMPORARY_FAILURE:\n            handleTemporaryFailure(mail, executionResult);\n            break;\n        case PERMANENT_FAILURE:\n            handlePermanentFailure(mail, executionResult);\n            break;\n    }\n}\n\n```\n\n\n里面负责判断重试次数，如果达标，则交给`Bouncer`处理，`Bouncer`会修改邮件状态，然后转给别的处理器处理。默认配置下最终转给了`DSNBounce`\n\n\n研究了一下代码，在`Bouncer`的第62行，就已经把真正有用的错误堆栈信息给处理掉了\n\n```java\npublic void bounce(Mail mail, Exception ex) {\n    if (!mail.hasSender()) {\n        LOGGER.debug(\"Null Sender: no bounce will be generated for {}\", mail.getName());\n    } else {\n        if (configuration.getBounceProcessor() != null) {\n            computeErrorCode(ex).ifPresent(mail::setAttribute);\n            mail.setAttribute(new Attribute(DELIVERY_ERROR, AttributeValue.of(getErrorMsg(ex))));\n            try {\n                mailetContext.sendMail(mail, configuration.getBounceProcessor());\n            } catch (MessagingException e) {\n                LOGGER.warn(\"Exception re-inserting failed mail: \", e);\n            }\n        } else {\n            bounceWithMailetContext(mail, ex);\n        }\n    }\n}\n```\n\n那就只有改这个类，但是这个类是直接在`RemoteDelivery`里写死的new方法创建，没办法动态注入\n\n```java\npublic void init() throws MessagingException {\n    configuration = new RemoteDeliveryConfiguration(getMailetConfig(), domainList);\n    queue = queueFactory.createQueue(configuration.getOutGoingQueueName());\n    deliveryRunnable = new DeliveryRunnable(queue,\n        configuration,\n        dnsServer,\n        metricFactory,\n        getMailetContext(),\n        new Bouncer(configuration, getMailetContext()));\n    if (startThreads == ThreadState.START_THREADS) {\n        deliveryRunnable.start();\n    }\n}\n```\n\n\njames大概是不希望这里能够自由扩展，但是没关系，反正是有源码的，改一下重新打包就是，修改成如下代码\n\n```java\n\nprivate void handleTemporaryFailure(Mail mail, ExecutionResult executionResult) throws MailQueue.MailQueueException {\n    if (!mail.getState().equals(Mail.ERROR)) {\n        mail.setState(Mail.ERROR);\n        DeliveryRetriesHelper.initRetries(mail);\n        mail.setLastUpdated(dateSupplier.get());\n    }\n    mail.setAttribute(new Attribute(IS_DELIVERY_PERMANENT_ERROR, AttributeValue.of(false)));\n    int retries = DeliveryRetriesHelper.retrieveRetries(mail);\n\n    if (retries < configuration.getMaxRetries()) {\n        reAttemptDelivery(mail, retries);\n    } else {\n\t    LOGGER.debug(\"Bouncing message {} after {} retries\", mail.getName(), retries);\n\t    bouncer.bounce(mail, new Exception(\"Too many retries failure. Bouncing after \" + retries + \" retries.\\n\" + executionResult.getException().map(e -> {\n\t        if (e instanceof MessagingException) {\n\t            return e.getMessage() + \"\\n\" + ((MessagingException) e).getNextException().getMessage();\n\t        }\n\t        return e.getMessage();\n\t    }).orElse(\"\"), executionResult.getException().orElse(null)));\n    }\n}\n\n```\n\n尝试打包后失败，原因是代码格式未通过校验。相关错误是import的位置不对和代码缩减使用了tab，处理一下就行能顺利打包了。\n\n如果之前已经打过包的，只需要在`server/mailet/mailets`和要使用的构建版本打两次包就行\n\n我这里用的docker，所以需要的是`server/apps/jpa-app/target`下的**jib-image.tar**，我还顺便改了一下image的标签\n\n\n\n","tags":["java","james","apache"],"categories":["后端","java","james"]},{"title":"james源码解析（三）","url":"/2022/11/14/2VRR7FK.html","content":"\n因个人需要，在个人服务器上搭建了邮箱服务器，使用的是[mailu](https://mailu.io/)，整体基于docker多容器搭建。\n\n本来用起来没什么大问题，但是因为其自带nginx容器，和我原本部署的nginx容器会有一定的冲突，不是很满意\n\n一番查找后，让我找到了[james](https://james.apache.org)——apache开发的基于java的邮箱服务器。\n\n<!-- more -->\n\n\n上一篇中解析到了SMTP协议的解码和命令执行，姑且搞明白了网络通信的部分，但是没有弄清楚如何跟邮件处理关联的。\n\n在翻看了代码后，让我找到了 `DataCmdHandler` 类，这是负责**Data**指令的数据，指令执行完之后就是邮件发送完成了\n\n查看**doDATA**方法，发现一行代码\n\n```java\nsession.pushLineHandler(lineHandler);\n```\n\n这是在往处理链条里加入一个新的处理器，并且在原有处理器前执行，不知道和之前提到的 获取最后一个LineHandler 有没有关系，继续往里深入，没有发现其被添加到chain里\n\ndebug后发现，这个lineHandler是个责任链模式，具体里面有哪些handler暂时不去深究，现在的重点是要找到最终的邮件处理，在一通操作后，找到了`DataLineJamesMessageHookHandler`，在这个类里面负责了**Mail**的创建，之前的handler应该就是解析各个部分。\n\n在这个类的 **messageHandlers** 属性中有个类是 `SendMailHandler`，在其`onMessage`方法中\n\n```java\nqueue.enQueue(mail);\n```\n\n可见最终是交给了一个队列，在jpa版本中这个队列是`ActiveMQCacheableMailQueue`，就整体架构来看，这应该是一个基于内存的队列。\n\n队列入队的数据，需要通知消费者，相关代码在`JMSCacheableMailQueue`的第204行，再往下就是`activemq-client`依赖包提供的内容了。\n\nSMTP邮件投递确实是一个异步的过程，可以使用队列解耦，但是IMAP和pop3是同步的，应该没法用mq了\n\n---\n\n\n找到了生产者，之后就是找消费者。debug之后，queueName是 **queue://spool** ，直接搜这个字符串没找到。那就只能从创建开始，最终找到了`JamesMailSpooler`，从里面的注释来看，这个类是负责响应队列消息分发给processor\n\n```java\nprivate reactor.core.Disposable run(MailQueue queue) {\n    return Flux.from(queue.deQueue())\n        .flatMap(item -> handleOnQueueItem(item).subscribeOn(Schedulers.elastic()), configuration.getConcurrencyLevel())\n        .onErrorContinue((throwable, item) -> LOGGER.error(\"Exception processing mail while spooling {}\", item, throwable))\n        .subscribeOn(Schedulers.elastic())\n        .subscribe();\n}\n```\n\n这里是通过一个定时器去队列里获取消息，最终转发到第117行，给处理器处理消息。从这个流程来看，感觉ActiveMQ仿佛没用上啊\n\n```java\nprivate void performProcessMail(MailQueueItem queueItem, Mail mail) {\n    LOGGER.debug(\"==== Begin processing mail {} ====\", mail.getName());\n    ImmutableList<MailAddress> originalRecipients = ImmutableList.copyOf(mail.getRecipients());\n    try {\n        mailProcessor.service(mail);\n\n        if (Thread.currentThread().isInterrupted()) {\n            throw new InterruptedException(\"Thread has been interrupted\");\n        }\n        queueItem.done(true);\n    } catch (Exception e) {\n        handleError(queueItem, mail, originalRecipients, e);\n    } finally {\n        LOGGER.debug(\"==== End processing mail {} ====\", mail.getName());\n    }\n}\n```\n\n---\n\n\n现在已经真正开始了邮件的一个处理过程，核心接口是`MailProcessor`。james把不同邮件状态交给不同的`MailProcessor`实例执行，从配置文件中也能看出来，抽象父类`AbstractStateMailetProcessor`负责处理这一逻辑\n\n\n\n这里开始涉及james中的一个概念————**mailet**，[https://james.apache.org/server/feature-mailetcontainer.html](https://james.apache.org/server/feature-mailetcontainer.html) 有对其详细的描述\n\n我的英文水平一般，看完之后的理解是：mailt是一个邮件处理器的抽象，其由两部分组成————matcher和Processor，前者负责匹配邮件，确定是否需要执行processor，后者负责具体的逻辑。整体看来依然是一个责任链模式或者装饰模式\n\n\nmailt的实现类非常多，结合**mailetcontainer.xml**来看，最主要的是**ToProcessor**类————原本我是这样想的，但是打开代码一看\n\n```java\n@Override\npublic void service(Mail mail) throws MessagingException {\n    if (debug) {\n        LOGGER.debug(\"Sending mail {} to {}\", mail, processor);\n    }\n    mail.setState(processor);\n    if (noticeText.isPresent()) {\n        setNoticeInErrorMessage(mail);\n    }\n}\n```\n\n实际上这货就负责改一个邮件状态，然后在流程中就是交给其他处理器负责了。具体是那个处理器可以从配置文件中看到————**<processor>transport</processor>**\n\n再重新看配置文件夹，重点是**transport**\n\n\n\n```xml\n<processor state=\"transport\" enableJmx=\"true\">\n    <matcher name=\"relay-allowed\" match=\"org.apache.james.mailetcontainer.impl.matchers.Or\">\n        <matcher match=\"SMTPAuthSuccessful\"/>\n        <matcher match=\"SMTPIsAuthNetwork\"/>\n        <matcher match=\"SentByMailet\"/>\n    </matcher>\n\n    <mailet match=\"All\" class=\"RemoveMimeHeader\">\n        <name>bcc</name>\n        <onMailetException>ignore</onMailetException>\n    </mailet>\n    <mailet match=\"All\" class=\"RecipientRewriteTable\">\n        <errorProcessor>rrt-error</errorProcessor>\n    </mailet>\n    <mailet match=\"RecipientIsLocal\" class=\"Sieve\"/>\n    <mailet match=\"RecipientIsLocal\" class=\"AddDeliveredToHeader\"/>\n    <mailet match=\"RecipientIsLocal\" class=\"LocalDelivery\"/>\n    <mailet match=\"HostIsLocal\" class=\"ToProcessor\">\n        <processor>local-address-error</processor>\n        <notice>550 - Requested action not taken: no such user here</notice>\n    </mailet>\n\n    <mailet match=\"relay-allowed\" class=\"ToProcessor\">\n        <processor>relay</processor>\n    </mailet>\n</processor>\n```\n\n\n这里有开始看不懂了，**Sieve**是RFC3028的java实现，是为了实现邮件过滤，可以理解成防垃圾邮件。**LocalDelivery**应该是处理投递到当前服务器的邮件。那么投递到其他邮箱服务器的实现又在哪里呢？\n\n先看本地投递吧\n\n本地投递没多少特别的，主要是注入了**UsersRepository**、**MailboxManager**负责用户和邮件的存储，实际使用是再委托给了**MailDispatcher**负责。很多项目都会这样，一层套一层，导致理解起来相当费劲。就jpa版本来说，就是把数据入库，要注意的是这里没有做消息通知，说明james的listener机制还有别的地方再处理。搞得很头大啊！\n\n手动发一封到其他邮箱服务的邮件，debug看一下具体流程\n\n果然根本发不出去！\n\n\n仔细看错误日志，这是在 **RCPT TO**给拒绝了\n\n检查了半天，最后改了一下 **smtpserver.xml** 的配置，把587端口的ssl要求都关闭，同时邮件发送脚本改用587端口\n\ndebug之后，找到了**RemoteDelivery**，很明显，这个类负责投递远程邮件。那么这个类又是什么时候注入的呢？\n\n再仔细回去看配置文件，这是在另一个state的processor中配置的\n\n```xml\n<processor state=\"relay\" enableJmx=\"true\">\n    <mailet match=\"All\" class=\"RemoteDelivery\">\n        <outgoingQueue>outgoing</outgoingQueue>\n        <delayTime>5000, 100000, 500000</delayTime>\n        <maxRetries>3</maxRetries>\n        <maxDnsProblemRetries>0</maxDnsProblemRetries>\n        <deliveryThreads>10</deliveryThreads>\n        <sendpartial>true</sendpartial>\n        <bounceProcessor>bounces</bounceProcessor>\n    </mailet>\n</processor>\n```\n\n查看该类的实现逻辑，依旧使用了队列，将其投递到了 **outgoing** 队列中，该队列由`DeliveryRunnable`负责消费，再将投递操作委托给`MailDelivrer`，再然后就是一些具体的邮件发送过程了，比如解析dns之类的，不做深入研究\n\n","tags":["java","james","apache"],"categories":["后端","java","james"]},{"title":"james源码解析（二）","url":"/2022/11/13/3X95FN1.html","content":"\n因个人需要，在个人服务器上搭建了邮箱服务器，使用的是[mailu](https://mailu.io/)，整体基于docker多容器搭建。\n\n本来用起来没什么大问题，但是因为其自带nginx容器，和我原本部署的nginx容器会有一定的冲突，不是很满意\n\n一番查找后，让我找到了[james](https://james.apache.org)——apache开发的基于java的邮箱服务器。\n\n<!-- more -->\n\n上一篇章中实现了james的运行和测试，这一篇开始源码入门\n\n## 源码入门\n\n\n在 `server/Overview.md` 中有对项目一些结构性描述，奈何文档只写了个开头，总共不过一百行文字，而且和现有项目都有些对不上了，希望apache社区能早日补充文档\n\n依照我目前的理解，james总体可以分成以下几个部分\n\n- protocols 协议实现和通信，基于netty的网络通信，实现了协议解析\n- store 数据存储\n- mailet james自已定义的组件名称，我的理解是邮件的处理器，james的各种功能也是通过mailet实现的\n- event 事件机制\n\n当然james不止这点东西，其他的要么我还没了解到，要么没必要深究\n\n--- \n\n想要了解一个项目，首先需要从程序入口开始。\n\n以`server/apps/jpa-app/src/main/java/org/apache/james/JPAJamesServerMain.java`为例\n\n查看他的main方法\n\n```java\npublic static void main(String[] args) throws Exception {\n    ExtraProperties.initialize();\n\n    JPAJamesConfiguration configuration = JPAJamesConfiguration.builder()\n        .useWorkingDirectoryEnvProperty()\n        .build();\n\n    LOGGER.info(\"Loading configuration {}\", configuration.toString());\n    GuiceJamesServer server = createServer(configuration)\n        .combineWith(new JMXServerModule());\n\n    JamesServerMain.main(server);\n}\n```\n\n头两行代码看起来是配置文件的读取，可以先跳过。重点是最后两行代码。\n\n`JamesServerMain.main(server);`是调用服务启动方法和注册关闭hook，不重要。\n\n\n因此看`createServer`\n```java\nstatic GuiceJamesServer createServer(JPAJamesConfiguration configuration) {\n    return GuiceJamesServer.forConfiguration(configuration)\n        .combineWith(JPA_MODULE_AGGREGATE)\n        .combineWith(new UsersRepositoryModuleChooser(new JPAUsersRepositoryModule())\n            .chooseModules(configuration.getUsersRepositoryImplementation()));\n}\n```\n\n这个`combineWith`是干什么的？看一下**JPA_MODULE_AGGREGATE**参数是什么\n\n```java\nprivate static final Module JPA_SERVER_MODULE = Modules.combine(\n    new ActiveMQQueueModule(),\n    new DefaultProcessorsConfigurationProviderModule(),\n    new ElasticSearchMetricReporterModule(),\n    new JPADataModule(),\n    new JPAMailboxModule(),\n    new MailboxModule(),\n    new LuceneSearchMailboxModule(),\n    new NoJwtModule(),\n    new RawPostDequeueDecoratorModule(),\n    new SieveJPARepositoryModules(),\n    new DefaultEventModule(),\n    new TaskManagerModule(),\n    new MemoryDeadLetterModule(),\n    new SpamAssassinListenerModule());\n\nprivate static final Module JPA_MODULE_AGGREGATE = Modules.combine(\n    new MailetProcessingModule(), JPA_SERVER_MODULE, PROTOCOLS);\n```\n\n\n从命令看出，这应该是在组装应用模块。james将功能拆分开，最后通过组合不同的模块，实现最终提供不同功能的版本\n\n\n一路深入下去，发现这一套 **module** 定义是 **Guice** 提供的，查阅资料可知，这是一个依赖注入框架，类似于Spring，在学习阶段直接当成Spring看待就行。\n\n以`server/container/guice/protocols/smtp/src/main/java/org/apache/james/modules/protocols/SMTPServerModule.java` 为例\n\n```java\npublic class SMTPServerModule extends AbstractModule {\n    @Override\n    protected void configure() {\n        install(new JSPFModule());\n        bind(SMTPServerFactory.class).in(Scopes.SINGLETON);\n        bind(OioSMTPServerFactory.class).in(Scopes.SINGLETON);\n\n        Multibinder.newSetBinder(binder(), GuiceProbe.class).addBinding().to(SmtpGuiceProbe.class);\n    }\n\n    @ProvidesIntoSet\n    InitializationOperation configureSmtp(ConfigurationProvider configurationProvider,\n                                        SMTPServerFactory smtpServerFactory,\n                                        SendMailHandler sendMailHandler) {\n        return InitilizationOperationBuilder\n            .forClass(SMTPServerFactory.class)\n            .init(() -> {\n                smtpServerFactory.configure(configurationProvider.getConfiguration(\"smtpserver\"));\n                smtpServerFactory.init();\n                sendMailHandler.init(null);\n            });\n    }\n\n}\n```\n\n核心方法应该是 **smtpServerFactory.init()** ，一路追踪下去，最终来到了`server/protocols/protocols-library/src/main/java/org/apache/james/protocols/lib/netty/AbstractConfigurableAsyncServer#init` \n\n```java\n@PostConstruct\npublic final void init() throws Exception {\n\n    if (isEnabled()) {\n\n        buildSSLContext();\n        preInit();\n        executionHandler = createExecutionHandler();\n        frameHandlerFactory = createFrameHandlerFactory();\n        bind();\n        port = retrieveFirstBindedPort();\n\n        mbeanServer = ManagementFactory.getPlatformMBeanServer();\n        registerMBean();\n        \n        LOGGER.info(\"Init {} done\", getServiceType());\n\n    }\n\n}\n```\n\n这个模块是SMTP协议实现，james的网络通信是使用的**netty**，netty核心是handler，所以需要关注的就是Handler实现类。\n\n结合之前测试的日志可以发现有个`SMTPChannelUpstreamHandler`类，排查代码，定位到 `SMTPServer`的第**221**行。\n\n这里的实现逻辑是抽象类提供方法负责注册handler，子类重写方法提供不同的handler实现。典型的模板模式\n\n`SMTPChannelUpstreamHandler`三个核心方法，也就是netty提供的方法，分别对应连接建立，收到消息和连接关闭。\n\n查看代码可知，具体实现在其父类`BasicChannelUpstreamHandler`\n\n---\n\n先看连接建立\n\n```java\npublic void channelConnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {\n    try (Closeable closeable = mdc(ctx).build()) {\n        List<ConnectHandler> connectHandlers = chain.getHandlers(ConnectHandler.class);\n        List<ProtocolHandlerResultHandler> resultHandlers = chain.getHandlers(ProtocolHandlerResultHandler.class);\n        ProtocolSession session = (ProtocolSession) ctx.getAttachment();\n        LOGGER.info(\"Connection established from {}\", session.getRemoteAddress().getAddress().getHostAddress());\n        if (connectHandlers != null) {\n            for (ConnectHandler cHandler : connectHandlers) {\n                long start = System.currentTimeMillis();\n                Response response = cHandler.onConnect(session);\n                long executionTime = System.currentTimeMillis() - start;\n\n                for (ProtocolHandlerResultHandler resultHandler : resultHandlers) {\n                    resultHandler.onResponse(session, response, executionTime, cHandler);\n                }\n                if (response != null) {\n                    // TODO: This kind of sucks but I was able to come up with something more elegant here\n                    ((ProtocolSessionImpl) session).getProtocolTransport().writeResponse(response, session);\n                }\n\n            }\n        }\n        super.channelConnected(ctx, e);\n    }\n}\n```\n\n其实三个方法逻辑都大差不大，都是通过**chain**获取handler，依次执行后写入数据到连接。只是不同事件封装了不同的Handler接口\n\n`ProtocolHandlerChain chain`里维护了一个handler的列表，查看其子类找到`SMTPProtocolHandlerChain#initDefaultHandlers`，可以看到其维护的handler列表。此时出现问题了，通过ide无法找到该类构造方法调用位置，debug断点也没有执行，反倒找到了另外一个类`org.apache.james.smtpserver.CoreCmdHandlerLoader`,这个类同样维护了一个handler列表，这就有点迷惑了，这到底是怎么个流程。\n\n实在搞不懂，先暂时跳过，总之知道了有哪些handler。\n\n---\n\n回到`BasicChannelUpstreamHandler`，重点看消息接受方法\n\n```java\npublic void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {\n    try (Closeable closeable = mdc(ctx).build()) {\n        ProtocolSession pSession = (ProtocolSession) ctx.getAttachment();\n        LinkedList<LineHandler> lineHandlers = chain.getHandlers(LineHandler.class);\n        LinkedList<ProtocolHandlerResultHandler> resultHandlers = chain.getHandlers(ProtocolHandlerResultHandler.class);\n\n\n        if (lineHandlers.size() > 0) {\n\n            ChannelBuffer buf = (ChannelBuffer) e.getMessage();\n            LineHandler lHandler = (LineHandler) lineHandlers.getLast();\n            long start = System.currentTimeMillis();\n            Response response = lHandler.onLine(pSession, buf.toByteBuffer());\n            long executionTime = System.currentTimeMillis() - start;\n\n            for (ProtocolHandlerResultHandler resultHandler : resultHandlers) {\n                response = resultHandler.onResponse(pSession, response, executionTime, lHandler);\n            }\n            if (response != null) {\n                // TODO: This kind of sucks but I was able to come up with something more elegant here\n                ((ProtocolSessionImpl) pSession).getProtocolTransport().writeResponse(response, pSession);\n            }\n\n        }\n\n        super.messageReceived(ctx, e);\n    }\n}\n```\n\n这里可以看到有点不太一样了，获取的LineHandler列表只执行了最后一个，这是为何啊。\n\n\n从之前的handler列表中，可以看到`CommandDispatcher`，从名字看是服务命令分发的。其他handler也基本是各个命令的实现。\n\n看到这里已经大致明白了网络协议的部分架构，但是还没搞懂如何和核心的邮件处理关联","tags":["java","james"],"categories":["后端","java","james"]},{"title":"james源码解析（一）","url":"/2022/11/12/3588MKS.html","content":"\n因个人需要，在个人服务器上搭建了邮箱服务器，使用的是[mailu](https://mailu.io/)，整体基于docker多容器搭建。\n\n本来用起来没什么大问题，但是因为其自带nginx容器，和我原本部署的nginx容器会有一定的冲突，不是很满意\n\n一番查找后，让我找到了[james](https://james.apache.org)——apache开发的基于java的邮箱服务器。\n\n<!-- more -->\n\n## james是什么\n\njames是apache开发的基于java的邮箱服务器，支持的协议包括常见的SMTP、IMAP、POP3，还有我都没听说过的JAMP。\n\n在本文编写时，最新版本为3.7.2\n\n## 编译\n\n首先获取项目源码，有两种途径，一是在apache官网上下载版本源码，二是在[github](https://github.com/apache/james-project)上clone代码\n\n\n\n我使用第二种方式。\n\n从后续的过程来看，如果想要编译运行，似乎需要git log记录，如果不是git项目的话，不知道会不会编译失败。\n\n----\n\n下载下来之后首先切到 3.7.2 的tag上，把代码固定住，后续贴代码的时候更方便\n\n下载下来之后可以看到项目模块非常多，而且还有scala相关代码，因此ide最好下载一个scala插件。\n\n里面还有部分文档是以.adoc结尾，是一种类似markdown的标记型语法，建议也装一个相关插件\n\n----\n\n在根目录执行\n\n```shell \nmvn clean install -DskipTests -T 6\n```\n\n**-T 6**代表开6个线程加速编译\n\n注意跳过测试不能使用 **-Dmaven.test.skip=true**，这样会导致test目录不会被编译，部分模块依赖会出错\n\n另外maven仓库最好换成官方仓库，我用的阿里云仓库会有部分依赖没有\n\n如果网络没有什么问题的话，编译应该很顺利。编译完成后项目5G，依赖2G，很夸张啊。\n\n\n## 运行\n\n如何启动项目[官网](https://james.apache.org/server/install.html)也有明确的描述\n\njames为了适应不同的环境需求，有着多种构建版本，具体可以参见[https://james.apache.org/server/packaging.html](https://james.apache.org/server/packaging.html)\n\n\n总的分成五个版本：\n\n- distributed 依赖最多、最为复杂的分布式版本，支持多节点部署\n- jpa 使用openjpa存储数据的单节点版本\n- demo 没看出和jpa有什么区别\n- memory 使用内存存储数据，主要用于测试\n- cassandra 换了存储方式和搜索引擎\n\n---\n\n为了测试环境是否正常，建议先运行**memory**版本\n\n\n启动类位于 `server/apps/memory-app/src/main/java/org/apache/james/MemoryJamesServerMain.java`\n\n同时需要指定一个工作目录用于存储数据，可以通过启动参数 `-Dworking.directory=/home/james` 指定\n\n在工作目录下创建目录 `conf`，将 `server/apps/memory-app/sample-configuration`里的文件全放进去\n\n默认情况下，还需要生成证书。\n\n在工作目录下执行以下命令\n\n```shell\nkeytool -genkey -alias james -keyalg RSA -keystore conf/keystore\n```\n\n证书密钥固定为 **james72laBalle** ，或者更换相关配置文件中的值为你想要的内容\n\n\n启动项目，注意由于 SMTP、POP3、IMAP默认启动端口都在1024以下，所以linux需要要么以**root**权限启动，要么修改`smtpserver.xml`、`imapserver.xml`、`pop3server.xml`里的端口\n\n\n## 配置邮箱\n\n启动项目之后需要添加两个账号用于测试，账号格式为 **account@localhost** ，后面域名部分固定，除非手动添加一个domain到domainlist中\n\n\n这里我是用jconsole通过jmx添加的，也可以通过相关命令行执行\n\n\n\n---\n\n邮箱客户端我使用的是win10自带的邮件软件\n\n注意设置服务器地址，而且最好不要使用ssl\n\n\n\n一通操作下来，向外部邮箱发送邮件和本地邮箱收发邮件应该没什么问题了。\n","tags":["java","james"],"categories":["后端","java","james"]},{"title":"统计最高在线人数","url":"/2022/07/12/2DRS3A3.html","content":"\n最近接了个统计需求，需要统计某一段时间内的最高在线人数\n\n\n<!-- more -->\n\n\n\n本来最高在线人数是前期最好处理，根据长连接建立和中断统计人数，将最高值入库。\n\n但是前期因为某些原因不太好做，那就只能后期来做处理。\n\n## 数据\n\n\n我能拿到的数据包含进入和离开时间，统计也按照这两个时间来。\n\n## 思路\n\n最开始想的是将若干个时间段放在时间轴上，然后用类似取交集的方式计算最高在线人数。\n\n\n看着很像是用**滑动窗口**解决，为此还去letcode上找有没有类似的题目。\n\n但是没找到，不得不转变思路。\n\n\n首先需要一根时间轴，这个用链表实现，将链表的每个节点认为是一个时间点，用index来表示。\n\n那么进入和退出就是在指定的节点上插入数据；\n\n最后再遍历这条链表，根据每个节点不同的状态执行 +1 -1 操作\n\n----\n\n但是上述方法会浪费大量的空间，因为可能存在某个时间点没有进入退出，但是链表上对应的节点依然存在\n\n需要想办法把这些节点给干掉\n\n## 优化\n\n之所以要提前建立节点，是因为在插入数据的时候没法保证顺序，后面遍历的时候一定要保证链表节点是按照时间顺序排列的。\n\n即便对原始数据进行排序，因为有两个时间的缘故，也没什么用处\n\n 尝试把进入和退出拆分到两条链表，再把原始数据按照两个时间分别排序。\n\n然后先遍历进入，再遍历退出。没办法在一个循环里搞定。\n\n再考虑怎么遍历。一条链表的情况下，只需要对每个节点做判断；但是两条链表的话，如何保证是在遍历每一秒，因为此时index不能代表时间点。\n\n\n\n可以使用双指针。\n第一个指针指向进入链表，以这条链表为准遍历。\n\n遍历开始，每个指针都执行头节点\n\n进入指针步进，同时做+1操作，根据当前节点的时间来判断退出链表是否步进，当进入时间晚于退出时间，则退出指针步进，此时方才做-1操作\n\n进入链表结束时，退出链表肯定没有完，但是后面的数据只会有-1操作，不影响最高人数统计，可以不用处理\n\n实际上的遍历操作就是一个双链表合并排序问题\n\n\n## 实现\n\n```java\n\n    private static class VisitNode {\n        /**\n         * 当前秒操作人数\n         */\n        private int count = 0;\n        /**\n         * 当前节点代表的时间点，\n         */\n        private int second = 0;\n\n        private VisitNode next;\n\n        private Long time;\n    }\n\n    private VisitNode count(long second, VisitNode tail, VisitNode head, LiveStat s, long time) {\n        if (tail == head) {//创建第一个节点\n            head.next = new VisitNode();\n            tail = head.next;\n            tail.second = ((int) second);\n            tail.count = 1;\n            tail.time = time;\n\n        } else if (tail.second == second) {//判断是否和当前时间点相同\n            tail.count += 1;\n        } else {//继续追加节点\n            tail.next = new VisitNode();\n            tail = tail.next;\n            tail.second = ((int) second);\n            tail.count = 1;\n            tail.time = time;\n        }\n        return tail;\n    }\n\n\n\n    VisitNode enterHead = new VisitNode();\n    VisitNode quietHead = new VisitNode();\n    VisitNode enterTail = enterHead, quietTail = quietHead;\n\n    List<LiveStat> enterStat; // 数据来源不重要，总之 enterStat 是一个按照 进入时间 排好序的数据\n    List<LiveStat> quietStat;  // 数据来源不重要，总之 quietStat 是一个按照 退出时间 排好序的数据\n\n\n    // 处理进入操作\n\n    for (LiveStat liveStat : enterStat) {\n        Long second = liveStat.getStartTime();\n\n        // 取当前秒距离开始统计时间的秒数\n        long se = (second - startTime) / 1000;\n\n        enterTail = count(se, enterTail, enterHead, liveStat, liveStat.getStartTime());\n\n    }\n\n    // 处理退出操作\n    for (LiveStat liveStat : quietStat) {\n        Long second = liveStat.getEndTime();\n\n        // 取当前秒距离开始统计时间的秒数\n        long se = (second - startTime) / 1000;\n        quietTail = count(se, quietTail, quietHead, liveStat, liveStat.getEndTime());\n\n    }\n\n    // 双指针，遍历进入退出\n\n    int max = 0;\n    int count = 0;\n    quietHead = quietHead.next;// 避免把头结点算进来\n    enterHead = enterHead.next;\n\n    while (enterHead != null) {//不用关心quietHead是否遍历完问题\n        if (enterHead.second < quietHead.second) {\n            logger.info(\"进入时间={}\", DateUtils.getAllTime(enterHead.time));\n            count += enterHead.count;\n            enterHead = enterHead.next;\n        } else if (enterHead.second > quietHead.second) {\n            logger.info(\"退出时间={}\", DateUtils.getAllTime(enterHead.time));\n            count -= quietHead.count;\n            quietHead = quietHead.next;\n        } else {//同时有人进出的情况\n            logger.info(\"同时时间={}\", DateUtils.getAllTime(enterHead.time));\n            count -= quietHead.count;\n            count += enterHead.count;\n\n            quietHead = quietHead.next;\n            enterHead = enterHead.next;\n        }\n        if (count >= max) {\n            max = count;\n        }\n\n    }\n\n\n```\n\n","tags":["算法","链表"],"categories":["算法"]},{"title":"SpringBoot线程安全问题","url":"/2022/06/29/3D0TZJP.html","content":"\n项目中使用到了ThreadLocal，在某次更新中出了问题，本以为只是把ThreadLocal remove就行了，结果却排查出一个线程安全问题\n\n<!-- more -->\n\n\n## 环境\n\n项目基于 **SpringBoot-2.3.7.RELEASE** 版本构建，其他无关紧要\n\n## 架构\n\n\n首先介绍一下整体流程。\n\n项目为了区分各个终端的版本，在**header**头里添加了**x-api**用于存储版本号\n\n后端为了便于使用，将版本号写成了一个枚举，采用三位版本号。由于前后端版本号不会同步的原因，前端有时候会升级小版本号，为了后端不发版，就把枚举做了处理，将小版本号用**ThraedLocal**存储\n\n\n基本代码如下：\n\n```java\n\npublic enum Version implements Comparable<Version> {\n\n\n    DEFAULT(1, 1, 0, true),\n    _1_4_0(1, 4, 0, true),\n    _2_0_0(2, 0, 0, true),\n    ;\n\n    private int high = 1;\n\n    private int mid = 1;\n\n    private int low = 0;\n\n\n    private static final ThreadLocal<Integer> lowVersion = new ThreadLocal<>();\n\n    Version(int high, int mid, int low, boolean swagger) {\n        this.high = high;\n        this.mid = mid;\n        this.low = low;\n        this.swagger = swagger;\n    }\n\n\n    public String value() {\n        Integer integer = lowVersion.get();\n        return String.format(\"%d.%d.%d\", high, mid, integer == null ? low : integer);\n    }\n\n    public boolean swagger() {\n        return swagger;\n    }\n\n    private static final Logger logger = LoggerFactory.getLogger(Version.class);\n\n    public static Version convert(String api) {\n        if (StringUtils.isBlank(api)) {\n            return DEFAULT;\n        }\n        if (Constants.DEFAULT_VERSION.equals(api)) {\n            return DEFAULT;\n        }\n        try {\n            Version version = valueOf(\"_\" + api.replaceAll(\"\\\\.\", \"_\"));\n            return version;\n        } catch (IllegalArgumentException e) {\n\n            // 没有对应的版本号，给一个大中版本都匹配的版本\n            String[] split = api.split(\"\\\\.\", 3);\n\n            if (split.length != 3) {\n                throw new UnsupportedVersionException(api);\n            }\n            Version[] values = values();\n            for (int i = values.length - 1; i >= 0; i--) {\n\n                if (split[0].equals(String.valueOf(values[i].high)) && split[1].equals(String.valueOf(values[i].mid))) {// 找到一个匹配的中版本，\n                    try {\n                        lowVersion.set(Integer.valueOf(split[2]));\n                        return values[i];\n                    } catch (NumberFormatException ex) {\n                        throw new UnsupportedVersionException(api);\n                    }\n                }\n            }\n            throw new UnsupportedVersionException(api);\n        }\n    }\n\n}\n\n\n```\n\n\n注意，上面使用到的ThreadLocal项我并没有调用remove，并非我忘了，而且我经过**“谨慎”**考虑，认为可以不清除，下次请求会给覆盖掉\n\n开发过程中一切正常，后来上线过程中，有个接口需要获取版本号做判断，这时前端有两个版本，分别是2.0.0和2.0.1。\n\n然后问题出现了，2.0.1的版本号判断正常，但是2.0.0的请求却出现了有时返回了2.0.1的判断逻辑。\n\n就是说，后端有时候把2.0.0当2.0.0本身处理，有时候又给当成2.0.1给处理。\n\n涉及的代码如下\n\n```java\n\n    @PostMapping(\"/audit_model\")\n    public R<Boolean> auditModel(HttpServletRequest request) {\n        return R.ok(auditModelService.auditModel(getVersion()));\n    }\n\n\n// getVersion() 是其父类中的方法，这里贴出父类的逻辑\n\n\n    /**\n     * request对象\n     */\n    private HttpServletRequest request;\n\n    /**\n     * response对象\n     */\n    private HttpServletResponse response;\n\n    /**\n     * 获取request\n     *\n     * @return\n     */\n    public HttpServletRequest getRequest() {\n        return request;\n    }\n\n    /**\n     * 获取response\n     *\n     * @return\n     */\n    public HttpServletResponse getResponse() {\n        return response;\n    }\n\n    @ModelAttribute\n    public void setReqAndResp(HttpServletRequest request, HttpServletResponse response) {\n        this.request = request;\n        this.response = response;\n    }\n\n\n    protected Version getVersion() {\n        return Version.convert(request.getHeader(\"x-api\"));\n    }\n\n```\n\n\n## 临时解决\n\n\n出了问题之后，我一看代码就发现了问题所在。\n\n\n问题出在 **ThreadLocal** 上，由于小版本号未清除，导致部分线程会保留小版本号，导致将2.0.0识别成2.0.1\n\n立马上线解决方案，涉及接口不使用枚举类，直接使用字符串，问题解决\n\n但是这个解决方案不够优雅，只是治标，只解决了这一个接口。其他接口如果有判断，还是会出错。\n\n另一个治本的方法是增加枚举类，把小版本号写上，但是这就违背了我的初衷。\n\n\n\n## 摸索治本方案\n\n首先为了测试bug是否给修复，我使用了一个jmeter脚本，方案是启动多个线程，每个线程内首先以**2.0.1**去多次请求接口，保证把线程的**ThreadLocal**小版本号给覆盖，然后以**2.0.0**去请求接口，确定是否会出现版本识别出错问题。多个线程并发，且都执行多次\n\n\n接着回滚临时解决方案，使用上面的脚本做测试，果然bug很轻易的就复现了，证明脚本逻辑正确。\n\n\n\n然后在**Version.convert**开头首先清理掉**ThreadLocal**，为了以防万一，再在拦截器的后置处理器里清理一遍。\n\n\n启动脚本，果然，bug很轻易地就解.....嗯？怎么还在？？\n\n\n缺了大德了，为什么没解决呢？？？\n\n算了，先打日志吧。\n\n我在接口里将获取到的版本号给输出给前端。代码如下\n\n```java\n    public R<Boolean> auditModel(HttpServletRequest request) {\n        return R.ok(data, MDC.get(\"traceId\") + \"  \" + Thread.currentThread().getName() + \"  \" + request.getHeader(\"x-api\") + \" \" + version.value() + \" \" + version);\n    }\n```\n\n另外为了确定请求来源，还使用了 **MDC** 来输出一个UUID来标记请求。这里不多赘述\n\n\n\n输出的错误情况就像这样\n\n```json\n{\n    \"msg\": \"d78d8911-a5d8-4451-84d1-894338b22959  http-nio-6784-exec-4  2.0.0 2.0.1 _latest\",\n    \"other\": null,\n    \"code\": 200,\n    \"data\": true\n}\n```\n\n可以看出，获取到的版本号还是不一致，明明已经清理了**ThreadLocal**。\n\n\n继续加日志，这次加在**Version.convert**方法里，记录一下传入的字符串类型版本号是多少\n\n\n结果出乎意料\n\n```\n\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.539 [http-nio-6784-exec-4] INFO  com.ruoyi.common.core.enums.Version - [convert,70] - 给的 api=2.0.0,结果= 2.0.0 _2_0_0\n\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.540 [http-nio-6784-exec-4] INFO  com.ruoyi.common.core.enums.Version - [convert,70] - 给的 api=2.0.0,结果= 2.0.0 _2_0_0\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.548 [http-nio-6784-exec-4] INFO  com.ruoyi.common.core.enums.Version - [convert,87] - 给的 api=2.0.1,结果= 2.0.1 _latest\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.548 [http-nio-6784-exec-4] DEBUG com.zfjs.app.mapper.AuditModelMapper.auditModel - [debug,137] - ==>  Preparing: select state from audit_model where version = ?\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.549 [http-nio-6784-exec-4] DEBUG com.zfjs.app.mapper.AuditModelMapper.auditModel - [debug,137] - ==> Parameters: 2.0.1(String)\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.552 [http-nio-6784-exec-4] DEBUG com.zfjs.app.mapper.AuditModelMapper.auditModel - [debug,137] - <==      Total: 1\n```\n\n\n枚举在同一个线程里接收到了**不同**的版本号，排查所有调用了**convert**方法的地方，最终怀疑是接口调用的**getVersion**方法内有问题\n\n\n调整接口如下:\n\n```java\n    public R<Boolean> auditModel(HttpServletRequest request) {\n        logger.info(\"req = {} -{}\",request.getHeader(\"x-api\"),getRequest().getHeader(\"x-api\"));\n        Version version = (getVersion());\n        Boolean data = auditModelService.auditModel(version);\n        return R.ok(data, MDC.get(\"traceId\") + \"  \" + Thread.currentThread().getName() + \"  \" + request.getHeader(\"x-api\") + \" \" + version.value() + \" \" + version);\n    }\n\n```\n\n\n结果出现了关键性日志\n\n```\nd78d8911-a5d8-4451-84d1-894338b22959 -19830284- 2022-06-29 10:14:44.546 [http-nio-6784-exec-4] INFO  com.zfjs.app.controller.app.v1.AppVersionController - [auditModel,49] - req = 2.0.0 -2.0.1\n```\n\n两个地方获取的版本号不一致，从最上面贴出的代码可以发现，**getVersion**里调用的**request**是通过**@ModelAttribute**注入的，是不是这个注解不是线程安全的？\n\n总之先替换掉**getVersion**方法之后，果然一切正常了。\n\n","tags":["并发","多线程","线程安全"],"categories":["后端","java","SpringBoot"]},{"title":"mysql利用索引排序使用条件","url":"/2022/06/24/74B8SN.html","content":"\n本以为排序使用索引是很简单的事情，直接加上就行了。结果实际测试下来问题还蛮多的\n\n<!-- more -->\n\n## 背景\n\n翻阅项目日志的时候，发现某条sql出现了 **Out of sort memory,  consider increasing server sort buffer size**。\n\n进一步排查发现，是该sql使用了文件排序(user filesort)导致的。\n\n这就很奇怪，本来给排序字段加了索引的，但是没有使用，先临时给一个 **force**\n\n\n## 环境\n\n本次实验使用的环境如下\n\n** mysql  Ver 15.1 Distrib 5.5.68-MariaDB, for Linux (x86_64) using readline 5.1  **\n\n使用的表结构如下，已去除部分无关字段\n\n```sql\n\n\nCREATE TABLE `advisory` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',\n  `column_id` bigint(20) NOT NULL,\n  `title` varchar(100) CHARACTER SET utf8mb4 NOT NULL ,\n  `content` text CHARACTER SET utf8mb4,\n  `state` tinyint(4) NOT NULL ,\n  `serial_number` varchar(15) CHARACTER SET utf8mb4 NOT NULL ,\n  `create_by` varchar(64) CHARACTER SET utf8mb4 DEFAULT '' ,\n  `create_time` datetime DEFAULT NULL COMMENT ,\n  `update_time` datetime DEFAULT NULL COMMENT ,\n  `remark` varchar(100) CHARACTER SET utf8mb4 DEFAULT NULL,\n  `comment_num` int(11) NOT NULL DEFAULT '0' ,\n  `ic_id` bigint(20) DEFAULT NULL COMMENT ,\n  PRIMARY KEY (`id`) USING BTREE,\n  KEY `idx_column` (`column_id`) USING BTREE,\n  KEY `idx_ic_id` (`ic_id`) USING BTREE,\n  KEY `idx_create_time` (`create_time`)\n) ENGINE=InnoDB AUTO_INCREMENT=1688151 DEFAULT CHARSET=utf8 COLLATE=utf8_bin ROW_FORMAT=DYNAMIC \n\n```\n\n\n\n测试sql如下\n\n```sql\n\nSELECT a.id,\n       a.author,\n       a.author_type,\n       a.ic_id,\n       a.create_by,\n       a.create_time,\n       a.update_time,\n       a.column_id,\n       a.content,\n       a.state\nFROM advisory a\norder by create_time\n\n```\n\n\n## 调试\n\n\n直接 explain 上面sql，extra直接写上**filesort**，同时执行的是全表扫描\n\n\n但是如果给加一个limit，例如 limit 10\n\nfilesort就消失不见，同时明确使用了**idx_create_time**索引。\n\n\n----------------\n\n\n再改造一下sql，去除其他select字段，只保留id字段\n\n```sql\n\nSELECT a.id\nFROM advisory a\norder by create_time\n\n```\n\n\nexplain 结果如下\n\n| id  | select_type | table | partitions | type   | possible_keys                    | key                              | key_len | ref                   | rows | filtered | extra         |\n| --- | ----------- | ----- | ---------- | ------ | -------------------------------- | -------------------------------- | ------- | --------------------- | ---- | -------- | ------------- |\n| 1   | SIMPLE      | a     |            | index  |                                  |   idx_create_time                |         |                       | 25   | 10       | Using index   |\n\n这回使用了索引。\n\n## 原理\n\n这样就能够猜测出一个大致的原因了。\n\n\n在查询了多余字段，且没有limit的情况下，mysql需要进行回表操作去获取其他字段的数据，这就导致mysql认为**全表扫描**比使用索引更加直接，全表扫描的副作用就是使用**filesort**\n\n在加上limit之后，由于回表数量大幅度减少，这时候使用索引就有价值了，也就没有filesort\n\n\n仅查询 id，也就是主键的情况叫做**覆盖索引**，意思是能够从索引中直接获取到需要的数据，不需要回表操作。\n\n本例中只能使用**id**字段，如果加上了别的字段，哪怕是有索引的字段，也会导致**filesort**\n\n这是因为在每一个索引中，都包括了主键字段和对应的索引字段。**idx_create_time**包括了**id**和**create_time**，而不包括别的字段\n","tags":["mysql","排序","索引"],"categories":["后端","数据库"]},{"title":"mysql优化","url":"/2022/06/21/F3R2NS.html","content":"\n一个小小的改动，优化掉Using temporary; Using filesort\n\n<!-- more -->\n\n## 问题\n\n项目开发过程中，发现某条sql出现了以下错误\n\n```\nOut of sort memory,  consider increasing server sort buffer size\n```\n\n错误原因是待排序的内容过大，导致 **buffer** 不够用\n\n其实以前就出过一次问题，当时给排序的 **create_time** 字段加上索引就解决了\n\n\n定位到问题sql如下\n\n```sql\n\nSELECT a.id\nfrom  a\n         LEFT JOIN  ac on a.column_id = ac.id\n         LEFT JOIN  ic ON a.ic_id = ic.id\nwhere not exists(select 1 from  gb where gb.type = 1 and gb.service_id = ac.id)\n  and a.`level` = 1\n  and a.state = 0\n  and ac.state = 1\norder by a.create_time desc\nlimit 1, 15;\n\n```\n\n## 排查\n\n首先对sql进行 **explain**，结果如下\n\n| id  | select_type | table | partitions | type   | possible_keys                    | key                              | key_len | ref                   | rows | filtered | extra                                        |\n| --- | ----------- | ----- | ---------- | ------ | -------------------------------- | -------------------------------- | ------- | --------------------- | ---- | -------- | -------------------------------------------- |\n| 1   | SIMPLE      | ac    |            | ALL    | PRIMARY                          |                                  |         |                       | 25   | 10       | Using where; Using temporary; Using filesort |\n| 1   | SIMPLE      | gb    |            | ref    | goods_bind_service_id_type_index | goods_bind_service_id_type_index | 14      | zfapp_app.ac.id,const | 1    | 100      | Using where; Not exists; Using index         |\n| 1   | SIMPLE      | a     |            | ref    | idx_column                       | idx_column                       | 8       | zfapp_app.ac.id       | 355  | 1        | Using where                                  |\n| 1   | SIMPLE      | ic    |            | eq_ref | PRIMARY                          | PRIMARY                          | 8       | zfapp_app.a.ic_id     | 1    | 100      |                                              |\n\n\n\n\n\n里面出现了非常可怕的 **Using temporary; Using filesort**\n\n另外出现的顺序也有点奇怪，我是以**a**表为主表，但是出现在第一项的是**ac**表\n\n\n## 解决\n\n在一点点的测试之后，终于找到了问题所在。\n\n将**where**之后的 **and ac.state = 1** 移到 **join**后面，最终sql如下\n\n```sql\n\nSELECT a.id\nfrom  a\n         LEFT JOIN  ac on a.column_id = ac.id  and ac.state = 1\n         LEFT JOIN  ic ON a.ic_id = ic.id\nwhere not exists(select 1 from  gb where gb.type = 1 and gb.service_id = ac.id)\n  and a.`level` = 1\n  and a.state = 0\norder by a.create_time desc\nlimit 1| 15;\n```\n\n再 explain一下\n\n\n| id  | select_type | table | partitions | type   | possible_keys                    | key                              | key_len | ref                   | rows | filtered | extra                                |\n| --- | ----------- | ----- | ---------- | ------ | -------------------------------- | -------------------------------- | ------- | --------------------- | ---- | -------- | ------------------------------------ |\n| 1   | SIMPLE      | a     |            | ref    | index                            | idx_create_time                  | 8       |                       | 12   | 1        | Using where; Backward index scan     |\n| 1   | SIMPLE      | ic    |            | eq_ref | PRIMARY                          | PRIMARY                          | 8       | zfapp_app.a.ic_id     | 1    | 100      |                                      |\n| 1   | SIMPLE      | ac    |            | eq_ref | PRIMARY                          |                                  | 8       | zfapp_app.a.column_id | 25   | 10       | Using where                          |\n| 1   | SIMPLE      | gb    |            | ref    | goods_bind_service_id_type_index | goods_bind_service_id_type_index | 14      | zfapp_app.ac.id,const | 1    | 100      | Using where; Not exists; Using index |\n\n结果正常了\n\n## 原理\n\n先随便猜测一下，对表的判断写在join里面，就只是对该表做回表，写在外面就是将两个表合并排序，问题很大\n\n","tags":["mysql","数据库","排序"],"categories":["后端","数据库"]},{"title":"swagger优雅显示枚举","url":"/2021/10/18/H1ZH22.html","content":"\n项目中使用到了swagger做文档，对于一些枚举值都是手动写的，比较死板。于是对swagger进行改造，更加友好的显示枚举\n\n<!-- more -->\n\n\n## 改动方向\n\n首先改动目标在两个地方：\n\n- 参数里的枚举\n- 返回model中的枚举\n\n## swagger原生显示效果\n\nswagger的**@ApiModelProperty**本身支持枚举，\n\n```java\n/**\n * Limits the acceptable values for this parameter.\n * <p>\n * There are three ways to describe the allowable values:\n * <ol>\n * <li>To set a list of values, provide a comma-separated list.\n * For example: {@code first, second, third}.</li>\n * <li>To set a range of values, start the value with \"range\", and surrounding by square\n * brackets include the minimum and maximum values, or round brackets for exclusive minimum and maximum values.\n * For example: {@code range[1, 5]}, {@code range(1, 5)}, {@code range[1, 5)}.</li>\n * <li>To set a minimum/maximum value, use the same format for range but use \"infinity\"\n * or \"-infinity\" as the second value. For example, {@code range[1, infinity]} means the\n * minimum allowable value of this parameter is 1.</li>\n * </ol>\n */\nString allowableValues() default \"\";\n```\n\n\n但是当我给一个Integer类型加上这个属性时，如下\n```java\n    @ApiModelProperty(value = \"测试\", allowableValues = \"1执行,2测试,3问题,4但是\")\n    private Integer demo;\n```\n\nweb界面上并没有出现枚举值，只有去掉非数字字符才会显示枚举值\n\n\n很明显，这种效果没多大意义，光有数值没有用\n\n\n## 自定义显示效果\n\n### 基本思路\n\nswagger中有个非常重要的类——`org.springframework.plugin.core.Plugin`，在这里接口下扩展出了若干种处理器\n\n\n\n这些处理器总体通过责任链模式调用，在此只需要关注两个类\n\n- `springfox.documentation.spi.schema.ModelPropertyBuilderPlugin`\n    > 负责解析 Model 类，其两个子类`ApiModelPropertyPropertyBuilder`和`XmlPropertyPlugin`分别处理`@ApiModelProperty`以及`@XmlElement`、`@XmlAttribute`\n- `springfox.documentation.spi.service.ExpandedParameterBuilderPlugin`\n    > 负责处理参数上的某一个非嵌套类型；同样两个子类，需要处理的是`springfox.documentation.spring.web.readers.parameter.ExpandedParameterBuilder`\n\n现在只需要提供两个类，覆盖上述类的逻辑即可。\n\n\n### 前期准备\n\n为了更友好的显示枚举，重点在两个方面：一个是需要自定义枚举代表的值，而不是直接使用其ordinal()或者name；其次是要文字说明枚举代表的意义\n\n因此，定义一个接口如下：\n\n```java\n\n\n/**\n * 枚举扩展\n */\npublic interface EnumDescription {\n    /**\n     * 枚举值可能并非使用序号，而是自定义code\n     *\n     * @return 实际使用的code值\n     */\n    int getCode();\n\n    /**\n     * 说明描述\n     *\n     * @return 描述文本\n     */\n    String getInfo();\n}\n\n```\n\n每个Enum需要继承该接口，并重写方法，例如以下例子：\n\n```java\n\n\n/**\n * 跳转类容\n */\npublic enum ContentTypeEnum implements EnumDescription {\n    ADVISORY(1, \"测试1\"),\n    GRAPHIC_LIVE(2, \"测试2\"),\n    ;\n    private final Integer code;\n    private final String info;\n\n    ContentTypeEnum(Integer code, String info) {\n        this.code = code;\n        this.info = info;\n    }\n\n    public static ContentTypeEnum valueOf(Integer code) {\n        for (ContentTypeEnum result : ContentTypeEnum.values()) {\n            if (result.code.equals(code)) {\n                return result;\n            }\n        }\n        return null;\n    }\n\n    @Override\n    public int getCode() {\n        return code;\n    }\n\n    @Override\n    public String getInfo() {\n        return info;\n    }\n}\n\n```\n\n\n在后续的逻辑中，类型判断就应该使用`EnumDescription`而非`Enum`了\n\n### 实现\n\n首先是处理Model的代码\n\n```java\n\nimport com.fasterxml.classmate.ResolvedType;\nimport com.google.common.base.Optional;\nimport com.ruoyi.common.core.enums.EnumDescription;\nimport io.swagger.annotations.ApiModelProperty;\nimport lombok.extern.slf4j.Slf4j;\nimport springfox.documentation.schema.Annotations;\nimport springfox.documentation.service.AllowableListValues;\nimport springfox.documentation.spi.DocumentationType;\nimport springfox.documentation.spi.schema.ModelPropertyBuilderPlugin;\nimport springfox.documentation.spi.schema.contexts.ModelPropertyContext;\nimport springfox.documentation.swagger.schema.ApiModelProperties;\n\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\n@Slf4j\npublic class EnumPropertyDisplayConfig implements ModelPropertyBuilderPlugin {\n\n    @Override\n    public void apply(ModelPropertyContext context) {\n        Optional<ApiModelProperty> annotation = Optional.absent();\n\n        if (context.getAnnotatedElement().isPresent()) {\n            annotation = annotation.or(ApiModelProperties.findApiModePropertyAnnotation(context.getAnnotatedElement().get()));\n        }\n        if (context.getBeanPropertyDefinition().isPresent()) {\n            annotation = annotation.or(Annotations.findPropertyAnnotation(\n                    context.getBeanPropertyDefinition().get(),\n                    ApiModelProperty.class));\n        }\n\n        final Class<?> rawPrimaryType = context.getBeanPropertyDefinition().get().getRawPrimaryType();\n        //过滤得到目标类型\n        if (annotation.isPresent() && EnumDescription.class.isAssignableFrom(rawPrimaryType)) {\n            log.info(\"des={}\", annotation.get().value());\n            //获取CodedEnum的code值\n            EnumDescription[] values = (EnumDescription[]) rawPrimaryType.getEnumConstants();\n            final List<String> displayValues = Arrays.stream(values).map(codedEnum -> codedEnum.getCode() + codedEnum.getInfo()).collect(Collectors.toList());\n            final AllowableListValues allowableListValues = new AllowableListValues(displayValues, rawPrimaryType.getTypeName());\n            //固定设置为int类型\n            final ResolvedType resolvedType = context.getResolver().resolve(int.class);\n            context.getBuilder().description(annotation.get().value() + \":\" + displayValues).type(resolvedType).allowableValues(allowableListValues);\n//            context.getBuilder().allowableValues(allowableListValues).type(resolvedType);\n        }\n    }\n\n    @Override\n    public boolean supports(DocumentationType documentationType) {\n        return true;\n    }\n}\n\n```\n\n---\n\n然后是覆盖参数的代码：\n\n```java\n\nimport com.fasterxml.classmate.ResolvedType;\nimport com.fasterxml.classmate.TypeResolver;\nimport com.google.common.base.Function;\nimport com.google.common.base.Optional;\nimport com.ruoyi.common.core.enums.EnumDescription;\nimport org.springframework.core.annotation.Order;\nimport springfox.documentation.schema.Enums;\nimport springfox.documentation.schema.ModelRef;\nimport springfox.documentation.schema.ModelReference;\nimport springfox.documentation.service.AllowableListValues;\nimport springfox.documentation.service.AllowableValues;\nimport springfox.documentation.spi.DocumentationType;\nimport springfox.documentation.spi.schema.EnumTypeDeterminer;\nimport springfox.documentation.spi.service.contexts.ParameterExpansionContext;\nimport springfox.documentation.spring.web.readers.parameter.ExpandedParameterBuilder;\n\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nimport static com.google.common.base.Strings.isNullOrEmpty;\nimport static com.google.common.collect.Lists.transform;\nimport static springfox.documentation.schema.Collections.*;\nimport static springfox.documentation.schema.Collections.isContainerType;\nimport static springfox.documentation.schema.Types.typeNameFor;\nimport static springfox.documentation.service.Parameter.DEFAULT_PRECEDENCE;\nimport static springfox.documentation.swagger.common.SwaggerPluginSupport.SWAGGER_PLUGIN_ORDER;\n\n@Order(SWAGGER_PLUGIN_ORDER + 1000)\npublic class EnumParamBuilderPlugin extends ExpandedParameterBuilder {\n    private final TypeResolver resolver;\n    private final EnumTypeDeterminer enumTypeDeterminer;\n\n    public EnumParamBuilderPlugin(TypeResolver resolver, EnumTypeDeterminer enumTypeDeterminer) {\n        super(resolver, enumTypeDeterminer);\n        this.resolver = resolver;\n        this.enumTypeDeterminer = enumTypeDeterminer;\n    }\n\n    @Override\n    public void apply(ParameterExpansionContext context) {\n        AllowableValues allowable = allowableValues(context.getFieldType().getErasedType());\n\n        String name = isNullOrEmpty(context.getParentName())\n                ? context.getFieldName()\n                : String.format(\"%s.%s\", context.getParentName(), context.getFieldName());\n\n        String typeName = context.getDataTypeName();\n        ModelReference itemModel = null;\n        ResolvedType resolved = resolver.resolve(context.getFieldType());\n        if (isContainerType(resolved)) {\n            resolved = fieldType(context).or(resolved);\n            ResolvedType elementType = collectionElementType(resolved);\n            String itemTypeName = typeNameFor(elementType.getErasedType());\n            AllowableValues itemAllowables = null;\n            if (enumTypeDeterminer.isEnum(elementType.getErasedType())) {\n                itemAllowables = Enums.allowableValues(elementType.getErasedType());\n                itemTypeName = \"int\";\n            }\n            typeName = containerType(resolved);\n            itemModel = new ModelRef(itemTypeName, itemAllowables);\n        } else if (enumTypeDeterminer.isEnum(resolved.getErasedType())) {\n            typeName = \"int\";\n        }\n        context.getParameterBuilder()\n                .name(name)\n                .description(null)\n                .defaultValue(null)\n                .required(Boolean.FALSE)\n                .allowMultiple(isContainerType(resolved))\n                .type(resolved)\n                .modelRef(new ModelRef(typeName, itemModel))\n                .allowableValues(allowable)\n                .parameterType(context.getParameterType())\n                .order(DEFAULT_PRECEDENCE)\n                .parameterAccess(null);\n    }\n\n    private Optional<ResolvedType> fieldType(ParameterExpansionContext context) {\n        return Optional.of(context.getFieldType());\n    }\n\n    @Override\n    public boolean supports(DocumentationType delimiter) {\n        return true;\n    }\n\n    private AllowableValues allowableValues(Class<?> fieldType) {\n\n        AllowableListValues allowable = null;\n        if (enumTypeDeterminer.isEnum(fieldType)) {\n            List<String> enumValues = getEnumValues(fieldType);\n            allowable = new AllowableListValues(enumValues, \"LIST\");\n        }\n\n        return allowable;\n    }\n\n    private List<String> getEnumValues(final Class<?> subject) {\n\n        if (EnumDescription.class.isAssignableFrom(subject)) {\n            EnumDescription[] enumConstants = (EnumDescription[]) subject.getEnumConstants();\n            return Arrays.stream(enumConstants).map(f -> f.getCode() + f.getInfo()).collect(Collectors.toList());\n        }\n        return transform(Arrays.asList(subject.getEnumConstants()), (Function<Object, String>) input -> input.toString());\n    }\n}\n\n```\n\n\n---\n\n\n然后将两个类注入\n\n```java\n    @Bean\n    public EnumPropertyDisplayConfig enumDisplayConfig() {\n        return new EnumPropertyDisplayConfig();\n    }\n\n    @Bean\n    public ExpandedParameterBuilder enumParamBuilderPlugin(TypeResolver resolver, EnumTypeDeterminer enumTypeDeterminer) {\n        return new EnumParamBuilderPlugin(resolver, enumTypeDeterminer);\n    }\n```\n\n\n需要注意的是，swagger默认的处理器在容器中依然存在，只是其执行结果被自定义的处理器覆盖了。\n\n另外，在注入参数处理器时，由于责任链中的处理器顺序问题，可能不会生效，因此需要`@Order`或者使用`Ordered`接口指定顺序为最末\n\n## 效果\n\n最终效果如下：\n\n![效果](https://article.biliimg.com/bfs/article/012b4ddbc13725626653bb7c1d2533dbc31ae1d9.png)\n\n\n\n以后如果有值变动，只需要修改枚举类即可，相关model直接使用Enum，只需要注明参数作用即可\n\n\n## 附\n\n同时可以对mybatis typehandler和jackson序列化做一下处理，实现代码中完全使用枚举类。因为前两者默认情况下都是使用的name，不一定符合实际情况\n\n## 2021-10-28 补充\n\n\n原本的参数显示效果很好，但是后来又发现了新的问题\n\n- 请求调试\n    > 直接在availableValues中写说明，会影响后面调试请求\n    > 这样类型不匹配，请求发不出去\n\n- 容器\n    > 当使用一个容器存储枚举时，当子项类型为int时，前端无法显示字符串的availableValues；\n\n----\n\n\n因此，availableValues还是使用int，文字说明改到description里\n\n解决思路有三种，一是继续在原本的`EnumParamBuilderPlugin`上修改；二是直接覆盖`SwaggerExpandedParameterBuilder`的逻辑；三是写一个`ExpandedParameterBuilderPlugin`只处理description部分\n\n这里我选择第三种方案\n\n新版代码如下:\n\n```java\n\nimport com.fasterxml.classmate.ResolvedType;\nimport com.fasterxml.classmate.TypeResolver;\nimport com.google.common.base.Function;\nimport com.google.common.base.Optional;\nimport com.ruoyi.common.core.enums.EnumDescription;\nimport io.swagger.annotations.ApiModelProperty;\nimport io.swagger.annotations.ApiParam;\nimport org.springframework.core.annotation.Order;\nimport springfox.documentation.spi.DocumentationType;\nimport springfox.documentation.spi.schema.EnumTypeDeterminer;\nimport springfox.documentation.spi.service.ExpandedParameterBuilderPlugin;\nimport springfox.documentation.spi.service.contexts.ParameterExpansionContext;\nimport springfox.documentation.spring.web.DescriptionResolver;\nimport springfox.documentation.swagger.common.SwaggerPluginSupport;\n\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nimport static com.google.common.collect.Lists.transform;\nimport static springfox.documentation.schema.Collections.*;\nimport static springfox.documentation.swagger.common.SwaggerPluginSupport.SWAGGER_PLUGIN_ORDER;\n\n@Order(SWAGGER_PLUGIN_ORDER + 1001)\npublic class EnumDescriptionExpandedParameterBuilder implements ExpandedParameterBuilderPlugin {\n    private final DescriptionResolver descriptions;\n    private final EnumTypeDeterminer enumTypeDeterminer;\n    private final TypeResolver resolver;\n\n    public EnumDescriptionExpandedParameterBuilder(\n            DescriptionResolver descriptions,\n            TypeResolver typeResolver,\n            EnumTypeDeterminer enumTypeDeterminer) {\n        this.resolver = typeResolver;\n        this.descriptions = descriptions;\n        this.enumTypeDeterminer = enumTypeDeterminer;\n    }\n\n    @Override\n    public void apply(ParameterExpansionContext context) {\n        Optional<ApiModelProperty> apiModelPropertyOptional = context.findAnnotation(ApiModelProperty.class);\n        if (apiModelPropertyOptional.isPresent()) {\n            fromApiModelProperty(context, apiModelPropertyOptional.get());\n        }\n        Optional<ApiParam> apiParamOptional = context.findAnnotation(ApiParam.class);\n        if (apiParamOptional.isPresent()) {\n            fromApiParam(context, apiParamOptional.get());\n        }\n    }\n\n    @Override\n    public boolean supports(DocumentationType delimiter) {\n        return SwaggerPluginSupport.pluginDoesApply(delimiter);\n    }\n\n    private void fromApiParam(ParameterExpansionContext context, ApiParam apiParam) {\n        context.getParameterBuilder()\n                .description(description(context, apiParam.value()));\n    }\n\n    private void fromApiModelProperty(ParameterExpansionContext context, ApiModelProperty apiModelProperty) {\n        context.getParameterBuilder()\n                .description(description(context, apiModelProperty.value()));\n    }\n\n    private String description(ParameterExpansionContext context, String value) {\n        value = descriptions.resolve(value);\n\n        //判断是否是枚举\n        ResolvedType resolved = this.resolver.resolve(context.getFieldType());\n        if (isContainerType(resolved)) {\n            resolved = fieldType(context).or(resolved);\n            ResolvedType elementType = collectionElementType(resolved);\n            if (enumTypeDeterminer.isEnum(elementType.getErasedType())) {\n                return value + \":\" + enumValues(elementType.getErasedType());\n            }\n        } else if (enumTypeDeterminer.isEnum(resolved.getErasedType())) {\n            return value + \":\" + enumValues(resolved.getErasedType());\n        }\n\n        return value;\n\n    }\n\n    private Optional<ResolvedType> fieldType(ParameterExpansionContext context) {\n        return Optional.of(context.getFieldType());\n    }\n\n    private List<String> enumValues(final Class<?> subject) {\n\n        if (EnumDescription.class.isAssignableFrom(subject)) {\n            EnumDescription[] enumConstants = (EnumDescription[]) subject.getEnumConstants();\n            return Arrays.stream(enumConstants).map(f -> f.getCode() + f.getInfo()).collect(Collectors.toList());\n        }\n        return transform(Arrays.asList(subject.getEnumConstants()), (Function<Object, String>) Object::toString);\n\n    }\n}\n```\n\n\n\n","tags":["java","文档","swagger"],"categories":["后端","java"]},{"title":"有限状态机解析json","url":"/2021/09/23/AS44AY.html","content":"\n前段时间看了篇博客，了解了有限状态机这么个概念。于是有了个想法想实验一下\n\n<!-- more -->\n\n### 基础知识\n\n\n首先一些基础概念可以参见[这篇博文](https://zhuanlan.zhihu.com/p/46347732)。\n\n状态机就是接收一个输入，根据输入决定下一个状态应该是什么，然后继续接收输入，判断状态是否正确。\n\n\n继续抽象输入为一个Token，状态机有一个初始状态。状态机每接收一个token，就判断是否符合期望，符合则转换到下一个状态。\n\n伪代码如下：\n\n```\n\nexpect_status = init_status;\n\nwhile (hasToken()){\n\n    if(token()==1){\n        if( expect_status == token_status){\n            expect_status = new_except_status;\n        }\n    }\n\n\n}\n\n```\n\n---\n\n回到json解析。\n\n首先我参考了[这篇博客](https://www.liaoxuefeng.com/article/994977272296736)\n\n\n文章中对于细节没有过多描述，我再做一些补充。\n\n### Token\n\ntoken代表一种输入，是对字符或者字节的抽象。token和状态并非一种固定的对应关系。\n\njson中可以定义token如下：\n\n- DOCUMENT_START,\n- DOCUMENT_END,\n- OBJECT_START,\n- OBJECT_END,\n- ARRAY_START,\n- ARRAY_END,\n- BOOLEAN,\n- SEP_COLON,\n- SEP_COMMA,\n- TEXT,\n- NUMBER,\n- NULL,\n- ILL, //非法\n\n### 状态\n\n为了编码方便，状态实际上是在指代期望的下一个状态。例如读取到一个 **\"** ，那期望就是一个字符串，当然这个字符串可能用在不同的位置，例如OBJECT-KEY，ARRAY-VALUE之类的\n\n\n可以定义状态如下\n\n- EXPECT_DOCUMENT_START\n- EXPECT_DOCUMENT_END\n- EXPECT_OBJECT_START\n- EXPECT_OBJECT_END\n- EXPECT_ARRAY_START\n- EXPECT_ARRAY_END\n- EXPECT_OBJECT_KEY\n- EXPECT_OBJECT_VALUE\n- EXPECT_ARRAY_VALUE\n- EXPECT_COMMA\n\n要注意，状态可能处于复合状态，同时期待多个状态，所以使用二的幂指数和位运算来处理状态\n\n### 实现\n\n最终实现位于[https://github.com/inkroom/json](https://github.com/inkroom/json)\n\n\n","tags":["json","状态机","算法"],"categories":["算法"]},{"title":"工具类设计的反面教材","url":"/2021/08/05/ZSZZ9T.html","content":"\n在维护公司交由外包团队开发的项目时，发现了一个redis操作类。里面的方法每一个都充满了不可思议，完全想不到的写法\n\n\n<!-- more -->\n\n\n话不多说，直接贴代码\n\n```java\n/**\n * \n * @Description: spring boot 的redis工具类\n */\n@SuppressWarnings(\"unchecked\")\n@Component\npublic class RedisUtil {\n    // 引入了两个template完全多余\n    @SuppressWarnings(\"rawtypes\")\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    @Autowired\n    private StringRedisTemplate stringRedisTemplate;\n \n    /**\n     * 批量删除对应的value\n     * \n     * @param keys\n     */\n    public void remove(final String... keys) {\n        for (String key : keys) {\n            /*\n            template完全支持批量删除，底下的方法就用到了，这里偏要一个一个删\n             */\n            remove(key);\n        }\n    }\n \n    /**\n     * 批量删除key\n     * \n     * @param pattern\n     */\n    public void removePattern(final String pattern) {\n        /*\n        暂且不提keys命令大量数据下不可用，ide都提示了可能存在空指针\n         */\n        Set<Serializable> keys = redisTemplate.keys(pattern);\n        if (keys.size() > 0)\n            redisTemplate.delete(keys);\n    }\n \n    /**\n     * 删除对应的value\n     * \n     * @param key\n     */\n    public void remove(final String key) {\n        /**\n         * 这里就完全想不通了，删除命令是有返回值的，删除一个不存在的key没有任何问题\n         */\n        if (exists(key)) {\n            redisTemplate.delete(key);\n        }\n    }\n \n    /**\n     * 判断缓存中是否有对应的value\n     * \n     * @param key\n     * @return\n     */\n    public boolean exists(final String key) {\n        /**\n         * hasKey返回的是包装类，这里唯一能想到的是给方法一个别名\n         */\n        return redisTemplate.hasKey(key);\n    }\n \n    /**\n     * 读取缓存\n     * \n     * @param key\n     * @return\n     */\n    public String get(final String key) {\n        /**\n         * 啊。。。这。。。。上面的StringRedisTemplate是拿来干嘛的？？而且怎么可能每次都new一个\n         */\n        Object result = null;\n        redisTemplate.setValueSerializer(new StringRedisSerializer());\n        ValueOperations<Serializable, Object> operations = redisTemplate.opsForValue();\n        result = operations.get(key);\n        if (result == null) {\n            return null;\n        }\n        return result.toString();\n    }\n \n    /**\n     * 写入缓存\n     * \n     * @param key\n     * @param value\n     * @return\n     */\n    public boolean set(final String key, Object value) {\n        // 这里只是写得啰嗦了一点，倒不是什么大问题\n        boolean result = false;\n        try {\n            ValueOperations<Serializable, Object> operations = redisTemplate.opsForValue();\n            operations.set(key, value);\n            result = true;\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return result;\n    }\n \n    /**\n     * 写入缓存\n     * \n     * @param key\n     * @param value\n     * @return\n     */\n    public boolean set(final String key, Object value, Long expireTime) {\n        // 但凡多按一个逗号，就知道一个命令就能搞定\n        boolean result = false;\n        try {\n            ValueOperations<Serializable, Object> operations = redisTemplate.opsForValue();\n            operations.set(key, value);\n            redisTemplate.expire(key, expireTime, TimeUnit.SECONDS);\n            result = true;\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return result;\n    }\n \n    public boolean hmset(String key, Map<String, String> value) {\n        boolean result = false;\n        try {\n            redisTemplate.opsForHash().putAll(key, value);\n            result = true;\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return result;\n    }\n \n    public Map<String, String> hmget(String key) {\n        Map<String, String> result = null;\n        try {\n            result = redisTemplate.opsForHash().entries(key);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return result;\n    }\n\n    public void setStr(final String key, final String value, final long expireTime) {\n        // 恭喜啊，又学到了新知识，学习速度不可想象啊。就是问一句工资是按代码行数算的嘛？\n        stringRedisTemplate.opsForValue().set(key, value, expireTime, TimeUnit.SECONDS);\n    }\n\n    public String getStr(final String key){\n        return stringRedisTemplate.opsForValue().get(key);\n    }\n\n    public void delStr(final String key){\n        // 对不起，我已经没话说了,只是希望早日治好失忆症\n        if(redisTemplate.hasKey(key)){\n            redisTemplate.delete(key);\n        }\n    }\n\n}\n \n```\n\n上面的代码充满了不可思议，写这代码的人一定有着多重人格。\n\n","tags":["redis","设计","反面教材"],"categories":["后端","java"]},{"title":"实现actuator访问安全","url":"/2021/07/23/2TE8ATE.html","content":"\nactuator被用于实现程序的监控，但是直接暴露相关接口非常危险，此处就需要探讨一下如何保证安全\n\n<!-- more -->\n\n## 危险来源\n\n在SpringCloud的常规架构中，使用Gateway对外暴露服务，其他服务由Gateway代为转发。再搭建Admin用于GUI展示，利用注册中心获取实例地址端口。\n\n一般情况下，只有Gateway会提供外网访问，其他微服务仅在内网访问，而Admin访问的时候也是获取的内网地址，比较安全。\n\n所以最危险的就是Gateway。\n\n\n最简单直接的安全方案，就是给Gateway加上Security，Admin访问的时候带上认证信息。\n\n但是该方案过于繁琐，不是很和我心意。\n\n\n经过一番搜索后，找到另一种方案，actuator支持使用别的端口。\n\n## 更换端口\n\n只需要如下配置\n\n```properties\nmanagement.server.port=2999\n```\n\n这样程序会使用两个端口，一个普通的请求端口，一个actuator使用的端口。\n\n但是，经过我的测试，实际上两个端口都能访问actuator，意思就是不管哪个端口，都可以访问**http://ip:port/actuator/health**等url。\n\n## 关闭普通端口访问\n\n既然新端口可以访问，那就把原本端口的相关路由给关闭了即可，给Gateway加入以下代码\n\n```java\n    @Bean\n    public RouteLocator locatorProd(RouteLocatorBuilder builder) {\n        //屏蔽监控端点\n        contract.route(\"actuator\", f -> f.path(\"/actuator/**\").filters(new Function<GatewayFilterSpec, UriSpec>() {\n            @Override\n            public UriSpec apply(GatewayFilterSpec gatewayFilterSpec) {\n                return gatewayFilterSpec.filter(new GatewayFilter() {\n                    @Override\n                    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n                        // 直接404\n                        ServerHttpResponse response = exchange.getResponse();\n                        response.setStatusCode(HttpStatus.NOT_FOUND);\n                        return response.writeWith(Mono.just(response.bufferFactory().wrap(\"404了\".getBytes(StandardCharsets.UTF_8))));\n                    }\n                });\n            }\n        }).uri(\"lb://404\"));//反正不会到后面，地址随便填一个就行\n        return contract.build();\n    }\n```\n\n这里使用了一个过滤器，直接返回404状态。\n\n## admin访问\n\n关闭的普通端口的访问，同时Admin那边也不能访问了，因为Admin还在访问原端口。\n\n在翻阅[admin文档](https://codecentric.github.io/spring-boot-admin/2.1.6/#_converting_serviceinstances)后，只要在注册中心中把使用的新端口带上即可。于是增加以下配置：\n\n```properties\neureka.instance.metadata-map.management.port=${management.server.port}\n```\n\n现在基本就可以正常访问了。但是我还想将这个新端口随机化，将来如果网关如果要更新，也能少设置一个端口，减少端口冲突的风险\n\n## 随机端口\n\n只需要**port=0**就是随机端口了。\n\n但是这又有一个新问题，由于配置文件将端口设置为0，那么注册中心记录的端口也还是0，admin就无法访问了。\n\n---\n\n解决思路是将端口的获取由代码完成，并且将端口写入配置项中。\n\n这里可以采用[jasypt](https://github.com/ulisesbocchio/jasypt-spring-boot)，这是一套主要用于配置项加密的库，但是两项功能没有本质区别。只需要实现一个自定义的解密器用来获取随机端口，后续的写入配置项操作就由库负责处理。\n\n---\n\n正如我之前不愿意引入security一样，引入[jasypt](https://github.com/ulisesbocchio/jasypt-spring-boot)也不和我心意。\n\n于是我自己琢磨出了一套方案，使用`EnvironmentPostProcessor`，实现方法如下：\n\n\n- 创建一个`EnvironmentPostProcessor`实现类，基本代码如下\n> ```java\n> public class PortEnvironmentPostProcessor implements EnvironmentPostProcessor {\n>     @Override\n>     public void postProcessEnvironment(ConfigurableEnvironment environment, S> pringApplication application) {\n>         Properties properties = new Properties();\n>         int availableTcpPort = SocketUtils.findAvailableTcpPort(6001, 12999);\n> \n>         properties.put(\"management.server.port\",availableTcpPort);\n>         properties.put(\"eureka.instance.metadata-map.management.port\",availableTcpPort);\n>         PropertiesPropertySource source = new PropertiesPropertySource(\"CONSUME\", properties);\n>         environment.getPropertySources().addFirst(source);\n>     }\n> }\n> \n> ```\n\n- 创建**META-INF/spring.factories**文件，内容如下\n> org.springframework.boot.env.EnvironmentPostProcessor=cn.inkroom.study.cloud.gateway.PortEnvironmentPostProcessor\n\n\n需要特别注明几点：\n\n- 是否覆盖原本配置文件中的某个配置项是有调用**addFirst**还是**addLast**方法决定的，越在前面的优先级越高\n- 默认情况下，自定义的`PortEnvironmentPostProcessor`总是在第一个被调用，因此无法获取其他配置项，意思是不能用于加解密，但是可以用于提供一些来自别的途径，较为动态的配置项\n\n\n\n----\n\n除了更换端口外，还可以更换context-path，但是我就没有再做测试了。\n\n\n\n","tags":["java","SpringCloud","安全"],"categories":["后端","java","SpringCloud"]},{"title":"Gateway中RouteDefinition如何创建","url":"/2021/07/21/2BR4GYX.html","content":"\n在Gateway中实现动态路由需要使用到一个RouteDefinition类，本文将探讨这个类该如何填充数据\n\n<!-- more -->\n\n## 序\n\n**RouteDefinition**是Gateway中用于存储路由元数据的类，其内可分为三部分：\n\n- 路由本身\n- 断言\n- 过滤器\n\n## 路由\n\n路由本身有三个数据：\n\n- `String id` 路由id，gateway中没有要求id唯一，只是一个便于定位和查看的标志\n- `URI uri` 要代理的url，支持服务发现就写成**lb://appName**\n- `int order` 顺序\n\n## 断言\n\n断言是存放在`ist<PredicateDefinition>`中，再查看`PredicateDefinition`的属性\n\n- `String name` 断言的名称，在内置的断言中，例如`HostRoutePredicate`，其name就**Host**\n- `Map<String, String> args` 这里是断言可能存在的参数，这里较为复杂，后续和过滤器一并解释\n\n## 过滤器\n\n过滤器存放在`List<FilterDefinition> filters`中，再查看`FilterDefinition`的属性\n\n- `String name` 过滤器的名称，在内置的过滤器中，例如`RemoveCachedBodyFilter`，其name就**RemoveCachedBody**\n- `Map<String, String> args` 这里是断言可能存在的参数，这里较为复杂，后续和过滤器一并解释\n\n注意，这里没有**order**属性，可见不支持排序\n\n## 参数注入\n\n在断言和过滤器中传递的参数解析涉及一个`org.springframework.cloud.gateway.support.ShortcutConfigurable.ShortcutType`的枚举类，其不同的枚举值代表不同的解析方式。\n\n比如`ShortcutType.GATHER_LIST`，其源码如下\n```java\nGATHER_LIST {\n    @Override\n    public Map<String, Object> normalize(Map<String, String> args,\n            ShortcutConfigurable shortcutConf, SpelExpressionParser parser,\n            BeanFactory beanFactory) {\n        Map<String, Object> map = new HashMap<>();\n        // field order should be of size 1\n        List<String> fieldOrder = shortcutConf.shortcutFieldOrder();\n        Assert.isTrue(fieldOrder != null && fieldOrder.size() == 1,\n                \"Shortcut Configuration Type GATHER_LIST must have shortcutFieldOrder of size 1\");\n        String fieldName = fieldOrder.get(0);\n        map.put(fieldName,\n                args.values().stream()\n                        .map(value -> getValue(parser, beanFactory, value))\n                        .collect(Collectors.toList()));\n        return map;\n    }\n},\n```\n\n可以看出这里不关心map中的key值，只把value值给转成一个list。\n\ngateway中断言和过滤器基本都是通过工程模式创建的，所以假设我需要找`HostRoutePredicate`的参数解析方式，那么就需要去看`HostRoutePredicateFactory`中的`public ShortcutType shortcutType()`方法\n\n\n除了查看枚举类以外，工厂类里面都有一个`Config`内部类，里面存放的就是解析完成的参数。此处以`RewritePathFilter`为例，查看复合参数应该怎么写。\n\n```java\npublic static final String REGEXP_KEY = \"regexp\";\npublic static final String REPLACEMENT_KEY = \"replacement\";\n\npublic RewritePathGatewayFilterFactory() {\n    super(Config.class);\n}\n\n@Override\npublic List<String> shortcutFieldOrder() {\n    return Arrays.asList(REGEXP_KEY, REPLACEMENT_KEY);\n}\n\npublic static class Config {\n    private String regexp;\n    private String replacement;\n\n}\n\n```\n\n注意`shortcutFieldOrder()`方法返回了一个包含参数key的list，我本以为这里代表args里的key，实际上只表示了将`FilterDefinition.arg`中的value对应key给替换掉，实际效果就是\n\n> _genkey_0=regex 替换后 regex=regex\n> _genkey_0=replacement 替换后 replacement=replacement\n\n\n所以我们只需要关心key的顺序就可以了。\n\n简单理解一下，虽然args是一个map，但是在实际用于构造前都是在当成一个List使用。\n\n----\n\n以下再提供一个样例\n\n```json\n\n[\n\t{\n\t\t\"id\": \"admin-server\",\n\t\t\"predicates\": [{\n\t\t\t\t\"name\": \"Path\",\n\t\t\t\t\"args\": {\n\t\t\t\t\t\"patterns\": \"/admin-server/**\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"Host\",\n\t\t\t\t\"args\": {\n\t\t\t\t\t\"1\": \"yapi.bcyunqian.com\",\n\t\t\t\t\t\"2\": \"yq.pre.bcyunqian.com\",\n\t\t\t\t\t\"3\": \"www.bcyunqian.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t],\n\t\t\"filters\": [{\n\t\t\t\t\"name\": \"PreserveHostHeader\",\n\t\t\t\t\"args\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"StripPrefix\",\n\t\t\t\t\"args\": {\n\t\t\t\t\t\"1\": \"1\"\n\t\t\t\t}\n\t\t\t}\n\t\t],\n\t\t\"uri\": \"lb://admin-server\",\n\t\t\"order\": 0\n\t},\n]\n\n```\n\n\n","tags":["java","SpringCloud","Gateway","动态路由"],"categories":["后端","java","SpringCloud"]},{"title":"网络小说的语法错误","url":"//novel-error.html","content":"\n网络小说门槛低了，同时水平也直线下降，像是文笔幼稚、行文底下、人物单薄、情节矛盾等问题层出不穷。在此我不讨论某本小说的问题，而是列举一些比较常见的语法错误。\n\n<!-- more -->\n\n## 序\n\n网络小说门槛低了，同时水平也直线下降，像是文笔幼稚、行文底下、人物单薄、情节矛盾等问题层出不穷。在此我不讨论某本小说的问题，而是列举一些比较常见的语法错误。\n\n## 标点符号\n\n### 冒号和双引号\n\n两个标点一般搭配起来用于人物说话、标志标语等情况。\n\n一般用法如下\n\n> 他说：“这事没法解决。”\n\n\n这点用法大家都懂，常见的错误是下面这种\n\n> \"这事没法解决。\"他伸出双手：“但是我可以给你想办法。”\n\n这里的问题出在冒号上。当一段话中间插入一段描写时，后面的引用不能以冒号开头，简言之，正确用法把冒号换成**逗号**\n\n> \"这事没法解决。\"他伸出双手，“但是我可以给你想办法。”\n\n另外还有一点就是，一般来说后引号前面一般使用句号、感叹号、问号这类表示一句话结束的标点，但是如果是上面这种情况，前半句话可以使用**逗号**结尾。\n\n\n## 词性\n\n多数形容词、名词都有褒义贬义中性区分。而网络小说就经常滥用词语，例如不区分人物立场，一律使用**诡计多端**来形容，反派没问题，但是正派就显得有问题了，一般情况就应该使用**足智多谋**。就算想要表示人物立场多变，正邪难定，也应该用中性词语。\n\n除了形容词外，名词也是一样的。就比如人物称谓。\n\n小品《主角与配角》里，扮演反派配角的陈佩斯有句台词“皇军托我给您带句话”，后面同样扮演反派配角的朱时茂台词却变成了“鬼子让我给你说”。\n\n看出问题了吧，人物立场决定了人物称谓，一般情况下没人会用蔑称称呼自己人。网络小说中一个错误就类似于所有侵华日军都管自己叫“鬼子”。\n\n这类词语很多，我这里简单列举一些\n\n> 下场 - 结局  \n> 团伙 - 团体  \n> 叛军 - 义军\n\n## 造词\n\n造词本身挺正常的，虽然我很不喜欢目前网络上的造词，缺乏生命力，都是活不了几天的垃圾词，但是造词是一门语言演化不可或缺的组成部分。然而网络小说中有种造词却是硬造词，例如**唯一**，不少小说都爱搞什么**唯二**、**唯三**，怎么不给唯一百啊，**仅有**这个词不会用嘛，还能帮你水字数呢\n\n","tags":["note"],"categories":["生活"]},{"title":"ClassLoader和双亲委派模型","url":"/2021/06/18/3V6FC1C.html","content":"\n\n这篇博客还是有些问题，一些逻辑还是没有理顺\n\n<!-- more -->\n\n## jdk中的ClassLoader\n\n在jdk9以前，jdk中有以下加载器\n\n![https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6544570c19724b618d0f72c5c2f8824d~tplv-k3u1fbpfcp-watermark.image](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6544570c19724b618d0f72c5c2f8824d~tplv-k3u1fbpfcp-watermark.image)\n\n\n- BootstrapClassLoader，又名根加载器，该加载器是由jvm实现，在jdk中不存在该类，负责加载存放在\n<JAVA_HOME>\\lib目录，或者被-Xbootclasspath参数所指定的路径中的class。同时，该加载器无法获取实例，所有该加载器加载的类的`getClassLoader()`方法都将返回**null**\n\n- ExtClassLoader，又名扩展加载器，负责加载<JAVA_HOME>\\lib\\ext以及java.ext.dirs内的类。该类存在于jdk中\n\n- AppClassLoader，负责加载由用户编写、不属于jdk的类，自定义加载器应该继承该类，并覆盖`findClass`方法\n\n## 双亲委派模型\n\njdk使用**双亲委派模型**来处理类加载流程。\n\n以用户编写的**Entry.class**为例，该类将会由**AppClassLoader**来负责加载。当其收到加载请求后，会先将请求交给其父类，也就是**ExtClassLoader**；扩展加载器再递交给根加载器，根加载尝试加载类，发现在其负责查找范围内没有该类，遂将请求返回给扩展加载器；扩展加载器同样无法加载，再返给应用加载器，最终由**AppClassLoader**完成加载\n\n---\n\n采用该模型主要是为了避免在内存中存在同一个类的不同实例，导致**instance**等语法出错。\n\n在这一模型下，类的访问范围被限制在当前加载器及其父加载器。由扩展加载器加载的类，可以访问其他由扩展加载的类以及由根加载器加载的类，但是不能访问应用加载器及其子加载器加载的类\n\n\n## jdk9以后的类加载器\n\njdk9以后采用了模块化方案，三级类加载器也有所变动\n\n![jdk9的类加载器](https://i.loli.net/2021/06/18/j7hfFy94C3RVALD.png)\n\n由于模块化设计，jdk目录也有所变化，不再有**ext**目录\n\n三个加载分别负责加载不同的模块，虽然仍然维持着三层类加载器和双亲委派的架构，但类加载的委派关系也发生了\n变动。当平台及应用程序类加载器收到类加载请求，在委派给父加载器加载前，要先判断该类是否能\n够归属到某一个系统模块中，如果可以找到这样的归属关系，就要优先委派给负责那个模块的加载器\n完成加载。\n\n顺便一提，BootstrapClassLoader也出现在了jdk中，但是依然无法获取实例\n\n## 类的隔离性\n\n**运行时包**\n\n每一个类都有一个运行时包的概念。和类所在包不同，运行时包包括了类加载器，基本结构如下\n\n> BootstrapClassLoader.ExtClassLoader.AppClassLoader.com.mysql.jdbc.Driver\n\n**初始类加载器**\n\njvm规范规定，在类的加载过程中，所有参与的类加载器，即使没有直接加载该类，都属于该类的初始类加载器\n\n\n---\n\n那么隔离性就由以下规则保证\n\n- 不同运行时包中的类不能互相访问\n- 有相同初始化类就行\n\n\n\n## 破坏双亲委派模型\n\n双亲委派模型是非强制性规范，同时受限于本身的设计，部分情况下得破坏模型。\n\n其中一种情况是**spi**，例如jdbc，接口以及接口的调用者为jdk中的类，但是实现由用户提供，二者处于不同的加载器中，按照双亲委派模型就无法运行。\n\njdk提供了**线程上下文类加载器（Thread Context ClassLoader）**。这个类加载器可以通过java.lang.Thread类的setContext-ClassLoader()方\n法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内\n都没有设置过的话，那这个类加载器默认就是应用程序类加载器。\n\n\n在**SPI**机制中，需要由接口提供方自动发现注册接口实现。在jdbc中，最重要的**DriverManger**使用**PlatformClassLoader**加载的，在其内部去加载某个实现类，如果不提供别的途径的话，**DriverManger**只能使用**PlatformClassLoader**，那就无法加载实现方了。\n\n因此提供一个线程上下文类加载器，**DriverManger**就能拿到可以加载实现方的类加载器了，这一过程也破坏了双亲委派模型\n\n\njdk主要是因为核心库和用户代码加载器不同，才需要一个线程上下文类加载器。假设我们需要一个spi机制，反倒不需要这么麻烦。\n","tags":["java","ClassLoader","editing"],"categories":["后端","java"]},{"title":"设计模式","url":"/2021/06/13/V4XA6C.html","content":"\n<!-- more -->\n\n\n### 三种工厂模式\n\n- 简单工厂\n    > 一般基于static方式实现，扩展性不足\n- 工厂\n    > 抽象了工厂和产品，但是一个工厂只能生产一种产品\n- 抽象工厂\n    > 和普通工厂不同在于抽象工厂有多个生产方法，可以生产多种产品，实现更复杂的组合\n\n### 建造者模式（Bulider模式）\n\n和普通的new方法相比，在对象的创建上更为灵活，可以根据不同情况跳过步骤，组合不同的参数。\n\n例如某个类有三个成员变量，根据需要的成员不同，提供了不同参数的方法重载。\n\n使用的时候可能会出现根据不同条件提供不同的参数，在new方式下就是许多的new，且参数可能反复填写\n\n```java\nif(条件1){\n    new Class(参数1,参数2)\n}else if(条件2){\n    new Class(参数1,参数3)\n}else if(条件3){\n    new Class(参数1,参数2,参数3)\n}\n```\n\n建造者模式下\n\n```java\nbuilder.参数1();\nif(条件2){\n    builder.参数2();\n}\nif(条件3){\n    builder.参数3();\n}\nbuilder.build();\n\n```\n\n可以看出步骤的省略更为明显\n\n\n### 命令模式\n\n将原本具体的逻辑抽象成一个个命令，用命令对象隔离调用和实现。例如之前的博客[解析yml]() 中就有**Event**类，可以看作是命令模式的一种实现\n\n\n\n\n","tags":["设计模式"],"categories":["后端"]},{"title":"CAS与VarHandle","url":"/2021/06/13/1ST875F.html","content":"\n现在java中多使用cas来实现无锁化\n\n<!-- more -->\n\n\n## 定义\n\nCAS(Compare and Swap)，如果原始值和给定值相同，则修改为新值，否则失败\n\n## 使用\n\n借助java9推出的**VarHandle**实现cas操作\n\n`VarHandle`通过以下方法获取\n```java\nMethodHandles.lookup().findVarHandle(CASExample.class, \"x\", int.class)\n```\n\n三个参数依次代表:\n\n- CASExample.class 需要操作的变量所在的类\n- x 变量的名字，在此处就是变量在CASExample中的名字\n- int.class 变量的类型\n\n调用如下:\n```java\nVarhandle.compareAndSet(example, 0, 1)\n```\n\n第一个参数是`CASEXample`的实例，第二次参数是期望值，第三个参数就想要设置的新值\n\n\n\n\n样例如下\n\n```java\npublic class CASExample {\n\n    private volatile int x = 0;\n\n    public static void main(String[] args) {\n        try {\n            VarHandle xVarhandle = MethodHandles.lookup().findVarHandle(CASExample.class, \"x\", int.class);\n\n            CyclicBarrier barrier = new CyclicBarrier(2);\n\n            CASExample example = new CASExample();\n\n\n            for (int i = 0; i < 2; i++) {\n                new Thread(new Runnable() {\n                    @Override\n                    public void run() {\n                        try {\n                            barrier.await();\n                            while (true) {\n                                if (xVarhandle.compareAndSet(example, 0, 1)) {\n                                    break;\n                                }\n                            }\n                            System.out.println(Thread.currentThread().getName() + \"设置完成\" + example.x);\n                        } catch (InterruptedException e) {\n                            e.printStackTrace();\n                        } catch (BrokenBarrierException e) {\n                            e.printStackTrace();\n                        }\n\n\n                    }\n                }).start();\n            }\n\n\n        } catch (NoSuchFieldException e) {\n            e.printStackTrace();\n        } catch (IllegalAccessException e) {\n            e.printStackTrace();\n        }\n\n    }\n\n}\n```\n\n输出一个1,同时cpu占有率开始上升，很明显是另一个线程死循环导致的\n\n\n---\n\n\n注意，我用的是**openjdk11**，jdk中存在两个Unsafe，分别是**sun.misc.Unsafe**和**jdk.internal.misc.Unsafe**，这里使用第二个\n\n\n### 原子类\n写一个原子类试一下\n\n```java\n\npublic class AtomicInt {\n\n    private volatile int value;\n    private VarHandle handle;\n\n    public AtomicInt() {\n        try {\n            value = 0;\n            handle = MethodHandles.lookup().findVarHandle(AtomicInt.class, \"value\", int.class);\n        } catch (NoSuchFieldException e) {\n            e.printStackTrace();\n        } catch (IllegalAccessException e) {\n            e.printStackTrace();\n        }\n\n    }\n\n\n    public boolean add() {\n        while (true) {\n            int v = value;\n            if (handle.compareAndSet(this, v, v + 1)) {\n                return true;\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        int threadCount = 100;\n        int count = 1000;\n        CountDownLatch latch = new CountDownLatch(threadCount);\n\n        AtomicInt atomicInt = new AtomicInt();\n\n        for (int i = 0; i < threadCount; i++) {\n            new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    for (int j = 0; j < count; j++) {\n                        atomicInt.add();\n                    }\n                    latch.countDown();\n                }\n            }).start();\n        }\n        try {\n            latch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(atomicInt.value);\n    }\n\n}\n```\n\n\n\n结果是100000，正确\n\n\n\n### ABA问题\n\nABA是指数据由A->B->A的转换，CAS会误以为没有变化。JDK提供了`AtomicStampedReference`和`AtomicMarkableReference`来解决。\n\n\n","tags":["java","并发","多线程"],"categories":["后端","java","concurrent"]},{"title":"HashMap和ConcurrentHashMap","url":"/2021/06/11/1YWY0TA.html","content":"\n关于HashMap和ConcurrentHashMap的一些记录\n\n<!-- more -->\n\n### HashMap\n\n`HashMap`基本结构是数组+单向链表/红黑树。\n\nmap有几个比较重要的变量\n\n- DEFAULT_INITIAL_CAPACITY 默认初始容量，16\n- DEFAULT_LOAD_FACTOR 默认负载因子0.75，用在扩容上\n- TREEIFY_THRESHOLD 转换成红黑树的链表长度 8\n- UNTREEIFY_THRESHOLD 由树转换成链表的长度，6\n- MIN_TREEIFY_CAPACITY 转换成红黑树的数组的最小长度 64，如果某链表长度大于8，但是此时数组长度不够，则只会扩容，不会转换\n\n贴出openjdk11里的put方法\n```java\n  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n        Node<K,V>[] tab; Node<K,V> p; int n, i;\n        if ((tab = table) == null || (n = tab.length) == 0)//当前数组未创建\n            n = (tab = resize()).length;\n        if ((p = tab[i = (n - 1) & hash]) == null)//对应的节点不存在\n            tab[i] = newNode(hash, key, value, null);\n        else {\n            Node<K,V> e; K k;\n            if (p.hash == hash &&\n                ((k = p.key) == key || (key != null && key.equals(k))))//hash碰撞，且当前的key和数组对应位置相同\n                e = p;\n            else if (p instanceof TreeNode)//当前节点是一颗树\n                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else {//链表结构，则遍历到尾结点\n                for (int binCount = 0; ; ++binCount) {\n                    if ((e = p.next) == null) {\n                        p.next = newNode(hash, key, value, null);\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            treeifyBin(tab, hash);//节点过长，转换成红黑树，注意，方法内部还判断了当前数组长度要大于MIN_TREEIFY_CAPACITY\n                        break;\n                    }\n                    if (e.hash == hash &&\n                        ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        if (++size > threshold)//扩容\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n\n---\n\n再看扩容算法\n\n```java\n\nfinal Node<K,V>[] resize() {\n        Node<K,V>[] oldTab = table;\n        int oldCap = (oldTab == null) ? 0 : oldTab.length;\n        int oldThr = threshold;\n        int newCap, newThr = 0;\n        if (oldCap > 0) {\n            if (oldCap >= MAXIMUM_CAPACITY) {\n                threshold = Integer.MAX_VALUE;\n                return oldTab;\n            }\n            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n                     oldCap >= DEFAULT_INITIAL_CAPACITY)\n                     // 直接扩充一倍，为原有容量的两倍，同时阈值也变成两倍\n                newThr = oldThr << 1; // double threshold\n        }\n        else if (oldThr > 0) // initial capacity was placed in threshold\n            newCap = oldThr;\n        else {               // zero initial threshold signifies using defaults\n            newCap = DEFAULT_INITIAL_CAPACITY;\n            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n        }\n        if (newThr == 0) {\n            float ft = (float)newCap * loadFactor;\n            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                      (int)ft : Integer.MAX_VALUE);\n        }\n        threshold = newThr;\n        @SuppressWarnings({\"rawtypes\",\"unchecked\"})\n        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];\n        table = newTab;\n        if (oldTab != null) {\n            for (int j = 0; j < oldCap; ++j) {\n                Node<K,V> e;\n                if ((e = oldTab[j]) != null) {\n                    oldTab[j] = null;\n                    if (e.next == null)//没有链表或者树结构.尽量保持索引不变\n                        newTab[e.hash & (newCap - 1)] = e;\n                    else if (e instanceof TreeNode)\n                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n                    else { // preserve order 把链表中的元素给重新散列到数组里\n                        Node<K,V> loHead = null, loTail = null;\n                        Node<K,V> hiHead = null, hiTail = null;\n                        Node<K,V> next;\n                        do {\n                            next = e.next;\n                            if ((e.hash & oldCap) == 0) {//新的坐标不变\n                                if (loTail == null)\n                                    loHead = e;\n                                else\n                                    loTail.next = e;\n                                loTail = e;\n                            }\n                            else {//新的坐标为原有坐标+原table长度\n                                if (hiTail == null)\n                                    hiHead = e;\n                                else\n                                    hiTail.next = e;\n                                hiTail = e;\n                            }\n                        } while ((e = next) != null);\n                        if (loTail != null) {\n                            loTail.next = null;\n                            newTab[j] = loHead;\n                        }\n                        if (hiTail != null) {//将原本的尾结点给散列到新的数组中去，不再作为链表中的节点\n                            hiTail.next = null;\n                            newTab[j + oldCap] = hiHead;\n                        }\n                    }\n                }\n            }\n        }\n        return newTab;\n    }\n```\n\n---\n\n此外还有一些细节\n\n- 初始容量不为2的n次幂的，会向上调整为最近的2次幂，同时由于扩容都是翻两倍，所以容量始终的2的n次幂\n\n- 扩容的阈值=容量*负载因子。只要当前数据量大于这个值就会触发扩容。假设现在有1000个数据，容量应该是2048，因为1024*0.75=768触发扩容，但是这样会浪费很多空间，可以通过吧负载因子设置为1来避免，\n\n- HashMap线程不安全体现在会造成死循环、数据丢失、数据覆盖这些问题。其中死循环和数据丢失是在JDK1.7中出现的问题，在JDK1.8中已经得到解决，然而1.8中仍会有数据覆盖这样的问题\n    > 在扩容时，先将数组设置为两倍大小的空数组，这时线程挂起，同时其他线程插入数据，再回来继续散列，数据可能就被覆盖了\n\n### ConcurrentHashMap\n\n1.7 的并发安全是通过**Segment**分段加锁实现的。1.8则使用了CAS+synchronized来实现\n\n以下是openjdk11里的代码\n\n直接看put方法\n```java\n    final V putVal(K key, V value, boolean onlyIfAbsent) {\n        if (key == null || value == null) throw new NullPointerException();\n        int hash = spread(key.hashCode());\n        int binCount = 0;\n        for (Node<K,V>[] tab = table;;) {\n            Node<K,V> f; int n, i, fh; K fk; V fv;\n            if (tab == null || (n = tab.length) == 0)\n                tab = initTable();\n            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {\n                if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))\n                    break;                   // no lock when adding to empty bin\n            }\n            else if ((fh = f.hash) == MOVED)\n                tab = helpTransfer(tab, f);\n            else if (onlyIfAbsent // check first node without acquiring lock\n                     && fh == hash\n                     && ((fk = f.key) == key || (fk != null && key.equals(fk)))\n                     && (fv = f.val) != null)\n                return fv;\n            else {\n                V oldVal = null;\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {\n                        if (fh >= 0) {\n                            binCount = 1;\n                            for (Node<K,V> e = f;; ++binCount) {\n                                K ek;\n                                if (e.hash == hash &&\n                                    ((ek = e.key) == key ||\n                                     (ek != null && key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)\n                                        e.val = value;\n                                    break;\n                                }\n                                Node<K,V> pred = e;\n                                if ((e = e.next) == null) {\n                                    pred.next = new Node<K,V>(hash, key, value);\n                                    break;\n                                }\n                            }\n                        }\n                        else if (f instanceof TreeBin) {\n                            Node<K,V> p;\n                            binCount = 2;\n                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                        else if (f instanceof ReservationNode)\n                            throw new IllegalStateException(\"Recursive update\");\n                    }\n                }\n                if (binCount != 0) {\n                    if (binCount >= TREEIFY_THRESHOLD)\n                        treeifyBin(tab, i);\n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        addCount(1L, binCount);\n        return null;\n    }\n```\n\n基本遵循以下逻辑\n\n- 计算hash，开始循环\n- 如果现在没有数据，则初始化一个table\n- 如果此时对应位置上没有数据，那么就尝试cas设置新值。设置不成功则开始自旋设置，直到当前线程设置成功，或者别的线程设置成功，则当前线程判断有值，不再进行cas\n- 有个**onlyIfAbsent**暂时不知道干嘛的，但是一般这个参数都为false，相应分支不会执行\n- 当当前位置有值，则开始追加数据，此时对这个节点加锁。这样加锁粒度比**HashTable**加在整个对象上要更小\n- 循环结束后，增加总数。这边也是CAS+自旋逻辑\n\n---\n\nConcurrentHashMap中有个非常重要的变量`sizeCtl`\n\n```java\nprivate transient volatile int sizeCtl;\n```\n当这个值为负数时，代表正在进行初始化或者扩容操作。-1代表初始化，-(1+参与扩容的线程数)代表正在扩容\n\n初始化\n\n初始化操作仅允许一个线程进行。在方法`initTable`中，如果发现`sizeCtl`是-1，则使用`Thread.yield()`让出cpu时间。注意：这种让渡是提示性的，而非强制，所以此处可能也会进行自旋等待初始化线程结束初始化，当前线程直接判断table不为null\n\n\n\n\n\n---\n\n总结：如果节点位置没有值，就用cas设置；有值，就对节点加锁。抛弃了Segment，但是相关的类还保留在源代码里，不知道为什么不删\n\n","tags":["java","并发","HashMap"],"categories":["后端","java","concurrent"]},{"title":"redis过期和内存淘汰策略","url":"/2021/06/10/SJBJBC.html","content":"\n关于redis的过期和内存淘汰策略的笔记。集合了官方文档，网络资源和实体书里的内容\n\n\n<!-- more -->\n\n## 内存淘汰策略\n\n内存淘汰是用于内存不足时淘汰数据使用\n\n\n### 可以使用多大内存\n\nredis通过以下配置决定内存使用量\n\n```redis\nmaxmemory 100mb\n```\n\n可以在配置文件中注明，也可以在运行时通过`config`命令指定\n\n如果设置为**0**，在64位系统上是无限制，就是可以使用所有的物理内存，在32位系统上最多使用3GB\n\n\n\n### 什么时候淘汰内存\n\nredis遵循以下逻辑\n\n- 客户端发送一个命令，该命令会导致内存占用增加\n- redis检查当前剩余内存是否够执行该命令，如果不够，则执行淘汰策略\n- redis执行命令，返回结果\n\n### 有哪些淘汰策略\n\n在4.0以后的版本中，有以下策略\n\n- **noeviction**: 可能导致内存增加的命令直接返回错误，所以不包括**del**和一些其他命令\n- **allkeys-lru**: 按照最近最少使用算法淘汰，淘汰范围为所有的key\n- **volatile-lru**: 按照最近最少使用算法淘汰，淘汰范围为设置了过期时间的key\n- **allkeys-random**: 随机淘汰，淘汰范围为所有的key\n- **volatile-random**: 随机淘汰，淘汰范围为设置了过期时间的key\n- **volatile-ttl**: 淘汰ttl最短的key\n- **volatile-lfu**: 按照最少访问频率淘汰，淘汰范围为设置了过期时间的key\n- **allkeys-lfu**: 按照最少访问频率淘汰，淘汰范围为所有的key\n\n\n可以按照以下方式记忆：\n\nredis淘汰策略有：**不淘汰**、**最近最少使用(lru)**、**随机淘汰**、**最短过期时间(ttl)**、**最少访问频率(lfu)**。\n\n除了**不淘汰**和**ttl**，剩下的又有两种分类，**所有的key**(allkeys)、**有过期时间的key**(volatile)\n\n---\n\n其中**noeviction**是默认的淘汰策略，同时如果其他淘汰策略无法淘汰合适的内存大小，也会进入该模式\n\n### 如何选择淘汰策略\n\n- 如果你不知道怎么选，直接使用**allkeys-lru**。这是官方推荐的策略（This is a good pick if you are unsure）。\n\n- 如果所有的key都会被持续地、周期性地被访问，或者你希望分布是均匀的（所有的节点都有相同的访问概率）。这里应该是想说数据没有热点，那就使用**allkeys-random**\n\n- 当你创建缓存对象的时候，你可以通过不同的ttl告诉redis哪些数据更应该被淘汰，这时使用**volatile-ttl**\n\n### LRU如何工作\n\nredis的LRU不是标准的lru，而是一种近似算法。\n\n基本原理是，在每个key中记录最后一次访问时间，然后每次随机选出**N**个key，把**N**个key中访问时间最小的淘汰。\n\n其中取样个数**N**可通过`CONFIG SET maxmemory-samples <count>`或者配置文件中配置。\n\n官网的例子是如果取样是**10**，那么就非常接近标准LRU算法了\n\n\n### LFU如何工作\n\n**LRU**仅按照最后一次访问时间作为判断标准，对于部分情况是不够准确的。\n\n> 假设有个key实际上很少使用，但就在淘汰开始前突然被访问了一次，那么LRU不会淘汰这个key。这里潜藏的风险就是很可能删除了一个当时暂时未被访问，但是以后可能会被高频访问的数据。\n\n以上是对官方文档的不标准翻译\n\n---\n\n**LFU**使用**8位**来记录访问频率。为了实现如此少的位保存足够高的频率，redis使用了一种叫做**Morris counter**的算法，具体原理暂时不去深究。\n\nredis提供了两个配置项来调整LFU算法\n\n```redis\nlfu-log-factor 10\nlfu-decay-time 1\n```\n\n**decay-time** 意为衰退时间，如果不做衰退处理，频率记录只会越来越高，直到上限。文档特别指出不要把这个值设置为0\n\n**log-factor** 这个值用来限定能够记录的最高频率。redis只用了8位记录频率，那么最高就是255，当访问频率高到一定程度后，频率记录就始终是255,分辨不出高低了。这个值越高，**一定程度**就会越高。官方给了一个表\n\n| factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits |\n| ------ | -------- | --------- | --------- | ------- | -------- |\n| 0      | 104      | 255       | 255       | 255     | 255      |\n| 1      | 18       | 49        | 255       | 255     | 255      |\n| 10     | 10       | 18        | 142       | 255     | 255      |\n| 100    | 8        | 11        | 49        | 143     | 255      |\n\n\n## 过期策略\n\nredis过期策略有两种：懒删除和定时扫描。官方称其为**passive way**、**active way**\n\n### 懒删除\n\n每次访问key时，判断key是否已经过期，过期了就删除\n\n### 定时扫描\n\nredis将会每秒进行10次扫描，每次扫描按照以下流程\n\n- 从过期字典(记录了所有设置了过期时间的key)中随机挑选20个key\n- 删除其中过期的key\n- 如果过期的数据占据了25%，那么重复步骤1\n\n--- \n\n除了官网内容外，书中还提及redis为了防止过度扫描，规定了一次扫描不能超过25毫秒，这25毫秒内是停止服务的。此外扫描还可能由于内存回收导致卡死。\n\n因此如果发生了**缓存雪崩**，除了请求击穿到数据库外，redis本身也可能出现一定程度的卡顿\n\n### 从节点和AOF\n\n当有key过期时，redis会写入一条**DEL**命令，这个命令会被写入AOF文件以及发送给从节点。所以从节点不会主动进行过期处理，全部依赖主节点的同步\n\n\n## 参考文件\n\n- [官方文档](https://redis.io/topics/lru-cache)\n- [https://www.jianshu.com/p/c8aeb3eee6bc](https://www.jianshu.com/p/c8aeb3eee6bc)","tags":["后端","redis"],"categories":["后端","redis"]},{"title":"bean的创建流程","url":"/2021/06/09/16VTBQC.html","content":"\nbean在spring中的生命周期\n\n<!-- more -->\n\n\n## 使用\n\n以下为一个bean的获取并使用流程\n\n```java\n\nDefaultListableBeanFactory factory = new XmlBeanFactory(new ClassPathResource(\"bean.xml\"));\nObject bean = factory.getBean(\"bean\");\nbean.toString();\n```\n\n## 流程\n\n- 首先是加载配置信息，这一步在`XmlBeanFactory`创建出来之后就完成了。在其中保存了bean的相关信息，比如id、name、类型、构造方法参数等等\n- getBean方法中去真正创建bean\n- 如果是单例模式，且缓存中有这个bean，就直接返回。没有则进行下一步\n- 对**Prototypre**模式的做循环依赖检查\n- 如果有父**Factory**，且当前工厂没有这个bean的配置信息，则交给父类工厂创建。在ssm模式中一般存在两个容器：Spring和SpringMVC，应该就是这种关系，确保MVC容器可以访问父类容器的bean\n- 查找依赖，这一步也会进行循环依赖检查。有依赖的情况下，就开始递归创建依赖bean\n- 根据不同的**scope**开始创建流程，在此暂时只讨论**singleton**类型的bean，也就是`getSingleton(String beanName, ObjectFactory<?> singletonFactory)`\n    \n    - 首先会将当前beanName添加到`singletonsCurrentlyInCreation`\n    - 调用`AbstractAutowireCapableBeanFactory#createBean`方法\n    - **BeanPostProcessors**会被调用，可以用来创建代理，然后直接返回\n    - 如果没有代理，则进入Spring的创建方法**doCreateBean**\n    - 再然后就是根据配置信息，决定用哪种实例化方案\n    - 当实例创建后，就会根据条件决定放不放入`singletonObjects`，同时从`earlySingletonObjects`中清除\n    - 再然后的方法`getEarlyBeanReference`说是可以注入aop，但是暂时没有找到相关代码\n- 接着开始注入属性，，一般来说就是通过name、type注入；如果有循环依赖的话，就去缓存里获取半成品bean\n- 初始化bean，一般就是调用一些相关方法，比如`init-method`，继承的接口，以及一些`BeanPostProcessor`\n- 注册销毁处理器，销毁时调用相关方法\n- 最后通过一个`getObjectForBeanInstance`来处理一些诸如**factory-bean**类型，获取真正的bean\n\n\n\n## ApplicationContext\n\n实际开发中，基本不会用`BeanFactory`的方式，都是使用`ApplicationContext`。这里已`ClassPathXmlApplicationContext`为例\n\n- 检查当前环境，例如判断是否有环境变量未设置\n- 创建beanFactory\n- 注册激活BeanFactory处理器，例如注入后置处理器，事件监听器\n- 初始化所有单例bean\n- 事件通知\n\n--- \n\n再配上一张SpringMVC流程图\n\n![SpringMVC流程](https://images2018.cnblogs.com/blog/733213/201804/733213-20180401021502228-788157259.jpg)\n\n## 参考资料\n\n[请别再问Spring Bean的生命周期了！](https://www.jianshu.com/p/1dec08d290c1)","tags":["java","Spring"],"categories":["后端","java","SpringBoot"]},{"title":"ThreadLocal","url":"/2021/06/05/AHYH5E.html","content":"\n本文将解释ThreadLocal的原理\n\n<!-- more -->\n\n\n## 结构\n\n**ThreadLocal** 本质是给每一个线程绑定一个map，以线程名为key\n\n线程和ThreadLocal的关系如下：\n\n![](https://i.loli.net/2021/06/05/wLzsQg6xHGDk21R.png)\n\n每一个线程都有一个**ThreadLocalMap**属性，该属性存有**Entry**数组，通过对**threadLocalHashCode**取模，得到下标索引。\n\n## 内存泄漏\n\n**ThreadLocalMap**是通过Thread访问的，同时还是**default**权限，如果Thread结束了，那么这一部分数据将用于无法被访问。如果Thread的实例还被保存着，那么这一部分数据就有泄漏的风险。\n\n---\n\n为了解决这一问题，jdk采取了以下办法\n\n### WeakReference\n\n**Entry**类使用 **WeakReference**。jvm在任何一次GC中，总会尝试去回收被WeakReference引用的对象。**ThreadLocalMap**会在get、set操作中去清理被回收的entry\n\n但是以上只是回收了Entry，对应的Value不会回收。想要回收，还是得等到Thread被回收\n\n可通过以下程序验证，以下代码就无法回收value内存\n```java\nThreadLocal threadLocal = new ThreadLocal();\ntry {\n    TimeUnit.SECONDS.sleep(20);\n} catch (InterruptedException e) {\n    e.printStackTrace();\n}\nthreadLocal.set(new byte[100 * 1024 * 1024]);\n\nthreadLocal = null;\ntry {\n    Thread.currentThread().join();\n} catch (InterruptedException e) {\n    e.printStackTrace();\n}\n\n```\n\n\n\n\n\n\n","tags":["java","多线程","ThreadLocal"],"categories":["后端","java","concurrent"]},{"title":"redis哨兵模式配置项","url":"/2021/06/03/73EEMX.html","content":"\n之前搭建了一个哨兵模式，发现主从切换相当的慢，于是找一些关于哨兵的配置项，但是网上没有中文的说明，只好去翻redis官方文档\n\n<!-- more -->\n\nredis在[高可用](https://redis.io/topics/sentinel)这篇文章中详细介绍了哨兵模式\n\n```\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 60000\nsentinel parallel-syncs mymaster 1\n```\n\n### down-after-milliseconds\n\n这里配置的 **5000**,代表哨兵在**5秒**内没有收到master响应则视为master下线。注意这里应该是主观下线，后面应该还有客观下线的交互过程，将这个参数写小一点，能更快的响应下线。\n\n### failover-timeout\n\n这个参数应该是指主从切换的超时，可能和哨兵之间的通信有关系\n\n### parallel-syncs\n\n设置复本的数量。后面的话我实在翻译不了，网上也没有人翻译。只看明白一句 值越低，切换花的时间越长。设置成1可以保证在指定时刻只有一份复本不可用\n\n\n\n\n","tags":["redis","sentinel"],"categories":["后端","redis"]},{"title":"偏向锁和轻量级锁","url":"/2021/06/03/3YX47QX.html","content":"\n关于java的偏向锁和轻量级锁\n\n<!-- more -->\n\n### 基础知识\n\njava中锁有四种级别，分别是\n\n- 无锁\n- 偏向锁\n- 轻量级锁\n- 重量级锁\n\n其中 **偏向锁** 是锁仅获取一次，后续加锁只需要判断对象头里记录的线程是不是当前线程，如果是就直接进入同步。这样可以免去频繁的加锁\n\n而如果有别的线程来竞争这个锁，那么这个锁就会升级成轻量级锁，线程通过自旋去竞争锁。\n\n锁升级过程是**不可逆**的\n\n\n### 偏向锁\n\n在开启偏向锁（默认开启）的情况下，一个锁将由第一个获取锁的线程偏向，对象头里将会记录对应的线程信息。以后这个线程只需要对比记录的线程是否一致，如果一致则不需要加锁解锁操作\n\n要注意的是，即使线程已经结束了，偏向锁状态也不会消失。而是等到另一个线程来获取这个锁，因为和记录不一致，将升级成轻量级锁\n\n### 轻量级锁\n\n轻量级锁是通过cas+自旋来尝试获取锁，首先利用CAS尝试把对象原本的Mark Word 更新为Lock Record的指针，成功就说明加锁成功，然后执行相关同步操作。如果不成功，则开始自旋，不断去CAS。如果指定自旋次数内无法获取锁，则升级为重量级锁，这一过程代表着有过多的线程在竞争锁，才会导致某个线程无法获取锁\n\n### 测试用例\n\n根据上述知识，设计一个演示程序。基本逻辑如下\n\n- 首先有一个线程每隔1秒去获取锁，此时锁应该为偏向锁\n- 程序运行5.5秒后，另外起线程去获取锁，0.5秒是为了错开竞争，保证之前那个线程不会在此时来获取锁。由于线程不一致，锁升级为轻量级锁\n- 再次间隔5.5秒后，再起线程每隔1秒去获取锁，此时会和第一个线程竞争，锁应该升级为重量级锁\n\n\n以下为一个两个线程竞争锁的程序\n\n```java\n\n    private static Object sync = new Object();\n\n    public static void main(String[] args) {\n\n        VirtualMachine vm = VM.current();\n        long mark = vm.getLong(sync, 0);\n        System.out.println(lockDes(mark));\n\n        // 测试偏向锁升级成轻量级锁\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                while (true) {//怀疑是这里使用了\n                    long l = System.nanoTime();\n                    long start = System.currentTimeMillis();\n                    //如果没有线程竞争锁，这里就是偏向锁，有竞争升级成轻量级锁，自旋以获取锁，理论上获取锁的时间会更长\n                    synchronized (sync) {\n                        long mark = vm.getLong(sync, 0);\n                        System.out.printf(\"%s获取了锁 %d %d %s %n\", Thread.currentThread().getName(), System.nanoTime() - l, (System.currentTimeMillis() - start) / 1000, lockDes(mark));\n                    }\n                    try {\n                        TimeUnit.SECONDS.sleep(1);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n\n                }\n            }\n        }).start();\n\n\n        try {\n            TimeUnit.SECONDS.sleep(5);\n            TimeUnit.MILLISECONDS.sleep(500);//把获取锁间隔开\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        long l = System.nanoTime();\n        long start = System.currentTimeMillis();\n        System.out.println(\"开始竞争\");\n        synchronized (sync) {\n            mark = vm.getLong(sync, 0);\n            System.out.printf(\"只竞争一次的%s获取了锁 %d %d %s %n\", Thread.currentThread().getName(), System.nanoTime() - l, (System.currentTimeMillis() - start) / 1000, lockDes(mark));\n        }\n        try {\n            TimeUnit.SECONDS.sleep(5);\n            TimeUnit.MILLISECONDS.sleep(500);//把获取锁间隔开\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n\n\n                while (true) {\n                    long l = System.nanoTime();\n                    long start = System.currentTimeMillis();\n                    //如果没有线程竞争锁，这里就是偏向锁，有竞争升级成轻量级锁，自旋以获取锁，理论上获取锁的时间会更长\n                    synchronized (sync) {\n                        long m = vm.getLong(sync, 0);\n                        System.out.printf(\"第三个线程%s获取了锁 %d %d %s  %n\", Thread.currentThread().getName(), System.nanoTime() - l, (System.currentTimeMillis() - start) / 1000, lockDes(m));\n\n                        try {\n                            TimeUnit.SECONDS.sleep(1);\n                        } catch (InterruptedException e) {\n                            e.printStackTrace();\n                        }\n                    }\n\n                }\n            }\n        }).start();\n\n    }\n\n\n    private static String lockDes(long mark) {\n\n        long bits = mark & 0b11;\n        switch ((int) bits) {\n            case 0b11:\n                return \"(marked: GC)\";\n            case 0b00:\n                return \"(thin lock: 轻量级锁)\";\n            case 0b10:\n                return \"(fat lock: 重量级锁)\";\n            case 0b01:\n                int tribits = (int) (mark & 0b111);\n                switch (tribits) {\n                    case 0b001:\n                        return \"(non-biasable)\";\n                    case 0b101:\n                        return \"(biased: 偏向锁)\";\n                }\n        }\n\n        return \"错误数据\";\n    }\n\n```\n\n\n\n输出如下：\n\n> Thread-0获取了锁 82570 0 (biased: 偏向锁) \n> Thread-0获取了锁 28500 0 (biased: 偏向锁) \n> Thread-0获取了锁 26974 0 (biased: 偏向锁) \n> Thread-0获取了锁 29410 0 (biased: 偏向锁) \n> Thread-0获取了锁 25658 0 (biased: 偏向锁) \n> Thread-0获取了锁 19214 0 (biased: 偏向锁) \n> 开始竞争\n> 只竞争一次的main获取了锁 2132418 0 (thin lock: 轻量级锁) \n> Thread-0获取了锁 19542 0 (thin lock: 轻量级锁) \n> Thread-0获取了锁 24973 0 (thin lock: 轻量级锁) \n> Thread-0获取了锁 28656 0 (thin lock: 轻量级锁) \n> Thread-0获取了锁 29874 0 (thin lock: 轻量级锁) \n> Thread-0获取了锁 30851 0 (thin lock: 轻量级锁) \n> 第三个线程Thread-1获取了锁 46264 0 (thin lock: 轻量级锁)  \n> Thread-0获取了锁 943671726 0 (fat lock: 重量级锁) \n> 第三个线程Thread-1获取了锁 1384640 0 (fat lock: 重量级锁)  \n> Thread-0获取了锁 77250 0 (fat lock: 重量级锁) \n> 第三个线程Thread-1获取了锁 574245 0 (fat lock: 重量级锁)  \n> 第三个线程Thread-1获取了锁 21957 0 (fat lock: 重量级锁)  \n> 第三个线程Thread-1获取了锁 26252 0 (fat lock: 重量级锁)  \n> Thread-0获取了锁 2004668640 2 (fat lock: 重量级锁) \n> 第三个线程Thread-1获取了锁 1563713 0 (fat lock: 重量级锁)  \n> 第三个线程Thread-1获取了锁 34069 0 (fat lock: 重量级锁)  \n\n\n\n---\n\n\n### 流程\n\n借助网上的一篇[博客](https://www.cnblogs.com/tiancai/p/9382542.html)，来梳理一下过程\n\n\n1、主线程来竞争锁\n2、判断锁为偏向锁，且指向的线程0依旧存活\n3、暂停线程0\n4、将锁升级为轻量级锁\n5、继续执行线程0\n6、主线程开始自旋\n7、主线程执行\n8、主线程释放锁\n9、线程0获取锁，此时应该为轻量级锁\n\n### 解释\n\n首先上面代码中用了**jol**来获取锁状态\n\n```xml\n <!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core -->\n<dependency>\n    <groupId>org.openjdk.jol</groupId>\n    <artifactId>jol-core</artifactId>\n    <version>0.16</version>\n<!--<scope>provided</scope>-->\n</dependency>\n```\n\n\n主要是获取对象头低3位\n\n![java对象头结构](https://i.loli.net/2021/06/03/mPc21TQCZybaLDS.png)\n![无锁和偏向锁](https://i.loli.net/2021/06/03/xuUvdZXnoDOfgCQ.png)\n\n\n---\n\n锁的升级过程基本可以理解了，但是有一个问题就是：一个对象初始状态怎么就是偏向锁了？\n\n查阅jdk源码（markOop.hpp，从jdk6到jdk11，这部分都没有改动），关于**markWord**部分注释如下:\n\n```c++\n\n//  unused:25 hash:31 -->| unused:1   age:4    biased_lock:1 lock:2 (normal object)\n\n//  JavaThread*:54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased object)\n\n//  PromotedObject*:61 --------------------->| promo_bits:3 ----->| (CMS promoted object)\n\n//  size:64 ----------------------------------------------------->| (CMS free block)\n\n//\n\n//  unused:25 hash:31 -->| cms_free:1 age:4    biased_lock:1 lock:2 (COOPs && normal object)\n\n//  JavaThread*:54 epoch:2 cms_free:1 age:4    biased_lock:1 lock:2 (COOPs && biased object)\n\n//  narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 ----->| (COOPs && CMS promoted object)\n\n//  unused:21 size:35 -->| cms_free:1 unused:7 ------------------>| (COOPs && CMS free block)\n\n//\n\n//  - hash contains the identity hash value: largest value is\n\n//    31 bits, see os::random().  Also, 64-bit vm's require\n\n//    a hash value no bigger than 32 bits because they will not\n\n//    properly generate a mask larger than that: see library_call.cpp\n\n//    and c1_CodePatterns_sparc.cpp.\n\n//\n\n//  - the biased lock pattern is used to bias a lock toward a given\n\n//    thread. When this pattern is set in the low three bits, the lock\n\n//    is either biased toward a given thread or \"anonymously\" biased,\n\n//    indicating that it is possible for it to be biased. When the\n\n//    lock is biased toward a given thread, locking and unlocking can\n\n//    be performed by that thread without using atomic operations.\n\n//    When a lock's bias is revoked, it reverts back to the normal\n\n//    locking scheme described below.\n\n//\n\n//    Note that we are overloading the meaning of the \"unlocked\" state\n\n//    of the header. Because we steal a bit from the age we can\n\n//    guarantee that the bias pattern will never be seen for a truly\n\n//    unlocked object.\n\n//\n\n//    Note also that the biased state contains the age bits normally\n\n//    contained in the object header. Large increases in scavenge\n\n//    times were seen when these bits were absent and an arbitrary age\n\n//    assigned to all biased objects, because they tended to consume a\n\n//    significant fraction of the eden semispaces and were not\n\n//    promoted promptly, causing an increase in the amount of copying\n\n//    performed. The runtime system aligns all JavaThread* pointers to\n\n//    a very large value (currently 128 bytes (32bVM) or 256 bytes (64bVM))\n\n//    to make room for the age bits & the epoch bits (used in support of\n\n//    biased locking), and for the CMS \"freeness\" bit in the 64bVM (+COOPs).\n\n//\n\n//    [JavaThread* | epoch | age | 1 | 01]       lock is biased toward given thread\n\n//    [0           | epoch | age | 1 | 01]       lock is anonymously biased\n\n//\n\n//  - the two lock bits are used to describe three states: locked/unlocked and monitor.\n\n//\n\n//    [ptr             | 00]  locked             ptr points to real header on stack\n\n//    [header      | 0 | 01]  unlocked           regular object header\n\n//    [ptr             | 10]  monitor            inflated lock (header is wapped out)\n\n//    [ptr             | 11]  marked             used by markSweep to mark an object\n\n//                                               not valid at any other time\n```\n\n另外还有**jol**中的代码：\n\n```java\nprivate static String parseMarkWord(long mark) {\n    //  64 bits:\n    //  unused:25 hash:31 -->| unused_gap:1   age:4    biased_lock:1 lock:2 (normal object)\n    //  JavaThread*:54 epoch:2 unused_gap:1   age:4    biased_lock:1 lock:2 (biased object)\n    long bits = mark & 0b11;\n    switch ((int) bits) {\n        case 0b11:\n            return \"(marked: \" + toHex(mark) + \")\";\n        case 0b00:\n            return \"(thin lock: \" + toHex(mark) + \")\";\n        case 0b10:\n            return \"(fat lock: \" + toHex(mark) + \")\";\n        case 0b01:\n            String s = \"; age: \" + ((mark >> 3) & 0xF);\n            int tribits = (int) (mark & 0b111);\n            switch (tribits) {\n                case 0b001:\n                    int hash = (int)(mark >>> 8);\n                    if (hash != 0) {\n                        return \"(hash: \" + toHex(hash) + s + \")\";\n                    } else {\n                        return \"(non-biasable\" + s + \")\";\n                    }\n                case 0b101:\n                    long thread = mark >>> 10;\n                    if (thread == 0) {\n                        return \"(biasable\" + s + \")\";\n                    } else {\n                        return \"(biased: \" + toHex(thread) + \"; epoch: \" + ((mark >> 8) & 0x2) + s + \")\";\n                    }\n            }\n        default:\n            return \"(parse error)\";\n    }\n}\n```\n\n关于偏向锁部分，重点在于倒数第三位的**baised_lock**。\n虽然名字叫偏向锁标记，但是我看下来结果更像是**baiseable_lock**——是否可以偏向的标志；如果是1，代表这个对象可以拥有偏向锁；区分是否已经获取了偏向锁，则靠高54位是否为0，获取了偏向锁的情况下，这54bit应该是对应的threadId。\n\n在使用了 **-XX:-UseBiasedLocking** 关闭偏向锁后，这一位就都变成0了。\n\n\n\n\n\n\n","tags":["java","并发","锁"],"categories":["后端","java","concurrent"]},{"title":"限流算法","url":"/2021/06/02/S6175R.html","content":"\n学习《Redis深度历险：核心原理和应用实践》一书中，提及了两种限流算法\n\n<!-- more -->\n\n### 漏水算法\n\n以下是算法实现\n\n```java\n\npackage cn.inkroom.study.redis;\n\n/**\n * 漏水算法\n *\n * @author inkbox\n */\npublic class FunnelRateLimiter {\n\n    static class Funnel {\n        /**\n         * 容器的容量\n         */\n        int capacity;\n        /**\n         * 流水速率，单位是 个/秒\n         * 以毫秒为单位，流水速率会比较小\n         */\n        float leakingRate;\n        /**\n         * 容器内的剩余容量\n         */\n        int leftQuota;\n\n        /**\n         * 上次漏水时间，实际代表的是上次请求时间\n         */\n        long lastLeakTime;\n\n        /**\n         * 初始化限流器\n         * <p>\n         * 假设某个行为需要100秒内最多50次(2秒一次)，最多连续操作15次\n         * 那么容器应该是15，流水速率为 50 / 100 = 0.5\n         *\n         * 容器会在第30秒装满，然后维持两秒一次请求通过\n         *\n         *\n         * @param capacity    容器数量\n         * @param leakingRate 流水速率\n         */\n        public Funnel(int capacity, float leakingRate) {\n            this.capacity = capacity;\n            this.leakingRate = leakingRate;\n            this.leftQuota = capacity;\n            this.lastLeakTime = System.currentTimeMillis();\n        }\n\n\n        void makeSpace() {\n            long nowTs = System.currentTimeMillis();\n            // 距离上次漏水差了多少时间\n            long deltaTs = nowTs - lastLeakTime;\n            // 计算应该流走多少数据\n            int deltaQuota = (int) (deltaTs / 1000 * leakingRate);\n\n\n            if (deltaQuota < 0) {// 书中注释，间隔时间太长，整数数字过大溢出\n                this.leftQuota = capacity;\n                this.lastLeakTime = nowTs;\n                return;\n            }\n            // 腾出空间太小，最小单位为1\n            if (deltaQuota < 1) {\n                return;\n            }\n            // 修改剩余容量\n            this.leftQuota += deltaQuota;\n            this.lastLeakTime = nowTs;\n            if (this.leftQuota > this.capacity) {\n                this.leftQuota = this.capacity;\n            }\n\n        }\n\n        boolean watering(int quota) {\n            makeSpace();\n            if (this.leftQuota >= quota) {\n                // 剩余容量减小\n                this.leftQuota -= quota;\n                return true;\n            }\n            return false;\n        }\n    }\n\n    public static void main(String[] args) {\n        Funnel funnel = new Funnel(15, 0.5f);\n        long now = System.currentTimeMillis();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                while (true) {\n                    System.out.println(\"当前：\" + ((System.currentTimeMillis() - now) / 1000) + \" \" + funnel.watering(1));\n                    try {\n                        Thread.sleep(1000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n\n\n            }\n        }).start();\n    }\n\n}\n\n\n```\n\n\n\n\n### 滑动窗口算法\n\n书中还提及了另一种简单的滑动窗口限流算法，但是给出的实现有一个小问题，会导致请求永远无法通过\n\n以下是我自己的代码，除了书中的代码，还使用lua脚本替换原本的管道事务的方案\n\n```java\npackage cn.inkroom.study.redis;\n\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.Pipeline;\nimport redis.clients.jedis.Response;\n\n/**\n * 简单限流器\n *\n * @author inkbox\n */\npublic class TimeLimit {\n\n    private Jedis jedis;\n\n    public TimeLimit() {\n        jedis = new Jedis(\"192.168.3.64\", 6379);\n    }\n\n    /**\n     * 操作是否允许被执行。用户userId的action操作在period时间段内，只允许最多执行maxCount次\n     *\n     * @param userId   用户\n     * @param action   操作类型，比如 like:123 可以代表给id为123的文章点赞\n     * @param period   从现在往前的时间段，单位秒。例如过去一分钟内，60\n     * @param maxCount 指定时间段内的最大次数\n     * @return\n     */\n    public boolean allowExecute(String userId, String action, int period, int maxCount) {\n\n// 以下是书中的实现，里面有一个小问题\n\n        String key = String.format(\"limit:%s:%s\", userId, action);\n        long now = System.currentTimeMillis();\n        Pipeline pipelined = jedis.pipelined();\n        pipelined.multi();\n        // 这里有个问题，假设在边界时间里不断重试，将会导致永远无法执行\n        // 假设 5秒内最多执行2次，但是每秒都在重试\n        // 那么除了最开始的两次，之后不管过了多少时间都无法执行\n        // 解决方法就是把 add 放到 zremrange 后面，不计数无效尝试\n\n        pipelined.zadd(key, now, now + \"\");\n        // 移除当前时间-period时间前的所有数据\n        pipelined.zremrangeByScore(key, 0, now - period * 1000L);\n        Response<Long> zcard = pipelined.zcard(key);\n        //设置过期时间\n        pipelined.expire(key, (period) + 1);\n        pipelined.exec();\n        pipelined.close();\n\n        return zcard.get() <= maxCount;\n    }\n\n    /**\n     * 操作是否允许被执行。用户userId的action操作在period时间段内，只允许最多执行maxCount次\n     * <p>\n     * 和 {@link TimeLimit#allowExecute(String, String, int, int)} 的区别在于，该方法不会统计不被允许的执行次数\n     *\n     * @param userId   用户\n     * @param action   操作类型，比如 like:123 可以代表给id为123的文章点赞\n     * @param period   从现在往前的时间段，单位秒。例如过去一分钟内，60\n     * @param maxCount 指定时间段内的最大次数\n     * @return\n     */\n    public boolean allowExecuteIgnoreFail(String userId, String action, int period, int maxCount) {\n        String key = String.format(\"limit:%s:%s\", userId, action);\n        long now = System.currentTimeMillis();\n\n        Long size = ((Long) jedis.eval(\n                \"redis.call('zremrangeByScore',KEYS[1],0,ARGV[1]);\"\n                        + \"local size=redis.call('zcard',KEYS[1]);\"\n                        + \"if (size < tonumber(ARGV[2])) then\"\n                        + \"  redis.call('zadd',KEYS[1],tonumber(ARGV[3]),ARGV[3]);\"\n                        + \"end;\"\n                        + \"redis.call('expire',KEYS[1],tonumber(ARGV[4]));\"\n                        + \"return size\"\n                ,\n                1, key, (now - period * 1000L) + \"\", maxCount + \"\", now + \"\", (period + 1) + \"\"));\n        return size < maxCount;\n        // 等同以下代码，只是具有原子性\n//        jedis.zremrangeByScore(key, 0, now - period * 1000L);\n//        Long size = jedis.zcard(key);\n//        if (size < maxCount) {\n//            //合法操作\n//            jedis.zadd(key, now, now + \"\");\n//            return true;\n//        }\n//        jedis.expire(key, period + 1);\n//        return false;\n\n    }\n\n    public static void main(String[] args) {\n        TimeLimit timeLimit = new TimeLimit();\n\n        int count = 2;\n        for (int i = 0; i < 100; i++) {\n            System.out.println(timeLimit.allowExecuteIgnoreFail(\"userId-\", \"action\", 5, count));\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n\n    }\n\n}\n\n\n```\n\n### 令牌算法\n\n令牌算法和漏水算法大同小异，只是把一些名词做了替换，令牌就相当于剩余容量，另外允许不经过限流处理，直接通过\n","tags":["java","redis","限流","漏水算法"],"categories":["后端","java"]},{"title":"redis管道和事务","url":"/2021/06/02/2SE8EY3.html","content":"\n关于管道和事务的使用时机\n\n<!-- more -->\n\n### 背景\n\n有这样一段代码\n```java\npipe = redis.pipeline();\npipe.multi();\npipe.incr(\"books\");\npipe.excute();\npipe.close();\n\n```\n\n这里同时应用了**管道**和**事务**，但是我认为有些多余。\n\n\n### 管道\n\n管道的作用是在于把多个命令合并成一次网络请求，交给redis执行，可以有效减少请求时间。\n\n> 我做过测试，同样次数的请求，一条一条发送，需要35秒左右。5条合并发送一次，就只需要1.5秒左右。\n\n由于redis响应请求是单线程的，所以管道内的请求不会被其他请求插队，可以保证其**原子性**\n\n### 事务\n\nredis事务很简单，使用**multi**开启，使用**exec** 提交，同时**不会**阻塞请求。按照书中的说法，其保证了当前执行的事务有着不被其他事务打断的权利。\n\n关于redis事务是否具有原子性的问题上，我看到各个地方说法不太一致\n\n- 《redis深度历险：核心原理和应用实践》中通过一个例子证明事务没有原子性\n- 《redis使用手册》直接说redis具有ACID，没有佐证\n- 菜鸟教程的说法又体现了其没有原子性\n\n我使用docker的**redis:6.2.3-alpine** 测试以下脚本\n\n\n```redis\nmulti\nset key1 22\nincr notExistKey\nexec\n\n```\n\n结果是\n> (error) EXECABORT Transaction discarded because of previous errors.\n\n再执行\n```\nget key1\n```\n\n没有对应的值，说明至少**6.2.3**这个版本的事务是有原子性的\n\n在**4.0.14-alpine**中执行以下脚本\n```redis\nset key1 1\nmulti\nset key2 2\nhgetall key1\nexec\n\nget key2\n\n```\n\n**exec**结果如下\n\n```\n1) OK\n2) (error) WRONGTYPE Operation against a key holding the wrong kind of value\n```\n\n**get** 能够拿到值，可见这个版本不具有原子性\n\n---\n\n为了控制变量，我又把这个命令在**6.2.3**上执行了一下，结果两个结果居然一样，key2 同样是有值的\n\n这。。。我就不知道该说什么了。\n\n只好求助网络了。\n\n---\n\n网上给了一个体现原子性的例子，就是在事务中执行一个不存在的命令（随便输入点什么）。\n\n这样exec就是报错，而不执行。\n\n这和我的理解不太一样，我原本理解是，redis事务命令入队时会检测命令是否合法，合法则入队，也就是返回**QUEUED**\n\n现在看可能是命令不合法，会将事务置为出错，入不入队都不重要了，exec时会直接提示错误。\n\n而我在4.x中执行的错误是一种使用错误，必须执行才能得知的。redis认为这种错误是程序员的错，不会为此大费周章，去做回滚之类的操作。这就是一些人说redis没有原子性的原因\n\n---\n\n再测试一下其他特性，按以下流程执行命令\n\n| clientA    | clientB   |\n| ------- | ------ |\n| set key1 1 | |\n| | multi|\n| | get key1|\n| set key1 2 | |\n| | get key1|\n| | set key1 3|\n| get key1 | |\n| |  exec |\n| get key1 ||\n\n结果如下\n\n![C6288E27-C711-4DDD-A494-0D84267F9CA5.png](https://i.loli.net/2021/06/02/YskpUOmEnHo47bN.png)\n\n\n可以看出，事务的隔离级别类似于未提交读，\n\n\n\n### 问题\n\n如果按照以上说法，管道同样拥有不会被别的请求打断的功能，那事务还有必要吗？\n\n### 回答\n\n后来我在实现限流时，尝试在管道close之前，获取某条命令的执行结果作判断，结果报了异常。\n\n细想一下，管道只会在close之后才发送请求，那么肯定是无法获取命令结果的。这就是管道的局限性\n\n所以后来我使用脚本实现，就能保证操作的原子性，同时不过分浪费网络请求\n\n当然也可以使用事务实现\n\n还是没看出来事务有多大意义\n\n\n---\n\n顺便提一句，网上好多关于redis的博客其实就是把官方文档给翻译了一遍，还搞得跟自己研究出来的一样\n","categories":["后端","redis"]},{"title":"redis哨兵模式","url":"/2021/06/01/5K01J8.html","content":"\n学习redis哨兵模式中发现的一些问题\n\n\n<!-- more -->\n\n\n我基于docker搭建了三个redis实例，其中一个master，两个slave。\n\n同时搭建一个sentinel 监视 master\n\n然后开始测试下线\n\n## master下线\n\n`docker stop master` 之后，sentinel切换了master，同时修改的配置文件里的 sentinel monitor 对应的ip地址\n\n## 测试全部下线\n\n将所有实例全部下线，sentinel 需要花很长时间才能确定实例**odown**\n\n再将实例全部启动，三台实例之间很容易就构成了最开始的主从结构。\n\n此时sentinel在经过非常多的时间后，终于发现了现在的主从结构。\n\n同时执行`sentinel slaves` 发现发现的实例数量在逐渐增多，由3个变4个，再变5个，多出来的两个处在 `s_down,slave,disconnected`状态\n\n初步猜测问题可能出在docker的网络模式上，我在最早的配置中写的是物理机的ip，但是在通信过程中，redis获取到的都是容器在虚拟网卡里的ip地址\n\n## 更换网络模式\n\n把docker网络模式换成**host**之后，实例数量正常了。 同时检查更新的频率为五分钟，相当漫长\n\n\n\n","tags":["后端","redis","哨兵"],"categories":["后端","redis"]},{"title":"并发学习笔记","url":"/2021/05/29/212W51W.html","content":"\n并发学习笔记\n\n<!-- more -->\n\n### 线程不安全的原因\n\n#### 共享变量\n\n线程对数据的操作是以一种类似数据缓存的方式来操作。内存模型中有主内存和本地内存的概念，注意，是概念，并不是一个固定的数据区域。线程操作变量只会操作本地内存里的数据，而从主内存读取和刷新到主内存是比较随机的，导致看似线程在访问同一个变量，实际是各玩各的。这一块叫做线程的可见性\n\n#### 指令重排\n\n在程序的各个层面，比如编译器、jvm、操作系统、处理器都可能会对将要运行的执行进行一定的重排序，这种重排序主要是出于效率考虑。\n\n重排序就是，你写的代码是执行方法A之后，执行方法B。实际运行过程中却非如此。在这一层面，比较看重的是**原子性**，任何非原子性操作就有可能发生指令重排，java中绝大多数操作都是非原子性的，包括但不限于**new**，**++**、**+=**，原子性操作有 **=**、**CAS**。\n\n\n\n### CAS\n\nCAS全称比较并交换(compare and swap)，需要三个操作数。第一个变量的地址，第二个期望中变量的值，第三个新值，当且仅当变量当前值等于期望值时，将变量赋予新值，否则什么都不做。这是一个**原子操作**。\n\nJDK9以前需要通过**UnSafe**类实现CAS操作，9以后使用**VarHandler**实现\n\n\n\n### Volatile\n\n两种功能：\n\n- 禁止volatile变量本身的读写 和前后的操作之间的重排序\n- 保证写入volatile会更新线程共享变量到主内存中（类似于缓存落库）；保证读取volatile之前会从主内存获取共享变量（类似与缓存更新）。也就是保证变量在线程间的可见性\n\n\n\n---\n\n有以下程序\n\n```java\n\nstatic boolean f = true;\npublic void static main(String[] args){\n    \n    new Threan(new Runable(){\n        public void run(){\n            while(r){}\n            System.out.println('结束循环');\n        }\n    }).start();\n     try {\n         Thread.sleep(1000);\n     } catch (InterruptedException e) {\n         e.printStackTrace();\n     }\n    s = false;\n    \n}\n\n```\n\n由于**jmm**不保证 **f** 的内存可见性，死循环将永远无法结束\n\n想要结束有以下方法\n\n- 给**f** 加上**volatile** 关键字\n- 此外 **f** 不变，额外加上一个 **volatile** 的变量 **a**，在循环体内读变量**a**进行读或者写操作，也能结束循环\n- 循环体内执行一个有**synchronized**关键字的方法\n\n---\n\n以上方法的原理是强制线程从主内存里获取共享变量最新的值\n\n\n\n","tags":["java","并发"],"categories":["后端","java","concurrent"]},{"title":"mariadb数据库索引失效情况","url":"/2021/05/27/2Z9HJBH.html","content":"\n最近看了一篇[博客](https://www.cnblogs.com/wdss/p/11186411.html)，研究索引失效情况，但是实际测试有一些不太一样的地方\n\n<!-- more -->\n\n## 数据库版本\n\n我使用的是mariadb，mysql的一个分支版本，具体版本为**mysql  Ver 15.1 Distrib 10.5.10-MariaDB, for debian-linux-gnu (x86_64) using readline 5.2**\n\n## 建库脚本\n```sql\n\nCREATE TABLE `f` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(120) DEFAULT NULL,\n  `c_id` int(11) DEFAULT NULL,\n  `phone` char(11) DEFAULT NULL,\n  `qq` varchar(20) DEFAULT NULL,\n  `gender` varchar(12) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `name_c_id_phone` (`name`,`c_id`,`phone`),\n  KEY `c_id` (`c_id`),\n  KEY `gender` (`gender`)\n) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8\n\n```\n\n## != 操作符\n\n博客 **第6点** 写到 **!=** 操作符永远不会使用到索引\n\n然而实际测试之后并非如此\n\n![C9FA60E8-21F7-460C-B63C-28B77CAB199C.png](https://i.loli.net/2021/05/27/u4wXWQSz5vOLFgC.png)\n\n### mysql\n\n再使用mysql做测试，版本**mysql  Ver 14.14 Distrib 5.7.34, for Linux (x86_64) using  EditLine wrapper**\n\n![7ED4BF54-89D6-42C6-86A9-8DB8052D0DD4.png](https://i.loli.net/2021/05/27/fsOAdw8aLDbt5i7.png)\n\n这次就和文章说法一致了\n\n## 组合索引，不使用第一列，索引失效\n\n\n\n文章中使用了以下sql\n\n```sql\nselect * from f where c_id=1\n\n```\n\nexplain 之后的结果确实和文章中所说相同，但是如果对查询列表做下修改\n\n![](https://i.loli.net/2021/06/06/hs74QybFJKUaupj.png)\n\n\n可以看出，尽管违背了最左匹配原则，但是还是使用了索引。\n\n原因就在于查询列表的列都在这个索引里存着，没有相应的回表操作，相比起数据量大的全表扫描，还是索引代价更低。所以还是会使用索引\n\n","tags":["mysql","数据库","索引"],"categories":["后端","数据库"]},{"title":"SpringBoot是如何解析yaml文件的","url":"/2021/05/12/3Y7W6EK.html","content":"\n\n\n本文旨在探寻SpringBoot解析**yaml**文件类库原理，而非SpringBoot本身的逻辑，掌握这一知识可以用于设计自己的配置文件格式\n\n\n\n<!-- more -->\n\n## 类库\n\n首先，SpringBoot是通过**PropertySourceLoader**来实现各种配置文件的加载，针对**yaml**则是**YamlPropertySourceLoader**\n\n```java\n@Override\n\tpublic List<PropertySource<?>> load(String name, Resource resource) throws IOException {\n\t\tif (!ClassUtils.isPresent(\"org.yaml.snakeyaml.Yaml\", null)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Attempted to load \" + name + \" but snakeyaml was not found on the classpath\");\n\t\t}\n\t\tList<Map<String, Object>> loaded = new OriginTrackedYamlLoader(resource).load();\n\t\tif (loaded.isEmpty()) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t\tList<PropertySource<?>> propertySources = new ArrayList<>(loaded.size());\n\t\tfor (int i = 0; i < loaded.size(); i++) {\n\t\t\tString documentNumber = (loaded.size() != 1) ? \" (document #\" + i + \")\" : \"\";\n\t\t\tpropertySources.add(new OriginTrackedMapPropertySource(name + documentNumber, loaded.get(i)));\n\t\t}\n\t\treturn propertySources;\n\t}\n\n```\n\n跟着路径一路追踪，来到`org.yaml.snakeyaml.Yaml`第536行\n\n```java\n\n public Iterable<Object> loadAll(Reader yaml) {\n        Composer composer = new Composer(new ParserImpl(new StreamReader(yaml)), resolver);\n        constructor.setComposer(composer);\n        Iterator<Object> result = new Iterator<Object>() {\n            @Override\n            public boolean hasNext() {\n                return constructor.checkData();\n            }\n\n            @Override\n            public Object next() {\n                return constructor.getData();\n            }\n\n            @Override\n            public void remove() {\n                throw new UnsupportedOperationException();\n            }\n        };\n        return new YamlIterable(result);\n    }\n    \n```\n\n这里出现了几个类，其中\n\n- StreamReader  负责数据读取\n- ParserImpl  负责数据转换\n- Composer 有点类似于一个对外的封装，负责触发读取事件\n- ScannerImpl 应该是负责数据扫描，将读取到的数据，按照规则组成有意义的单位\n\n### 读取\n\n来看数据读取这一部分，就是`StreamReader`\n\n首先是初始化\n\n```java\npublic StreamReader(Reader reader) {\n    this.name = \"'reader'\";\n    this.dataWindow = new int[0];//数据窗口，应该一次读取一定的数据\n    this.dataLength = 0;//已经读取到的数据长度\n    this.stream = reader;// 数据流\n    this.eof = false;// 文件是否读取完标志\n    this.buffer = new char[BUFFER_SIZE];// 缓冲\n}\n```\n\n初始化完成后，就应该要读取文件了\n\n文件读取是对流的操作，那么只要一路跟踪**this.stream**的调用就行了。但是这只适用于简单的类\n\n可以看出，这里只有`private void update()` 才有流的操作，那么在这里打断点\n\n这是刚开始的情况\n\n--插入图片\n\n```java\nprivate void update() {\n        try {\n            int read = stream.read(buffer, 0, BUFFER_SIZE - 1);\n            if (read > 0) {\n                int cpIndex = (dataLength - pointer);//这里是获取本次读取在dataWindow中的起始点，从这以后的数据，就是本次读取到的数据\n                dataWindow = Arrays.copyOfRange(dataWindow, pointer, dataLength + read);//重新构建一个数组，其他目的待定\n\n                if (Character.isHighSurrogate(buffer[read - 1])) {//判断最后一个字符是否是HighSurrogate，这是unicode编码中的概念，此时需要再多读取一个字符。这里不太明白，可能需要再去学习编码知识才行\n                    if (stream.read(buffer, read, 1) == -1) {\n                        eof = true;\n                    } else {\n                        read++;\n                    }\n                }\n\n                int nonPrintable = ' ';\n                for (int i = 0; i < read; cpIndex++) {\n                    int codePoint = Character.codePointAt(buffer, i);\n                    dataWindow[cpIndex] = codePoint;//赋值\n                    if (isPrintable(codePoint)) {//判断这个字符是否可打印，或者说可见，如果可见则继续读取\n                        i += Character.charCount(codePoint);\n                    } else {//不可见则读写结束，避免有不可见字符导致出bug\n                        nonPrintable = codePoint;\n                        i = read;\n                    }\n                }\n\n                dataLength = cpIndex;\n                pointer = 0;//当前数据指针归零\n                if (nonPrintable != ' ') {\n                    throw new ReaderException(name, cpIndex - 1, nonPrintable,\n                            \"special characters are not allowed\");\n                }\n            } else {\n                eof = true;\n            }\n        } catch (IOException ioe) {\n            throw new YAMLException(ioe);\n        }\n    }\n\n```\n\n\n\n第一次读写结束，跟着debug发现，这是被`private boolean ensureEnoughData(int size)`调用\n\n数据读取没有什么特别的地方，总体结果就是读取了一定长度的数据\n\n\n\n### 扫描\n\n数据读取后，需要在组织成有意义的数据单位，这就是由 `ScannerImpl` 负责的内容\n\n上面的数据读取是由`ScannerImpl`的`private void scanToNextToken()`方法调用的。\n\n这个方法的作用在于，定位到有实际意义的字符开头，跳过一些特殊字符和注释\n\n```java\nprivate void scanToNextToken() {\n        // If there is a byte order mark (BOM) at the beginning of the stream,\n        // forward past it.\n        if (reader.getIndex() == 0 && reader.peek() == 0xFEFF) {//跳过文件开头可能存在的bom头\n            reader.forward();\n        }\n        boolean found = false;\n        while (!found) {\n            int ff = 0;\n            // Peek ahead until we find the first non-space character, then\n            // move forward directly to that character.\n            while (reader.peek(ff) == ' ') {\n                ff++;\n            }\n            if (ff > 0) {\n                reader.forward(ff);\n            }\n            // If the character we have skipped forward to is a comment (#),\n            // then peek ahead until we find the next end of line. YAML\n            // comments are from a # to the next new-line. We then forward\n            // past the comment.\n            if (reader.peek() == '#') {//这一行被注释，直接跳过\n                ff = 0;\n                while (Constant.NULL_OR_LINEBR.hasNo(reader.peek(ff))) {//跳过一些字符，具体为什么还没弄明白\n                    ff++;\n                }\n                if (ff > 0) {\n                    reader.forward(ff);\n                }\n            }\n            // If we scanned a line break, then (depending on flow level),\n            // simple keys may be allowed.\n            if (scanLineBreak().length() != 0) {// found a line-break 处理各种情况的换行符，这里涉及到\\u2029之类的特殊字符编码，需要去学习\n                if (this.flowLevel == 0) {\n                    // Simple keys are allowed at flow-level 0 after a line\n                    // break\n                    this.allowSimpleKey = true;\n                }\n            } else {\n                found = true;\n            }\n        }\n    }\n\n```\n\n----\n\n\n\n回到上级调用——`private void fetchMoreTokens()`\n\n```java\nprivate void fetchMoreTokens() {\n        // Eat whitespaces and comments until we reach the next token.\n        scanToNextToken();\n        // Remove obsolete possible simple keys. 删除一些不再使用的 simple keys，不能理解这个simple keys是什么，在debug中，这个方法实际没有具体执行内容\n        stalePossibleSimpleKeys();\n        // Compare the current indentation and column. It may add some tokens\n        // and decrease the current indentation level.  根据当前数据指针所在列，确定缩进级别；这里有个flowLevel决定要不要处理缩进；这个方法里有一些细节，建议先看下文解析；只处理缩进减小是因为如果缩进会增大，那么在下面的判断第一个字符获取token的时候就会重新定位缩进\n         unwindIndent(reader.getColumn());\n        // Peek the next code point, to decide what the next group of tokens\n        // will look like.\n        int c = reader.peek();//此时拿到的应该是一行数据第一个有意义的字符\n        switch (c) { //接下来首先要判断是不是一些关键字\n        case '\\0'\n            // Is it the end of stream? 可能读取到了一行回车，或者只有空白字符的数据\n            fetchStreamEnd();\n            return;\n        case '%':\n            // Is it a directive? 指令\n            if (checkDirective()) {\n                fetchDirective();\n                return;\n            }\n            break;\n        case '-':\n            // Is it the document start?\n            if (checkDocumentStart()) {\n                fetchDocumentStart();\n                return;\n                // Is it the block entry indicator?\n            } else if (checkBlockEntry()) {\n                fetchBlockEntry();\n                return;\n            }\n            break;\n        case '.':\n            // Is it the document end?\n            if (checkDocumentEnd()) {\n                fetchDocumentEnd();\n                return;\n            }\n            break;\n        // TODO support for BOM within a stream. (not implemented in PyYAML)\n        case '[':\n            // Is it the flow sequence start indicator?\n            fetchFlowSequenceStart();\n            return;\n        case '{':\n            // Is it the flow mapping start indicator?\n            fetchFlowMappingStart();\n            return;\n        case ']':\n            // Is it the flow sequence end indicator?\n            fetchFlowSequenceEnd();\n            return;\n        case '}':\n            // Is it the flow mapping end indicator?\n            fetchFlowMappingEnd();\n            return;\n        case ',':\n            // Is it the flow entry indicator?\n            fetchFlowEntry();\n            return;\n            // see block entry indicator above\n        case '?':\n            // Is it the key indicator?\n            if (checkKey()) {\n                fetchKey();\n                return;\n            }\n            break;\n        case ':':\n            // Is it the value indicator?\n            if (checkValue()) {\n                fetchValue();\n                return;\n            }\n            break;\n        case '*':\n            // Is it an alias?\n            fetchAlias();\n            return;\n        case '&':\n            // Is it an anchor?\n            fetchAnchor();\n            return;\n        case '!':\n            // Is it a tag?\n            fetchTag();\n            return;\n        case '|':\n            // Is it a literal scalar?\n            if (this.flowLevel == 0) {\n                fetchLiteral();\n                return;\n            }\n            break;\n        case '>':\n            // Is it a folded scalar?\n            if (this.flowLevel == 0) {\n                fetchFolded();\n                return;\n            }\n            break;\n        case '\\'':\n            // Is it a single quoted scalar?\n            fetchSingle();\n            return;\n        case '\"':\n            // Is it a double quoted scalar?\n            fetchDouble();\n            return;\n        }\n        // It must be a plain scalar then. 此时是一个普通字符\n        if (checkPlain()) {\n            fetchPlain();\n            return;\n        }\n        // No? It's an error. Let's produce a nice error message.We do this by\n        // converting escaped characters into their escape sequences. This is a\n        // backwards use of the ESCAPE_REPLACEMENTS map.\n        String chRepresentation = String.valueOf(Character.toChars(c));\n        for (Character s : ESCAPE_REPLACEMENTS.keySet()) {\n            String v = ESCAPE_REPLACEMENTS.get(s);\n            if (v.equals(chRepresentation)) {\n                chRepresentation = \"\\\\\" + s;// ' ' -> '\\t'\n                break;\n            }\n        }\n        if (c == '\\t')\n            chRepresentation += \"(TAB)\";\n        String text = String\n                .format(\"found character '%s' that cannot start any token. (Do not use %s for indentation)\",\n                        chRepresentation, chRepresentation);\n        throw new ScannerException(\"while scanning for the next token\", null, text,\n                reader.getMark());\n    }\n\n    // Simple keys treatment.\n\n    /**\n     * Return the number of the nearest possible simple key. Actually we don't\n     * need to loop through the whole dictionary.\n     */\n    private int nextPossibleSimpleKey() {\n        /*\n         * the implementation is not as in PyYAML. Because\n         * this.possibleSimpleKeys is ordered we can simply take the first key\n         */\n        if (!this.possibleSimpleKeys.isEmpty()) {\n            return this.possibleSimpleKeys.values().iterator().next().getTokenNumber();\n        }\n        return -1;\n    }\n```\n\n\n\n#### 看一下如何决定缩进级别的\n\n```java\n private void unwindIndent(int col) {\n        // In the flow context, indentation is ignored. We make the scanner less\n        // restrictive then specification requires.\n        if (this.flowLevel != 0) {\n            return;\n        }\n\n        // In block context, we may need to issue the BLOCK-END tokens.\n        while (this.indent > col) {//确定当前有没有必要减小缩进；一个缩进减小代表结束了一个block(代码块)\n            Mark mark = reader.getMark();//这里mark相当于对当前数据状态的一个快照\n            this.indent = this.indents.pop();//这里使用了一个栈来记录经历的缩进级别变化，此处出栈来确定当前应该有的缩进级别\n            this.tokens.add(new BlockEndToken(mark, mark));//代码块结束，而且可能不止结束一个\n        }\n    }\n```\n\n\n\n----\n\n`fetchMoreToken`执行完成后，此时应该增加了一个Token\n\n### 转换\n\n此时调用来到了`PraseImpl`的第195行，此时处在一个内部类中`private class ParseImplicitDocumentStart implements Production`\n\n这里有个接口`Production`，注释说明这个接口用于语法转换。我的理解就是用来处理Token的，处理完成后返回Event，同时注册下一个`Production`\n\n此外还有一个`Event`，这个类就是一个基本单元，表明现在处于读写的什么状态上，这里面会存放数据快照\n\n```java\n private class ParseImplicitDocumentStart implements Production {\n        public Event produce() {\n            // Parse an implicit document.\n            if (!scanner.checkToken(Token.ID.Directive, Token.ID.DocumentStart, Token.ID.StreamEnd)) {//只要不是这三种Token，那么代表文件是有数据的\n                directives = new VersionTagsTuple(null, DEFAULT_TAGS);\n                Token token = scanner.peekToken();\n                Mark startMark = token.getStartMark();\n                Mark endMark = startMark;\n                Event event = new DocumentStartEvent(startMark, endMark, false, null, null);\n                // Prepare the next state.\n                states.push(new ParseDocumentEnd());//保底操作\n                state = new ParseBlockNode();\n                return event;\n            } else {\n                Production p = new ParseDocumentStart();\n                return p.produce();\n            }\n        }\n    }\n```\n\n要注意一下方法命名规则，**peek**是获取当前Event，如果没有就根据实际情况去扫描文件转换一个Event出来，**get**是获取当前Event，同时清除Event，之后调用**peek**就会一定去扫描文件了\n\n---\n\n继续回退之后，这些还只是在 `checkData`，还没有去获取数据\n\n### 数据封装\n\n在`getData`方法中去获取数据，并封装\n\n入口定位为`Compose.getNode()` 方法，这里又有一个新的类`Node`。这个可以看作一颗树，但是根据每个节点的类型不同，子树结构会有一些变化。\n\n那么对于树结构来说，递归就是常规用法了。\n\n主要方法就是`Node composeNode(Node parent)`。这个方法相当于一个总的递归入口，里面还会根据不同情况继续分发方法，比如`Node composeScalarNode(String anchor)`、` Node composeSequenceNode(String anchor) `、`Node composeMappingNode(String anchor)`\n\n\n\n拿最常见的mapping来说明，假设现在有下面这样一个配置\n\n```yaml\nlogging:\n\tcom: debug\n```\n\n\n\n```java\n//此时node应该就是logging，childdren代表node底下还可能有的数据存储\nprotected void composeMappingChildren(List<NodeTuple> children, MappingNode node) {\n    \tNode itemKey = composeKeyNode(node);//这里获取key，此处就应该是com\n        if (itemKey.getTag().equals(Tag.MERGE)) {\n            node.setMerged(true);\n        }\n        Node itemValue = composeValueNode(node);//这里获取value，此处就应该是debug，同时这些方法都是递归调用，也就允许一直往下\n        children.add(new NodeTuple(itemKey, itemValue));//这里就是把com: debug 作为children存入\n}\n```\n\n---\n\n最终读取到的结果就是一个树结构，但是spring中实际使用是都是普通的kv结构，所以还需要进行一个转换。\n\n这一过程交给了`YamlProcessor`的`boolean process(Map<String, Object> map, MatchCallback callback)`方法，这里就属于spring的内容了，不在研究范围内\n\n\n\n## 总结\n\n\n\n- **snake**一次读取若干字节，从里面剔除非法字符、注释\n- 逐字扫描，确定字符类型和接下来的操作\n- 将扫描出来的字符封装成Token，交给`Parse`转换成Event\n- 再将Event做封装成Node，将Node组成一棵树交给Spring\n- Spring再把树做扁平化处理，用于后续流程\n\n虽然在这里是自下向顶的，但是实际流程是**自顶向下**执行的。本文只为探究基本原理，因此源码中大量的细节未曾涉及，感兴趣的可以自行研究\n\n\n## 2021-09-23 补充\n\n实际上这就是一种状态机思想，我也使用这种思想实现了一个json库，具体参见[博客](http://blog.inkroom.cn/2021/09/23/AS44AY.html)\n\n","tags":["java","yaml","SpringBoot","snakeyaml"],"categories":["后端","java"]},{"title":"dubbo踩坑","url":"/2021/04/04/045R8S.html","content":"\n\n\n\n\n\n\n\n\n记录一下学习dubbo中踩的坑\n\n<!-- more -->\n\n### 版本\n\n版本务必要匹配，否则总会出一些问题，目前使用的版本如下：\n\n- openjdk version 11.0.10\n\n- SpringBoot: 2.1.6.RELEASE\n\n- dubbo: 2.7.7\n\n- dubbo-spring-boot-starter: 2.7.7\n\n- nacos-client: 1.4.1\n\n- dubbo-serialization-kryo: 2.7.9\n\n- com.github.briandilley.jsonrpc4j:jsonrpc4j:1.2.0 \n\n  > 仅在使用http协议时引用。高版本上**HttpException**访问权限为default\n\n- org.eclipse.jetty:jetty-servlet\n\n  > 注意，官网标定版本是6.1.26，但是此版本的groupdId和包名是[org.mortbay.jetty](https://mvnrepository.com/artifact/org.mortbay.jetty)\n\n\n\n整体基于**spring.properties**配置\n\n\n\nps: 在此必须骂一下dubbo的文档，dubbo高版本上已经在源码上集成了若干注册中心的代码，但是文档里居然还在要求引入相关的依赖，而且demo的版本还在0.0.2\n\n\n\n### 多协议\n\n官网上只列出了xml下的多协议\n\n经过测试，服务提供者spring配置应该如下\n\n```properties\n## 多出的协议写在这里\ndubbo.protocols.dubbo.port=20081\ndubbo.protocols.http.port=7845\n## 以下配置必须写，否则会报错\ndubbo.protocol.name=dubbo\ndubbo.protocol.port=10022\n\n## 以上配置会启动三个协议，分别是dubbo[10022]、http[7845]、dubbo[20081]\n```\n\n---\n\n某项服务如果提供了多协议，那么消费者默认都是dubbo协议，暂时没有找到切换的方法\n\n#### http协议踩坑\n\n在使用http协议时，消费者忘记引入**jsonrpc**，结果出现找不到服务提供者错误**No provider available for the service**，\n\n经过**一天** 的排查，问题出现在`org.apache.dubbo.registry.integration.RegistryDirectory:429`。由于`org.apache.dubbo.rpc.protocol.http.HttpProtocol`引入了**jsonrpc4j**的依赖\n\n---\n\ndubbo里的http协议意思是rpc过程通过http协议传输，对应的接口并不能对web提供，**哪怕**官网确实写了可以。想要实现需要使用**REST**协议，但是需要对代码作改动\n\n---\n\ndubbo-admin 测试不支持http协议，一旦只提供http协议的，测试就会出现服务找不到错误，但是消费者实际使用时没有问题\n\n\n\n### 日志\n\n配置项中务必加上\n\n```properties\ndubbo.application.logger=slf4j\n```\n\n\n\n否则 dubbo 不会输出日志\n\n### 多实现\n\n假设一个接口有多个实现，那么之间必须进行分组，否则只会注册一个实现。\n\n现在我有两个**FileStorage**的实现类\n\n分别注解如下\n\n```java\n@DubboService( protocol = \"http\", tag = \"minio\",group = \"minio\")\npublic class MinIOFileStorage implements FileStorage \n```\n\n```java\n@DubboService(protocol = \"http\",tag = \"qn\",interfaceClass = FileStorage.class,group = \"qn\")\npublic class QiNiuFileStorage implements FileStorage \n```\n\n**nacos** 显示如下\n\n![2021-04-05 15-11-23屏幕截图](/home/ink/图片/2021-04-05 15-11-23屏幕截图.png)\n\n\n\n但是在**dubbo-admin**中又只显示**qn**实现，只有一次显示了两个实现\n\n消费者引用如下\n\n```java\n    @DubboReference(group = \"minio\")\n    private FileStorage minioFileStorage;\n    @DubboReference(group = \"qn\")\n    private FileStorage qnFileStorage;\n```\n\n\n\n测试结果显示，两个变量都是 **QiNiuFileStorage** 的实现，查看nacos，消费者只订阅了**minio**\n\n![](/home/ink/图片/2021-04-05 15-13-20屏幕截图.png)\n\n多次测试后发现，此时是dubbo的负载均衡作祟，多个实现轮流调用\n\n\n\n测试后修改配置如下\n\n```java\n@DubboService( group = \"minio\")\n@Component\npublic class MinIOFileStorage implements FileStorage\n```\n\n```java\n@DubboService(group = \"qn\",path = \"qnFileStorage\")\npublic class QiNiuFileStorage implements FileStorage\n```\n\n```java\n@DubboReference(group = \"minio\")\nprivate FileStorage fileStorage;\n@DubboReference(group = \"qn\")\nprivate FileStorage qnFileStorage;\n```\n\n实际起作用的是**path = \"qnFileStorage\"**，怀疑可能是dubbo通过path去寻找对应的实现类，默认情况下path相同，被是为同一实现的不同实例，启用负载。\n\n但是**dubbo-admin** 仍然只能看到一个实现\n\n\n\n### 多版本\n\n当服务端配置了版本\n\n```pro\ndubbo.provider.version=1.0\ndubbo.provider.group=dev-third\n```\n\n消费者也必须指定版本\n\n```properties\ndubbo.consumer.group=dev-third\ndubbo.consumer.version=1.0\n```\n\n\n\n---\n\n文档上注明 不关注版本时可以 写成 *****\n\n但实际上 会出现以下错误\n\n```java\n[2021-04-11 15:45:02.552] [3.4.1] [DubboSaveMetadataReport-thread-1] [后台] [无] ERROR org.apache.dubbo.metadata.store.nacos.NacosMetadataReport :  [DUBBO] Failed to put consumer metadata org.apache.dubbo.metadata.report.identifier.MetadataIdentifier@2c1e3659;  {init=false, side=consumer, release=2.7.7, logger=slf4j, dubbo=2.0.2, interface=com.bcyunqian.yq.third.api.Bank4Identify, version=*, qos.enable=false, generic=true, timeout=5000, metadata-type=remote, application=service, sticky=false, group=dev-third}, cause: Failed to put org.apache.dubbo.metadata.report.identifier.MetadataIdentifier@2c1e3659 to nacos {\"init\":\"false\",\"side\":\"consumer\",\"release\":\"2.7.7\",\"logger\":\"slf4j\",\"dubbo\":\"2.0.2\",\"interface\":\"com.bcyunqian.yq.third.api.Bank4Identify\",\"version\":\"*\",\"qos.enable\":\"false\",\"generic\":\"true\",\"timeout\":\"5000\",\"metadata-type\":\"remote\",\"application\":\"service\",\"sticky\":\"false\",\"group\":\"dev-third\"}, cause: dataId invalid, dubbo version: 2.7.7, current host: 192.168.101.100\norg.apache.dubbo.rpc.RpcException: Failed to put org.apache.dubbo.metadata.report.identifier.MetadataIdentifier@2c1e3659 to nacos {\"init\":\"false\",\"side\":\"consumer\",\"release\":\"2.7.7\",\"logger\":\"slf4j\",\"dubbo\":\"2.0.2\",\"interface\":\"com.bcyunqian.yq.third.api.Bank4Identify\",\"version\":\"*\",\"qos.enable\":\"false\",\"generic\":\"true\",\"timeout\":\"5000\",\"metadata-type\":\"remote\",\"application\":\"service\",\"sticky\":\"false\",\"group\":\"dev-third\"}, cause: dataId invalid\n\tat org.apache.dubbo.metadata.store.nacos.NacosMetadataReport.storeMetadata(NacosMetadataReport.java:210)\n\tat org.apache.dubbo.metadata.store.nacos.NacosMetadataReport.doStoreConsumerMetadata(NacosMetadataReport.java:165)\n\tat org.apache.dubbo.metadata.report.support.AbstractMetadataReport.storeConsumerMetadataTask(AbstractMetadataReport.java:286)\n\tat org.apache.dubbo.metadata.report.support.AbstractMetadataReport.lambda$storeConsumerMetadata$1(AbstractMetadataReport.java:272)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: com.alibaba.nacos.api.exception.NacosException: dataId invalid\n\tat com.alibaba.nacos.client.config.utils.ParamUtils.checkKeyParam(ParamUtils.java:90)\n\tat com.alibaba.nacos.client.config.utils.ParamUtils.checkParam(ParamUtils.java:147)\n\tat com.alibaba.nacos.client.config.NacosConfigService.publishConfigInner(NacosConfigService.java:222)\n\tat com.alibaba.nacos.client.config.NacosConfigService.publishConfig(NacosConfigService.java:121)\n\tat com.alibaba.nacos.client.config.NacosConfigService.publishConfig(NacosConfigService.java:116)\n\tat org.apache.dubbo.metadata.store.nacos.NacosMetadataReport.storeMetadata(NacosMetadataReport.java:204)\n\t... 6 common frames omitted\n```\n\n可以看出 **nacos** 不支持该特性\n\n\n\n\n\n### 多次订阅\n\n在启用了**@EnableDubbo**以及**dubbo.consumer.generic=true**的情况下\n\n当同一个接口在不同的地方使用 **@DubboReference** ，会提示重复引入","tags":["java","dubbo","分布式"],"categories":["后端","java"]},{"title":"用户中心规划和实现","url":"/2021/03/17/31Q4EWQ.html","content":"\n应公司发展需要，现在需要实现单点登录，以保证多个系统之间的用户一致。\n\n故，本文旨在开发一个用户中心，以提供登录、注册、用户信息存储功能。\n\n<!-- more -->\n\n\n\n### 需求\n\n系统需求基本如下\n\n- 用户注册\n- 用户登录\n- 用户信息获取\n- 用户登出\n- 系统间的切换不再需要登录\n\n\n\n\n\n### 细节分析\n\n#### 登录\n\n登录总体采用**oauth2**协议完成\n\n#### 用户信息\n\n用户信息分成两块\n\n- 基本用户信息\n- 业务系统自有信息\n\n第二点由业务系统自行维护，不作处理。\n\n\n\n对于基本信息，应该由用户中心存储，业务系统需要使用时向用户中心申请，这样以便各个业务系统之间的信息一致\n\n如果需要修改，也应该交由用户中心或者通知用户中心\n\n\n\n#### 登出\n\n登出需要保证一处登出，所有系统一并登出。\n\n\n\n在此，设计思路是当用户在某一个业务系统，或者直接在用户中心登出时，用户中心登出用户并且通过http发送消息给所有登录了的业务系统，业务系统再把用户从自己系统中登出。\n\n\n\n注：该方案仅适用于业务系统在自己控制之下的情况\n\n\n\n#### 系统切换\n\n当用户在访问应用A的过程中，需要去访问应用B，此时中间应该会经过用户中心。用户中心某种手段，例如cookie，识别到当前登录的用户，直接跳转到应用B。\n\n一般情况下将用户中心将数据存入session，浏览器端使用cookie保存就可以了。\n\n但是cookie和session是有时限的，如果用户在应用A停留时间超过了这个时限，那么在经过用户中心的时候就会判断成未登录。\n\n\n\n所以问题就成了用户中心需要记住用户。\n\n结合上面的业务系统每次访问都需要请求用户中心，可以得知用户正处于活动中，这一流程是服务器间的交互，不经过浏览器。\n\n---\n\n用户中心这边\n\n首先，用户登录之后，生成一个随机字串和用户id绑定，即写入redis。\n\n然后将这个字串写入cookie，并保证cookie存活期为会话\n\n业务系统的每次访问，根据用户id去获取这个随机字串，不断延长其expire\n\n\n\n用户第二次进入用户中心，\n\n后台通过cookie里的随机字串，在redis中寻找是否存在一个用户id，如果存在，则直接认证通过\n\n---\n\n\n\n绑定关系为双向绑定，代表redis中需要存两个key\n\n\n\n### 流程\n\n\n\n#### 登录授权\n\n![授权](https://i.loli.net/2021/03/17/IlHZN4aLyOPzMRU.png)\n\n\n\n#### 登出\n\n![登出](https://i.loli.net/2021/03/17/IutEon6YsrGBTlV.png)\n\n\n\n### 实现\n\n**oauth2**协议并不复杂，此处略去不表，仅对网上少有资料的细节进行原理阐述。\n\n\n\n#### 授权码\n\n授权码的生成需要将使用范围限定为指定业务系统和指定用户，不能混用或共用，且有效期不宜过长。\n\n\n\n本次我不打算在用户中心保存授权码，而是采用类似**JWT**的实现方案。\n\n> 将信息以**json**形式存储，加上加密和签名，组成一个字符串交给业务系统\n\n---\n\n首先确定json格式，暂定需要以下内容\n\n- 业务系统id\n- 用户id\n- 授权时间\n\n\n\n以上字段保密性要求不高，不过还是可以加上加密。\n\n\n\n确定生成流程如下\n\n- 构建json数据\n- 进行对称加密\n- 将密文和业务系统的**client_secret**连接后进行签名\n- 将密文和签名按照规则(自定义)拼装后再**base64**编码\n\n最后得到的数据就是授权码，其中密文和签名的拼接规则自定义即可，只要保证后续解析时能够完整地把数据给拆分开就行。\n\n\n\n#### token\n\n\n\ntoken由于上述的登出功能限制，必须由用户中心进行保存。\n\n除此之外，token就没有什么特别的处理了，随便生成一个UUID，和user绑定起来就行了。\n\n\n\n\n\n","tags":["java","后端"],"categories":["后端","java"]},{"title":"logstash使用注意事项","url":"/2020/11/17/2VWHDY.html","content":"\n项目中使用elk作为日志采集方案，因此研究了一下 logstash 的使用\n\n<!-- more -->\n\n\n\n## 目录位置\n\n\n\n在 filter 中可以使用 **patterns_dir**， 如下所示\n\n```ruby\ngrok{\n        patterns_dir => [\"./pattern\"]\n        match =>{\"message\"=>\"%{LOG}\"}\n        overwrite =>[ \"message\" ]\n    }\n```\n\n\n\n**pattern** 存放位置取决于启动logstash时所在目录\n\n\n\n例如，我是在logstash根目录启动的，启动命令为 `./bin/logstash -f config/logstash.conf`；\n\n所以这个文件也应该放在根目录中。\n\n\n\n----\n\n如果使用了**./bin/system-install**，将logstash注册成了系统服务，使用**systemctl start logstash** 启动的，其工作目录位于系统根目录 **/**, 所以对应的文件位置也需要调整\n\n\n\n### 解决方案\n\n编辑 **/etc/systemd/system/logstash.service** ，把其中的 **WorkingDirectory** 修改成logstash所在目录\n\n修改前请务必确认服务处于**停止**状态\n\n\n\n","tags":["elk","logstash"],"categories":["后端"]},{"title":"SpringBoot对于配置项的读取和设置","url":"/2020/10/16/SR3GH3.html","content":"\n项目中需要对配置文件中的配置项进行加密，因此研究一下SpringBoot的配置项处理\n\n\n\n<!-- more -->\n\n\n\n## 前人栽树\n\n搜索了一下，常用的配置项加密方案是**[jasypt](https://github.com/ulisesbocchio/jasypt-spring-boot)**；\n\n这是一个已经完善的方案，基本上直接引入就可以用了。但是项目中要求的加解密算法比较特殊，不能用这个项目，因此需要研究一下。\n\n## 配置项读取\n\nSpringBoot中配置项读取是使用`ConfigFileApplicationListener`实现了，最终会将配置项封装到`PropertySource`的实现类里。\n\n## 配置项使用\n\n读取到配置项后，需要把值给到各个bean。其中主要负责是通过`PropertySouurcesPropertyResolver`实现的，其中这个类负责提供配置项，同时还需要处理占位符等。\n\n----\n\n现在找到了读取和设置，但是还是不清楚其中的数据是如何流动的。\n\n通过对`PropertySourcesPropertyResolver`的构造方法进行debug，发现其在`AbstractEnviorment`、`LoggingSystemProperties`、`PropertSourcesPlaceholderConfiurer`被创建了实例。\n\n环境类中创建的**Resolver** ，没有给存储了配置项的`PropertySource`\n\n```java\npackage org.springframework.core.env;\npublic abstract class AbstractEnvironment implements ConfigurableEnvironment {\n\t\tprivate final ConfigurablePropertyResolver propertyResolver =\n\t\t\tnew PropertySourcesPropertyResolver(this.propertySources);  \n}\n```\n\n\n\n所以没有多大意义。\n\n\n\n另外两个类给传入的参数都是基本一致的，从类名推测，重点研究对象应该是`PropertSourcesPlaceholderConfiurer`\n\n### `PropertySourcesPlaceholderConfiurer\n\n\n\n重点方法如下\n\n\n\n```java\n/**\n\t * Processing occurs by replacing ${...} placeholders in bean definitions by resolving each\n\t * against this configurer's set of {@link PropertySources}, which includes:\n\t * <ul>\n\t * <li>all {@linkplain org.springframework.core.env.ConfigurableEnvironment#getPropertySources\n\t * environment property sources}, if an {@code Environment} {@linkplain #setEnvironment is present}\n\t * <li>{@linkplain #mergeProperties merged local properties}, if {@linkplain #setLocation any}\n\t * {@linkplain #setLocations have} {@linkplain #setProperties been}\n\t * {@linkplain #setPropertiesArray specified}\n\t * <li>any property sources set by calling {@link #setPropertySources}\n\t * </ul>\n\t * <p>If {@link #setPropertySources} is called, <strong>environment and local properties will be\n\t * ignored</strong>. This method is designed to give the user fine-grained control over property\n\t * sources, and once set, the configurer makes no assumptions about adding additional sources.\n\t */\n\t@Override\n\tpublic void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {\n\t\tif (this.propertySources == null) {\n\t\t\tthis.propertySources = new MutablePropertySources();\n\t\t\tif (this.environment != null) {\n\t\t\t\tthis.propertySources.addLast(\n\t\t\t\t\tnew PropertySource<Environment>(ENVIRONMENT_PROPERTIES_PROPERTY_SOURCE_NAME, this.environment) {\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\t@Nullable\n\t\t\t\t\t\tpublic String getProperty(String key) {\n\t\t\t\t\t\t\treturn this.source.getProperty(key);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tPropertySource<?> localPropertySource =\n\t\t\t\t\t\tnew PropertiesPropertySource(LOCAL_PROPERTIES_PROPERTY_SOURCE_NAME, mergeProperties());\n\t\t\t\tif (this.localOverride) {\n\t\t\t\t\tthis.propertySources.addFirst(localPropertySource);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tthis.propertySources.addLast(localPropertySource);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\tthrow new BeanInitializationException(\"Could not load properties\", ex);\n\t\t\t}\n\t\t}\n\n\t\tprocessProperties(beanFactory, new PropertySourcesPropertyResolver(this.propertySources));\n\t\tthis.appliedPropertySources = this.propertySources;\n\t}\n/**\n\t * Visit each bean definition in the given bean factory and attempt to replace ${...} property\n\t * placeholders with values from the given properties.\n\t */\n\tprotected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess,\n\t\t\tfinal ConfigurablePropertyResolver propertyResolver) throws BeansException {\n\n\t\tpropertyResolver.setPlaceholderPrefix(this.placeholderPrefix);\n\t\tpropertyResolver.setPlaceholderSuffix(this.placeholderSuffix);\n\t\tpropertyResolver.setValueSeparator(this.valueSeparator);\n\n\t\tStringValueResolver valueResolver = strVal -> {\n\t\t\tString resolved = (this.ignoreUnresolvablePlaceholders ?\n\t\t\t\t\tpropertyResolver.resolvePlaceholders(strVal) :\n\t\t\t\t\tpropertyResolver.resolveRequiredPlaceholders(strVal));\n\t\t\tif (this.trimValues) {\n\t\t\t\tresolved = resolved.trim();\n\t\t\t}\n\t\t\treturn (resolved.equals(this.nullValue) ? null : resolved);\n\t\t};\n// 将对象实例注入到Spring容器中\n\t\tdoProcessProperties(beanFactoryToProcess, valueResolver);\n\t}\n\nprotected void doProcessProperties(ConfigurableListableBeanFactory beanFactoryToProcess,\n\t\t\tStringValueResolver valueResolver) {\n\n\t\tBeanDefinitionVisitor visitor = new BeanDefinitionVisitor(valueResolver);\n\n\t\tString[] beanNames = beanFactoryToProcess.getBeanDefinitionNames();\n\t\tfor (String curName : beanNames) {\n\t\t\t// Check that we're not parsing our own bean definition,\n\t\t\t// to avoid failing on unresolvable placeholders in properties file locations.\n\t\t\tif (!(curName.equals(this.beanName) && beanFactoryToProcess.equals(this.beanFactory))) {\n\t\t\t\tBeanDefinition bd = beanFactoryToProcess.getBeanDefinition(curName);\n\t\t\t\ttry {\n\t\t\t\t\tvisitor.visitBeanDefinition(bd);\n\t\t\t\t}\n\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\tthrow new BeanDefinitionStoreException(bd.getResourceDescription(), curName, ex.getMessage(), ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// New in Spring 2.5: resolve placeholders in alias target names and aliases as well.\n\t\tbeanFactoryToProcess.resolveAliases(valueResolver);\n\n\t\t// New in Spring 3.0: resolve placeholders in embedded values such as annotation attributes.\n\t\tbeanFactoryToProcess.addEmbeddedValueResolver(valueResolver);\n\t}\n```\n\n\n\n在`PropertySourcesPlaceholderConfigurer`中，有两个重要属性：`MutablePropertySources propertySources`、`Environment environment`\n\n其中`environment`就存储了配置项，而`propertySources`在方法刚执行时是null。在方法中还涉及到配置来源优先级覆盖的问题\n\n---\n\n从代码中可以看出来，实际上注入容器的是`StringValueResolver`的匿名子类，原本的类反倒没有直接注入。\n\n\n\n## 实现一\n\n很容易可以看出，我们可以从第二个方法，也就是`protected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess,\n\t\t\tfinal ConfigurablePropertyResolver propertyResolver) throws BeansException `下手。\n\n\n\n编写相关代码如下\n\n```java\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.BeansException;\nimport org.springframework.beans.factory.config.ConfigurableListableBeanFactory;\nimport org.springframework.context.support.PropertySourcesPlaceholderConfigurer;\nimport org.springframework.core.env.ConfigurablePropertyResolver;\nimport org.springframework.util.StringValueResolver;\n\npublic class EncryptPropertySourcesPlaceholderConfigurer extends PropertySourcesPlaceholderConfigurer {\n\n    private Logger logger = LoggerFactory.getLogger(getClass());\n\n    @Override\n    protected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, ConfigurablePropertyResolver propertyResolver) throws BeansException {\n\n        logger.debug(\"生成自定义注释\");\n\n\n        propertyResolver.setPlaceholderPrefix(this.placeholderPrefix);\n        propertyResolver.setPlaceholderSuffix(this.placeholderSuffix);\n        propertyResolver.setValueSeparator(this.valueSeparator);\n\n        StringValueResolver valueResolver = strVal -> {\n\n            String resolved = (this.ignoreUnresolvablePlaceholders ?\n                    propertyResolver.resolvePlaceholders(strVal) :\n                    propertyResolver.resolveRequiredPlaceholders(strVal));\n            if (this.trimValues) {\n                resolved = resolved.trim();\n            }\n            String s = (resolved.equals(this.nullValue) ? null : resolved);\n            logger.debug(\"key={},v={}\", strVal,resolved);\n\n            if (s != null && s.startsWith(\"enc\")) {\n               //修改\n                return \"jsdofasudfawpjtwuit8\";\n            }\n            return s;\n        };\n\n        doProcessProperties(beanFactoryToProcess, valueResolver);\n\n\n//        super.processProperties(beanFactoryToProcess, propertyResolver);\n    }\n}\n```\n\n\n\n注入\n\n```java\n@Bean(\"propertySourcesPlaceholderConfigurer\")\npublic static PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer() {\n\treturn new EncryptPropertySourcesPlaceholderConfigurer();\n}\n```\n\nSpring通过`StringValueResolver`来实现配置项的注入。\n\n要特别注意，这个类实际负责的范围很广。除了注入配置项，还有uri，beanName之类的也在处理\n\n可以从输出日志中看出来\n\n```text\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=singleton,v=singleton\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration,v=org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=tomcatWebServerFactoryCustomizer,v=tomcatWebServerFactoryCustomizer\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,v=org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=multipartResolver,v=multipartResolver\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=,v=\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=org.springframework.boot.autoconfigure.web.servlet.MultipartProperties,v=org.springframework.boot.autoconfigure.web.servlet.MultipartProperties\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=,v=\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=taskExecutor,v=taskExecutor\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=applicationTaskExecutor,v=applicationTaskExecutor\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=${seal.header.vid},v=HNCA\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=${hn.unit.unify},v=false\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=#{ @environment['shiro.loginUrl'] ?: '/login.jsp' },v=#{ @environment['shiro.loginUrl'] ?: '/login.jsp' }\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=#{ @environment['shiro.successUrl'] ?: '/' },v=#{ @environment['shiro.successUrl'] ?: '/' }\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=#{ @environment['shiro.unauthorizedUrl'] ?: null },v=#{ @environment['shiro.unauthorizedUrl'] ?: null }\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=${sms.max.send-time},v=5\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=${seal.root-data-path},v=/Users/apple\\seal\\temp\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=/bind/certificate,v=/bind/certificate\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=/search/list,v=/search/list\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=/swagger-resources,v=/swagger-resources\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=${server.error.path:${error.path:/error}},v=/error\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=${server.error.path:${error.path:/error}},v=/error\n[EncryptPropertySourcesPlaceholderConfigurer:lambda$processProperties$0:34] [DEBUG] - key=/v2/api-docs,v=/v2/api-docs\n```\n\n----\n\n当然，这个方案也有一定的缺点。\n\n首先，由于解密是在获取配置项之后，因此，如果明文中使用了占位符，就无法获取对应的数据。\n\n其次，由于Spring的机制问题，这种方案更适用于 `@Value`注入参数的配置项，对于像 jdbc 这类配置就完全不可行。\n\n\n\n\n\n---\n\n**2021-07-23 补充**\n\n我在尝试实现一个需求 替换配置文件中的某个配置项时，发现一个更为简洁的方案。\b\n\n步骤如下\n\n- 创建一个`EnvironmentPostProcessor`实现类，基本代码如下\n> ```java\n> public class PortEnvironmentPostProcessor implements EnvironmentPostProcessor {\n>     @Override\n>     public void postProcessEnvironment(ConfigurableEnvironment environment, S> pringApplication application) {\n>         Properties properties = new Properties();\n>         int availableTcpPort = SocketUtils.findAvailableTcpPort(6001, 12999);\n> \n>         properties.put(\"management.server.port\",availableTcpPort);\n>         properties.put(\"eureka.instance.metadata-map.management.port\",availableTcpPort);\n>         PropertiesPropertySource source = new PropertiesPropertySource(\"CONSUME\", properties);\n>         environment.getPropertySources().addFirst(source);\n>     }\n> }\n> \n> ```\n\n- 创建**META-INF/spring.factories**文件，内容如下\n> org.springframework.boot.env.EnvironmentPostProcessor=cn.inkroom.study.cloud.gateway.PortEnvironmentPostProcessor\n\n\n需要特别注明几点：\n\n- 是否覆盖原本配置文件中的某个配置项是有调用**addFirst**还是**addLast**方法决定的，越在前面的优先级越高\n- 默认情况下，自定义的`PortEnvironmentPostProcessor`总是在第一个被调用，因此无法获取其他配置项，意思是不能用于加解密，但是可以用于提供一些来自别的途径，较为动态的配置项\n\n\n\n","tags":["SpringBoot","配置项读取","源码"],"categories":["后端","java","SpringBoot"]},{"title":"jpackage打包javafx","url":"/2020/09/30/6ZJYGK.html","content":"\n<!-- more -->\n\n\n\n## 基本打包命令\n\n\n\n```\njpackage -t app-image -i /Users/apple/resource/project/java/seal_client/applet/target/applet-1.0.21/ --java-options --add-modules=javafx.controls,javafx.swing,javafx.fxml,javafx.web --java-options -Dloader.path=lib/ -n applet --main-class com.hongding.seal.pc.applet.AppletApplication --main-jar applet.jar\n```\n\n要求 javafx sdk 放到 对应的 mods 目录下\n\n\n\n### 配置项处理\n\n#### 日志\n\nmac下相对路径失效，最好使用 user.home\n\n\n\n因此实现一个 配置项加载器处理配置项"},{"title":"jlink精简jre","url":"/2020/09/24/1SHCBJP.html","content":"\njdk9以后提供了模块化方案，利用此方案可以实现jre的精简。但是我在实现过程中遇到了很多问题\n\n\n\n<!-- more -->\n\n\n\n### 环境\n\n- oracleJdk11\n- maven3.6.1\n- Idea2020.1.1\n\n### 情况概述\n\n我创建了三个模块**model**、**service**、**entry**，相互之间依赖关系如下\n\n![165608FC-ACAA-438A-8184-645423DE2621.png](https://i.loli.net/2020/09/24/MAejKSubiQgndqc.png)\n\n其中**slf4j.api**是**service**模块中引入的第三方依赖\n\n---\n\n将三个模块打包后，找到生成的jar文件，将三个jar放在同一个文件夹中。\n\n然后执行命令\n\n```sehll\n./jlink -p /Users/apple/resource/project/java/jdk11/target/:/Library/Java/JavaVirtualMachines/jdk-11.0.7.jdk/Contents/Home/jmods --add-modules jdk11.entry --output /Users/apple/resource/project/java/jdk11/target --launcher entry=jdk11.entry/cn.inkroom.entry.Enry\n```\n\n\n\n其中：\n\n- **/Users/apple/resource/project/java/jdk11/target/** 代表放置了三个jar的文件夹目录\n- **/Library/Java/JavaVirtualMachines/jdk-11.0.7.jdk/Contents/Home/jmods** jdk的模块目录\n- **--add-modules jdk11.entry** 启动模块，这个模块内有main方法\n- **--launcher entry=jdk11.entry/cn.inkroom.entry.Enry** 启动方法，等号前内容随便写\n\n---\n\n第一次执行结果如下：\n\n```\n错误: Module slf4j.api not found, required by jdk11.service\n```\n\n推测是因为引入了第三方依赖，但是找不到。因此找到项目中的第三方依赖的jar，放到和之前的三个jar相同的目录中。\n\n---\n\n再次执行命令如下：\n\n```\n错误: 自动模块不能用于来自 file:///Users/apple/resource/project/java/jdk11/target/logback-core-1.2.3.jar 的 jlink: logback.core\n```\n\n这里错误就比较麻烦了。意思是jlink只支持命名模块，不支持自动模块。真的不理解java社区的思路，不支持自动模块，那生态里的一大堆jar都等着别人升级到jdk11？这个jlink搞得还有多大意义\n\n---\n\n经过我百般搜索，最终找到一篇[博客](https://blog.csdn.net/hlm2016/article/details/102065694)\n\n总体思路是通过插件给自动模块补充**module-info.java**，但是这会有非常多的问题。\n\n以我这里用的**slf4j**举例，**slf4j**因为其实现原理的原因，其jar实际上是不太完整的，缺少了一些实现类，因此在生成module-info时，需要补上具体实现了**slf4j**的依赖。\n\n然后在打包的过程中，插件就会下载这些相关依赖，非常耗时。\n\n\n\n当然，耗时其实影响不大。真正影响大的是需要给所有的自动模块补充module-info，换句话说，本来应该给类库维护者的工作给加到自己身上，如果项目中用到的依赖较多，这个工作量非常大；而且由于不同类库的实现不同，还可能出现类似**slf4j**这种必须了解其实现细节才能补充的情况。\n\n\n\n### 总结\n\n就目前的情况来看，jlink实在是一个鸡肋。\n\n首先就普通web项目来说，精简jre并没有什么意义，不差那点空间；而且假设一台机器上要部署多个不同的服务，多个jre只会让维护混乱。\n\n其次，目前大多数类库都没有实现模块化，导致jlink无法向下分析，也拆不出合适的模块。\n\n","tags":["java","后端","jre"],"categories":["后端","java"]},{"title":"mybatis是如何将mapper接口注册到spring","url":"/2020/09/21/2FNKG2W.html","content":"\n\n\n今天看了篇博客，就是这个标题，但是说得不够清楚。我在研究源码后补上部分细节\n\n<!-- more -->\n\n\n\n在阅读本篇博客前，需要阅读 [这篇博客](https://my.oschina.net/10000000000/blog/4614571)\n\n---\n\n\n\n### MapperScannerRegistrar\n\nmybatis通过该类注入一个 `BeanDefinitionRegistryPostProcessor` 的实现类 `MapperScannerConfigurer`\n\n\n\n### MapperScannerConfigurer\n\n这个类主要读取了mybatis的一些配置信息，并且创建一个`ClassPathMapperScanner`用于对包进行扫描\n\n### ClassPathMapperScanner\n\n这个类负责路径扫描，但是不负责实例创建和代理\n\n### MapperFactoryBean\n\n这里负责实例的创建，但是最终该任务会被交给`MapperRegistry`，`MapperRegistry`会通过`MapperProxyFactory`创建一个代理。\n\n### MapperProxyFactory\n\n通过`MapperProxy`实现代理，所以逻辑都在`MapperProxy`里\n\n### MapperMethod\n\n在`MapperProxy`里会创建`MapperMethod`，这个类才是执行相关方法的核心类\n\n","tags":["java","后端","mybatis"],"categories":["后端","java"]},{"title":"恼人的bom头","url":"/2020/09/16/BK9VX0.html","content":"\n\n\n**65279** ，记事本中常见的bom头。\n\n万万没想到，居然出现在了数据里。\n\n<!-- more -->\n\n\n\n前两天程序突然出现了一个字符串判等错误。原本以为是客户填错了，后来翻数据一看，这怎么俩字符串一模一样？\n\n---\n\n\n\n本来就是一个**equals**返回false的问题。看数据是相同的字符串，然后去翻日志，日志里也是相同的。\n\n\n\n尝试了很多办法都没看出有什么不同。\n\n\n\n于是后来一气之下一个字符一个字符的判断过去，结果就发现了问题所在。\n\n\n\n两个字符串居然**长度不一样**，有一个字符串开头多出一个不可见字符，将字符转成int后发现，这第一个字符就是**65279**。\n\n\n\n这东西就是**bom头**，我经常看到的地方就是各种文本编辑器保存文件的时候可能会加上这个头。\n\n\n\n---\n\n\n\n所以其实这个问题解决方案就很简单，把数据改一下就行了。\n\n\n\n但是这个头是怎么出来的呢？出问题的字符串来源是一个不应该被修改过的数据，而这个数据在以前是可行的，这就很奇怪。\n\n\n\n当时得出结论已经快下班了，于是就保留事故现场，第二天再来找源头。\n\n\n\n结果第二天上班之后发现，这个问题又消失了，客户已经正常使用了。\n\n\n\n---\n\n\n\n事故现场消失，无法排查原因，只能做些推测。\n\n\n\n数据是存储在redis中的，怀疑是序列化中出现问题，序列化方案是**FastJson**提供的序列化工具类`GenericFastJsonRedisSerializer`\n\n","categories":["后端","java"]},{"title":"单元测试方式执行次数的断言","url":"/2020/07/06/MTZ194.html","content":"\n\n\n关于`org.mockito.Mockito.verify()`方法断言调用次数的一些细节\n\n\n\n<!-- more -->\n\n\n\n### 背景\n\n```java\n/**\n     * Verifies certain behavior happened at least once / exact number of times / never. E.g:\n     * <pre class=\"code\"><code class=\"java\">\n     *   verify(mock, times(5)).someMethod(\"was called five times\");\n     *\n     *   verify(mock, atLeast(2)).someMethod(\"was called at least two times\");\n     *\n     *   //you can use flexible argument matchers, e.g:\n     *   verify(mock, atLeastOnce()).someMethod(<b>anyString()</b>);\n     * </code></pre>\n     *\n     * <b>times(1) is the default</b> and can be omitted\n     * <p>\n     * Arguments passed are compared using <code>equals()</code> method.\n     * Read about {@link ArgumentCaptor} or {@link ArgumentMatcher} to find out other ways of matching / asserting arguments passed.\n     * <p>\n     *\n     * @param mock to be verified\n     * @param mode times(x), atLeastOnce() or never()\n     *\n     * @return mock object itself\n     */\n    @CheckReturnValue\n    public static <T> T verify(T mock, VerificationMode mode) {\n        return MOCKITO_CORE.verify(mock, mode);\n    }\n```\n\n\n\n方法注释中只写了第二个参数的使用方式，但是没有指出第二个参数的生命周期。\n\n---\n\n因此我有以下问题：\n\n- 多次执行被mock方法后，只调用一次`verify`，其次数如何断言？\n- 同一个被mock bean，通过改变被mock方法的参数调用，`verify`如何分别断言不同参数的调用？\n- 相同的mock调用(不改变参数)，和`verify`交叉调用，次数应该如何断言，即次数是否会累计计算？\n\n\n\n### 实验\n\n#### 问题1：\n\n**多次执行被mock方法后，只调用一次`verify`，其次数如何断言？**\n\n代码如下：\n\n```java\nConsumeHandler handler = mock(ConsumeHandler.class);\n\nhandler.consume(null,null,null,10);\nhandler.consume(null,null,null,10);\nhandler.consume(null,null,null,10);\nhandler.consume(null,null,null,10);\n\n\nverify(handler,times(4)).consume(isNull(),isNull(),isNull(),eq(10));\nverify(handler,times(4)).consume(isNull(),isNull(),isNull(),eq(10));\n```\n\n**总结：**\n\n单纯的调用`verify`，其次数确实和调用次数相关；要特别注意的是，多次`verify`次数是累计计算，并不会出现因为上次`verify`了而重新开始计算\n\n\n\n#### 问题2：\n\n**同一个被mock bean，通过改变被mock方法的参数调用，`verify`如何分别断言不同参数的调用？**\n\n代码如下：\n\n```java\nConsumeHandler handler = mock(ConsumeHandler.class);\n\n\nhandler.consume(null,null,null,10);\nhandler.consume(null,null,null,1);\nhandler.consume(null,null,null,1);\nhandler.consume(null,null,null,14);\n\n\nverify(handler,times(1)).consume(isNull(),isNull(),isNull(),eq(10));\nverify(handler,times(2)).consume(isNull(),isNull(),isNull(),eq(1));\nverify(handler,times(4)).consume(isNull(),isNull(),isNull(),anyInt());\n```\n\n**总结：**\n\n次数和参数相关，只有满足了参数匹配的调用才会被计算次数\n\n\n\n#### 问题3：\n\n**相同的mock调用(不改变参数)，和`verify`交叉调用，次数应该如何断言，即次数是否会累计计算？**\n\n代码如下：\n\n```java\nConsumeHandler handler = mock(ConsumeHandler.class);\n\n\nhandler.consume(null,null,null,10);\n\nverify(handler,times(1)).consume(isNull(),isNull(),isNull(),eq(10));\n\nhandler.consume(null,null,null,10);\n\nverify(handler,times(2)).consume(isNull(),isNull(),isNull(),eq(10));\n\nhandler.consume(null,null,null,10);\nhandler.consume(null,null,null,10);\n\nverify(handler,times(4)).consume(isNull(),isNull(),isNull(),eq(10));\n```\n\n**总结：**\n\n可以看出，次数只和调用`verify`之前，执行了多少次符合参数匹配的方式有关，与`verify`调用次数无关\n\n\n\n","tags":["java","后端","单元测试"],"categories":["后端","java"]},{"title":"使用装饰模式实现多种扣费方式","url":"/2020/07/01/23AVPCZ.html","content":"\n利用装饰模式实现多种扣费方式，利于扩展。\n\n<!-- more -->\n\n\n\n## 背景\n\n项目中有个扣费功能。原本是直接从用户本身扣费，最近新增的需求要求从别的地方扣费。那么就要对原本的扣费流程进行修改，最基本的方式就是直接 if else，但是本次使用装饰模式来实现该功能。\n\n\n\n优点在于后期可以扩展更多扣费方式，而且可以简单地调整扣费方式的优先级，同时有利于简化调用方的代码。\n\n\n\n## 实现\n\n装饰模式首先要求有一个接口，这个接口给调用方使用。调用方只需要持有接口的一个实例对象即可。\n\n### 接口\n\n那么接口定义如下（隐去部分业务相关代码）：\n\n\n\n```java\n/**\n * 负责签署时扣除次数，使用装饰模式\n */\npublic interface ConsumeHandler {\n\n    /**\n     * 扣除次数\n     *\n     * @param user\n     * @param count     需要扣除的次数\n     * @return 返回扣除后剩余的次数；\n     */\n    int consume(User user, int count);\n\n}\n```\n\n**返回值**\n\n项目中扣除的是次数，若有需要扣除其他都是同理。\n\n每一个处理器返回的值代表从当前途径扣除的次数；这样做的好处在于，可以允许同时使用多种方式支付，只要所有资金来源加起来能够超过需要扣除的次数，那么一定能扣除成功，不至于强求一次支付成功。\n\n**参数**\n\n`count`代表需要**当前**处理器扣除的次数。注意是**当前**，不是总计次数。\n\n**举例**\n\n假设有处理器A和处理器B，目前要扣除12次，扣除顺序为A->B。\n\n\n\n基于装饰模式，应该由B来调用A\n\n那么B接收次数为**12**次，调用A，告诉A需要扣除**12次**\n\nA执行逻辑，扣除**5**次，返回**7**\n\nB拿到**7**，判断剩余次数不为**0**，需要自身扣除**7**次。\n\nB扣除完成，返回给调用方**0**\n\n调用方接收到扣除结果**0**，扣费成功。\n\n\n\n### 抽象类\n\n装饰模式有一些通用逻辑，例如都需要接收一个上级参数。本次中还有一个判断当前是否应该继续扣费的逻辑，因此额外写一个抽象类实现这些逻辑。\n\n\n\n```java\n\npublic abstract class AbstractConsumeHandler implements ConsumeHandler {\n\n\n    protected ConsumeHandler parent;\n\n    public AbstractConsumeHandler(ConsumeHandler parent) {\n        this.parent = parent;\n    }\n\n    @Override\n    public int consume(User user, int count) {\n   \t  //扣费完成\n        if (count == 0) return count;\n        int c = count;\n        if (this.parent != null) {\n            c = this.parent.consume(contract, signatory, user, count);\n            if (c == 0) {//扣费完毕\n                return 0;\n            }\n        }\n        int myCount = c;\n\n//        继续扣费\n        c = consumeCount(contract, signatory, user, myCount);\n\n        return myCount - c;\n    }\n\n    /**\n     * 子类需要重写的方法，用于实际扣除次数；子类不需要考虑次数是否扣除完毕的问题\n     *\n     * @param user\n     * @param count     当前处理器需要扣除的次数\n     * @return 返回当前处理器扣除的次数\n     */\n    public abstract int consumeCount( User user, int count);\n\n\n}\n\n```\n\n\n\n实际处理器，只需要继承抽象类，并且直接实现扣费逻辑即可。\n\n\n\n## 注入\n\n项目基于**SpringBoot**开发，需要一种友好的方式注入实例。\n\n\n\n本来想直接通过`@Component`之类的注解注入处理器实例，但是这样一来不好注入上级实例，不利于调整优先级；二来调用方不方便选择注入实例。\n\n\n\n所以还是只能通过配置类手动注入\n\n\n\n```java\n    /**\n     * 注入次数消费处理器\n     *\n     * @return\n     */\n    @Bean\n    public ConsumeHandler consumeHandler(AgentService agentService, UserService userService) {\n\n//        优先级高的放前面\n        AgentCountConsumeHandler agentCountConsumeHandler = new AgentCountConsumeHandler(null);\n\n        agentCountConsumeHandler.setService(agentService);\n\n        UserCountConsumeHandler userCountConsumeHandler = new UserCountConsumeHandler(agentCountConsumeHandler);\n        userCountConsumeHandler.setUserService(userService);\n\n        return userCountConsumeHandler;\n    }\n```\n\n\n\n这种注入方式较为死板，处理器本身依赖的外部组件只能手动set，且失去了一层代理，可能部分切面功能无法使用。\n\n## 注意事项\n\n如果采用多种途径共同扣费逻辑，需要特别处理事务回滚相关。因为每一个处理器都不能知道最终结果是否会扣费成功，因此自身都会进行数据持久化操作。只有调用方知道是否扣费成功，此时方能进行回滚操作\n\n\n\n","tags":["java","后端","设计模式"],"categories":["后端"]},{"title":"数组越界下标翻转","url":"/2020/05/28/3NZ0KXT.html","content":"\n简单的数学知识\n\n<!-- more -->\n\n### 向上翻转\n\n新下标 = (当前下标 + 数组长度 - 1) % 数组长度\n\n---\n\n例如：\n\n当前下标0，数组长度5。则：\n\n( 0 + 5 - 1 ) % 5 = 4\n\n\n\n### 向下翻转\n\n新下标 = (当前下标 + 1) % 数组长度\n\n\n\n\n\n"},{"title":"日志采集","url":"/2020/05/18/126CEWS.html","content":"\n随着互联网的发展，网络基础设置的改善，人们对于网络应用提出了更高的要求，于是各大互联网公司纷纷采用分布式架构以支持越来越高的并发量。由分布式架构引出来的日志问题也越来越突出。在单机环境下可以正常使用的日志解决方案在分布式环境下表现的有心无力。因此本系统的目的在于提供一个更加友好的日志采集和存储方案。\n本文分几部分阐述了基于Java开发，涉及消息中间件，socket短连接等技术的日志采集系统的结构和设计实现过程，实现了日志发送、日志存储、日志备份、日志实时浏览等功能。支持横向扩展，可以轻松实现分布式部署。同时充分考虑了宕机情况的出现，尽可能地保证系统核心功能的正常运行。\n根据本文设计思路，最终开发出一个健壮、稳定的日志采集系统。\n\n<!-- more -->\n\n\n## 概述\n\n### 原理\n\n软件客户端发送日志消息到消息中间件，采集模块从消息中间件中拿取数据，存入时序数据库，并且定时备份日志文件到本地文件系统，同时利用WebSocket等技术实现日志的实时浏览。\n\n\n### 功能\n\n#### 日志发送\n\n软件客户端通过本系统提供的工具发送日志消息到指定的消息中间件，且在一定程度上保证有序。\n\n#### 日志收集\n\n本系统通过监听消息中间件，即使拿取日志消息，并且按照一定的规则进行持久化存储。\n\n#### 服务监控\n\n本系统提供Web模块以监控采集模块以及相关服务运行状况。\n\n#### 日志备份\n\n本系统可以定期将日志持久化到文件，存储在本地文件系统。同时提供相应的下载接口\n\n#### 实时日志浏览\n\n本系统提供接口以实时查看消息中间件接收到的日志消息，同时支持简单的规则过滤，并保证在一定程度下日志消息有序，以便开发人员调试。\n\n#### 宕机记录\n\n可通过本系统查看相应日志生产者宕机情况\n\n## 环境\n\n涉及到的环境\n\n- jdk1.8+\n- ActiveMq\n- Influxdb\n\n\n## 设计\n\n### 架构\u0010\n\n![系统架构](https://user-images.githubusercontent.com/27911304/82168048-3e1ecb80-98f0-11ea-8f64-e8592e97f03f.png)\n\n\n\n![流程图](https://user-images.githubusercontent.com/27911304/82168151-a53c8000-98f0-11ea-98d6-7307b519efd5.png)\n\n#### client\n\n供日志产生端使用的工具模块。思路为自定义日志组件消息通道，目前支持log4j框架；以及直接读入程序日志文件。该模块需要对现有Java项目进行一定程序的修改。\n\n#### MQ\n\n消息中间件依赖。用于中转日志以及服务状态监控等数据通信领域。\n\n#### Server\n\n日志采集模块。负责监听消息中间件，将日志消息持久化到TSDB，同时负责按照一定的周期备份日志文件到本地文件系统或其他存储系统。\n\n该模块支持横向扩展，只需要多台机器保持消息中间件等相关配置一致即可。\n\n#### WEB\n\n图形化界面模块。B/S架构。该模块以Web界面方式提供监控Server模块状态、日志文件下载、系统报警和实时日志浏览等功能。\n\n该模块非必需模块，缺失或宕机不影响日志采集存储功能。\n\n#### TSDB\n\n时序数据库。用于临时存储日志消息，以解决使用消息中间件通讯中由于网络抖动等原因导致的顺序错位。\n\n\n\n### 通信方案\n\n本系统使用了四种通信方式\n\n- JMS——主要用于Client-MQ-Server。\n- HTTP协议——Web模块对用户提供服务。\n- Socket——Web和Server直接通信，主要用于文件传输。\n- WebSocket——用于Web模块浏览实时日志\n\n\n\n![client-MQ-Server](https://user-images.githubusercontent.com/27911304/82168320-1b40e700-98f1-11ea-9cc6-952fe013ae38.png)\n\n![Web-User](https://user-images.githubusercontent.com/27911304/82168325-209e3180-98f1-11ea-906d-1a36e6e15e95.png)\n\n![Client-Web](https://user-images.githubusercontent.com/27911304/82168332-23992200-98f1-11ea-8afd-105f03851967.png)\n\n\n\n## 可行性分析\n\n解释部分设计原理和难点解决方案\n\n### 日志发送方式\n\n引入消息中间件作为通信桥梁，使用队列模式\n\n**优点**\n\n- 日志生产者和消费者解耦\n- 日志消费者可以横向扩展\n\n**缺点**\n\n- 日志消费者无法保证日志有序\n\n\n\n### Java程序如何接入\n\n- 如果是基于slf4j的程序，只需要引入一个appender，修改日志配置即可\n- 或者基于文件监控，需要在服务器上额外部署一个服务(不推荐)\n\n### 如何保证日志有序\n\n引入时序数据库，日志消费者将从中间件获取的日志存储到时序数据库，由时序数据库负责排序和临时存储。消费者再每隔一段时间从数据库获取数据，依次保证在这段时间间隔内的日志尽可能有序。\n\n### 如何实现日志实时浏览\n\n- 日志消费者在从**queue**中获取数据后，再以**topic**形式发送出去\n- Web模块订阅**topic**，一旦接收到日志消息，则以**WebSocket**方式进行广播\n- 前端通过**WebSocket**和后端进行全双工通信\n\n### 如何降低耦合\n\n**耦合来源**\n\n- 消息中间件\n- 时序数据库\n\n**解决方案**\n\n使用设计模式实现相关实现的可替换。可参考slf4j不同日志输出组件的原理\n\n\n\n## 健壮性分析\n\n- 消息中间件\n\n消息中间件宕机将会影响Client发送日志，此时Client需要将日志缓存到本地，等待消息中间件恢复之后将日志消息重新发送。\n\n- Client\n\nClient宕机即代表终端服务宕机，此时不会产生日志，且终端服务宕机应该有另外的报警方案，不在本系统设计考虑范围内。\n\n- Server\n\nServer支持横向扩展，单一机器宕机只会影响日志采集效率，不会导致系统全线崩溃。\n\n- Web\n\n该模块为非必需模块，宕机不会影响日志采集功能，因此不在考虑范围内；建议使用额外的方案以监听该模块状态，例如定时发送HTTP请求即可判断模块运行状态。\n\n- TSDB\n\n时序数据库宕机将会导致Server无法持久化，此时Server将会把采集到的日志返还到消息中间件，不采用缓存方案，防止此时Server宕机导致缓存的日志丢失。\n\n\n\n## 实现\n\n### 数据库设计\n\n![Web模块](https://user-images.githubusercontent.com/27911304/82169128-10875180-98f3-11ea-8ffd-bd0d51e46702.png)\n\n![Server模块](https://user-images.githubusercontent.com/27911304/82169134-154c0580-98f3-11ea-9b97-7683a33f216d.png)\n\n![时序数据库](https://user-images.githubusercontent.com/27911304/82169137-167d3280-98f3-11ea-8c6a-58779faeb1ea.png)\n\n\n\n### 源码\n\n本系统已托管在**github**，项目地址为：[https://github.com/inkroom/log-colleage/](https://github.com/inkroom/log-colleage/)\n\n\n","tags":["java","后端","log","日志采集"],"categories":["后端","java"]},{"title":"dream","url":"//dream.html","content":"\n今天——或者说昨天晚上——做了一个很有意思的梦。一言以概之，就是一个套娃的梦。\n\n<!-- more -->\n\n---\n\n我正在本睡半醒间，忽然感觉到床在晃动。\n\n我心知是地震了，准备赶紧起床。但是整个人却困得不行，连眼睛都睁不开。赶忙抓住床边的楼梯，强行将自己拽起来，眼睛还是完全睁不开。\n\n从床上坐起来，没有脚碰到地板的冰凉。明白了自己是在做梦，想起影视剧里判断自己做梦都是掐一下自己。我也掐了我的左手臂，果然没有任何痛觉。不，我甚至连我的手臂都感觉不到，不只是手臂，我连自己身体的任何部位都感觉不到。我就是个旁观者。我果然是在做梦。\n\n----\n\n头又睡在枕头上了，摇晃还是没有停止。这回肯定不是做梦了，虽然眼睛还是睁不开。\n\n依旧靠着楼梯坐起来，感觉到了地板的冰凉。努力睁开了眼睛，在房间里走了几步；觉察到不对劲，还是在做梦\n\n---\n\n这次一下子就睁开了眼睛。在床上翻来覆去，确定自己终于醒过来了。\n\n\n\nend\n\n---\n\n---\n\n这种梦中梦，明白自己在做梦的经历我已经有过很多回了。正好最近博客搭建好了，就顺便记录一下；只可惜写下文章的时候已经过去了十几个小时，梦里的内容已经记不大清了。\n\n以后还有这种梦的话，可以一并记录一下，看能不能凑个连续剧。\n\n\n\n\n\n\n\n","tags":["梦","梦中梦","private"],"categories":["private","生活"]},{"title":"基于netty的文件传输","url":"/2020/05/15/1BZHG4N.html","content":"\n项目中需要迁移一部分文件，原计划通过ftp上传；但是服务器环境中ftp传输总是有问题，因此自己开发一个文件传输服务\n\n<!-- more -->\n\n## 设计\n\n本次任务中需要实现一个文件传输程序，不需要额外的功能。\n\n\n---\n\n\n程序分为 **server** 端和 **client** 端\n\nserver 采用netty实现；client采用原生socket即可\n\n\n---\n\n传输中涉及协议定义；协议主要是为了方便扩展，如果只是一个简单的文件传输，那么只需要用socket即可\n\n\n协议定义如下\n\n- 开头四个byte 用于存储本次帧长度\n- 后续字节采用json格式，如下\n```json\n{\n    \"type\":\"本次协议的操作\",\n    \"data\":\"协议的数据，一般是文件的base64\"\n}\n\n```\n\n\n## 实现\n\n### server\n\n只展示核心的 pipline 实现\n\n``` java\n\nprotected void initChannel(SocketChannel socketChannel) throws Exception {\n    socketChannel.pipeline().addLast(\n            new StringEncoder(),\n            new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4),\n            new StringDecoder(CharsetUtil.UTF_8),\n            new SimpleChannelInboundHandler<String>() {\n\n                protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n\n                    logger.debug(\"收到消息:{}\", msg);\n                    JSONObject json = JSONObject.parseObject(msg);\n                    String body = null;\n                    if (json.getString(\"type\").equals(\"check\")) {//校验文件是否存在\n\n                        String path = json.getString(\"msg\");\n\n                        body = new File(dir, path).exists() + \"\";\n                    } else if (json.getString(\"type\").equals(\"upload\")) {//文件上传\n                        String path = json.getString(\"msg\");\n                        String data = json.getString(\"data\");//文件base64\n                        File file = new File(dir, path);\n                        if (!file.getParentFile().exists()) {\n                            file.getParentFile().mkdirs();\n                        }\n    //                                                base64解码\n                        byte[] bytes = Base64.decodeBase64(data);\n                        try (FileOutputStream out = new FileOutputStream(file)) {\n                            IOUtils.write(bytes, out);\n                        }\n                        body = \"ok\";\n                        logger.debug(\"upload write\");\n                    } else if (json.getString(\"type\").equals(\"download\")) {\n                        String path = json.getString(\"msg\");\n                        File file = new File(dir, path);\n                        JSONObject j = new JSONObject();\n                        if (file.exists()) {\n                            j.put(\"r\", \"true\");\n                            j.put(\"data\", Base64.encodeBase64String(IOUtils.toByteArray(new FileInputStream(file))));\n                        } else {\n                            j.put(\"r\", \"false\");\n                        }\n                        body = j.toJSONString();\n                        logger.debug(\"download {}\", j.toString());\n                    }\n\n                    int length = body.getBytes().length;\n    //                                            首先写一个长度\n                    byte[] bytes = new byte[4];\n                    //通过移位运算，截取低8位的方式，将int保存到byte数组\n                    bytes[0] = (byte) (length >>> 24);\n                    bytes[1] = (byte) (length >>> 16);\n                    bytes[2] = (byte) (length >>> 8);\n                    bytes[3] = (byte) length;\n\n                    logger.debug(\"写入长度={}\", length);\n                    ByteBuf buf = Unpooled.buffer(4 + length).writeBytes(bytes).writeBytes(body.getBytes());\n                    ctx.writeAndFlush(buf);\n    //                                            ctx.writeAndFlush(bytes);\n    //                                            ctx.writeAndFlush(Unpooled.copiedBuffer((body).getBytes()));\n\n                }\n            }\n    );\n}\n```\n\n\n\n---\n\n其中较为重要的是对数据的拆包，用到了 `new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)`\n\n依次解释参数\n- Integer.MAX_VALUE 数据包的最大长度\n- 0 字节偏移量，代表帧与帧之间是否有间隔，此次为0即可\n- 4 代表长度字段的字节数，本次使用**int**存储长度，因此是4个长度\n- 0 \n- 4 交给下一个handler的数据跳过的字节数。例如一个帧 携带的数据长度 20 字节，加上长度，一共是 24 字节；此处为4，代表拆包器交给下一个handler的数据会跳过4个字节，从下标4处开始读取长度字段大小的字节数据，也就是20个字节\n\n\n\n--- \n\n`new StringDecoder(CharsetUtil.UTF_8)`  此处是对数据进行解码，后续handler可以直接使用字符串，其参数来自于`LengthFieldBasedFrameDecoder`读取的数据\n\n---\n\n最后一个就是处理器，其获取的数据就是json格式，直接处理即可；\n\n需要注意的是数据返回。返回给client的数据也要遵循协议，即开头4个字节代表数据大小\n\n此处采用了对int进行位运算的方案，而不是调用更为方便的 `writeInt(int)` 方法；\n\n因为该方法并不会一定写入四个字节，而是写入当前int实际占据的字节数。例如本次数据长度为 2，那么实际只会写入一个字节；因为int占据4个字节，但是 2 只会用到32位低位的两位，netty只会写入一个字节\n\n\n### client\n\nclient端采取原生的socket实现。\n\n```java\n\n  private String send(JSONObject json) throws IOException {\n        String body = json.toJSONString();\n        int length = body.length();\n        Socket socket = new Socket(properties.getHost(), properties.getPort());\n        socket.getOutputStream().write(int2Bytes(length));\n        socket.getOutputStream().write(body.getBytes());\n\n// 读取长度\n\n        byte[] le = new byte[4];\n        InputStream input = socket.getInputStream();\n\n        length = input.read(le, 0, 4);\n        logger.debug(\"[netty] - 读取长度的字节长度={}\", length);\n        if (length != 4) {\n            throw new AppMsgException(\"错误的包数据\");\n        }\n        length = bytes2Int(le);\n\n        logger.debug(\"[netty] - 包的长度={}\", length);\n        byte[] bytes = new byte[length];\n\n        byte[] cache = new byte[65535];//缓冲区大小\n        int readLength = 0;\n        do {\n            int t = input.read(cache, 0, cache.length);\n            for (int i = 0; i < t; i++, readLength++) {\n                bytes[readLength] = cache[i];\n            }\n        } while (readLength != length);\n        socket.close();\n        return new String(bytes);\n    }\n\n```\n\n\n---\n\n基本逻辑是——建立链接->发送数据->读取返回\n\n`socket.getOutputStream().write(int2Bytes(length));` 这一行的原理同上述返回，都是确保一定写入了4个字节\n\n\n读取内容也较为简单，也是先读取四个字节，然后再读取指定长度的数据\n\n\n注意 原生socket 缓冲区大小有限制，即使指定读取 50 个字节，也可能无法读取到足够的数据，因此需要循环读取，保证能够读取到指定长度的数据\n\n---\n\n最后再提一下，socket连接尽量不要使用多线程。我就因为把`Socket`作为成员变量，然后多线程操作，结果导致数据读取老是出错\n\n","tags":["java","netty"],"categories":["后端","java"]},{"title":"java security","url":"/2020/05/13/21DB9B8.html","content":"\n\n\n**该博文有问题，请无视**\n\n\n\n\n\n<!-- more -->\n\n\n\n## 背景\n\n项目上需要使用证书做pdf签章，引入了bc库。在单元测试时，签章正常通过，tomcat运行时，加载证书失败\n\n## 出错位置追溯\n\n问题出现在一下代码第二行中\n``` java\n    protected void loadKeyStore(InputStream pfx, String password) throws Exception {\n        keyStore = KeyStore.getInstance(\"PKCS12\");\n        keyStore.load(pfx, password.toCharArray());\n        this.loadKeyStore(keyStore, password);\n    }\n\n```\n\n---\n\n分别的单元测试环境、Tomcat环境中debug后发现，`keyStore`这个变量中有个成员变量`keyStoreSpi` 对应的具体实现不同。\n\n在单元测试中是 `sun.security.pkcs12.PKCS12KeyStore`，而在tomcat中是一个bc库中的实现。\n\n那么原因可能找到了，对应的实现不同导致的。\n\n---\n\n问题是：为什么这个变量会经常换？\n\n## 源码debug\n\n\n\n查看`KeyStore#getInstance` 方法，其内部依次调用了 `Security.getImpl`、`Providers.getProviderList()`\n\n具体如下\n\n```java\n\n public static GetInstance.Instance getInstance(String var0, Class<?> var1, String var2) throws NoSuchAlgorithmException {\n        ProviderList var3 = Providers.getProviderList();\n        Service var4 = var3.getService(var0, var2);\n        if (var4 == null) {\n            throw new NoSuchAlgorithmException(var2 + \" \" + var0 + \" not available\");\n        } else {\n            try {\n                return getInstance(var4, var1);\n            } catch (NoSuchAlgorithmException var10) {\n                NoSuchAlgorithmException var5 = var10;\n                Iterator var6 = var3.getServices(var0, var2).iterator();\n\n                while(true) {\n                    Service var7;\n                    do {\n                        if (!var6.hasNext()) {\n                            throw var5;\n                        }\n\n                        var7 = (Service)var6.next();\n                    } while(var7 == var4);\n\n                    try {\n                        return getInstance(var7, var1);\n                    } catch (NoSuchAlgorithmException var9) {\n                        var5 = var9;\n                    }\n                }\n            }\n        }\n    }\n\n\n```\n\n注意其中的第二行，`var3.getService(var0,var1)`，这里是需要获取一个`KeyStore`实现，其中的var0=KeyStore，var2=PKCS12\n\n\n最后返回了一个`java.security.Provider$Service`，这个会生成一个`PKCS12KeyStore`，从而正确签章\n\n\n## 解决思路\n\n查看了`KeyStore`源码后，发现其`getInstance`支持如下重载\n```java\npublic static KeyStore getInstance(String type, Provider provider)\n        throws KeyStoreException, NoSuchProviderException;\n```\n\n\n那么重点就在于其第二个参数，如果能够传入生成`PKCS12KeyStore`的值，问题不就解决了？\n\n\n\n## 解决方案\n\n现在需要获取一个`Provider`实现，\n\n根据debug的结果，其寻找 Provider 在于`ProviderList`的的userList属性。\n\n\ndebug之后发现，其在单元测试环境下，userList数据如下\n\n```\n\n\nproviders size=11\nprovider=SUN version 1.8\nprovider=SunRsaSign version 1.8\nprovider=SunEC version 1.8\nprovider=SunJSSE version 1.8\nprovider=SunJCE version 1.8\nprovider=SunJGSS version 1.8\nprovider=SunSASL version 1.8\nprovider=XMLDSig version 1.8\nprovider=SunPCSC version 1.8\nprovider=SunMSCAPI version 1.8\nprovider=BC version 1.6\n\n```\n\ntomcat环境下如下\n\n```\nproviders size=11\nprovider=SUN version 1.8\nprovider=BC version 1.6\nprovider=SunRsaSign version 1.8\nprovider=SunEC version 1.8\nprovider=SunJSSE version 1.8\nprovider=SunJCE version 1.8\nprovider=SunJGSS version 1.8\nprovider=SunSASL version 1.8\nprovider=XMLDSig version 1.8\nprovider=SunPCSC version 1.8\nprovider=SunMSCAPI version 1.8\n\n```\n\n很明显可以看出 bc 库的顺序不对，这个大概就是根源了。\n\n---\n\n单元测试下需要对应的索引为**3**，即为**SunJSSE**，这是`Provider`的name属性\n\n\n\n\n**解决失败**\n\n虽然确实换了spi 属性，但是tomcat下依然失败","tags":["java","后端","加密"],"categories":["后端","java"]},{"title":"SpringBoot依赖外置","url":"/2020/05/13/2Q6VVTX.html","content":"\n\n\n近期有个SpringBoot的项目需要频繁更新，但是每次上传到服务器上几十MB，实在是花时间，所以打算优化打包方案，将第三方依赖外置\n\n\n\n<!-- more -->\n\n### 背景\n\n近期有个SpringBoot的项目需要频繁更新，但是每次上传到服务器上几十MB，实在是花时间，所以打算优化打包方案，将第三方依赖外置\n\n### 流程\n\n- 首先使用SpringBoot打包插件将第三方排除，但是一些版本号同步更新的本地模块依赖需要放到一个jar中\n- 使用maven dependency插件将第三方依赖复制到构建目录中\n- 使用maven过滤功能实现一个启动脚本\n- 使用assembly打包一个完整版，包括boot jar，第三方依赖，启动脚本\n- 第一次部署使用完整版，后续更新只需要上传boot jar就行了\n\n\n### 实现方法\n\n\n\n首先在 **resource** 目录中准备一个脚本\n\n内容如下\n\n```\njava -Dloader.path=lib/ -Dfile.encoding=utf-8 -jar @project.build.finalName@.jar\n\n```\n\n其中 **@project.build.finalName@** 是最后生成的可执行jar的文件名\npath指定第三方依赖目录\n\n---\n\n\n其次修改pom文件如下\n\n```xml\n\n    <build>\n        <resources>\n            <resource>\n            <!-- 启用maven过滤，主要为脚本做准备 -->\n                <directory>src/main/resources</directory>\n                <filtering>true</filtering>\n             </resource>\n        </resources>\n\n        <finalName>${project.artifactId}-${project.version}-${spring.active}</finalName>\n\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <configuration>\n                    <mainClass>xxx.Application</mainClass>\n\n                    <layout>ZIP</layout>\n                    <executable>true</executable>\n                    <includes>\n                    <!-- 以下为需要打包到jar中的本地模块依赖，主要是版本号需要更新，如果放到第三方依赖中，可能会出现多个版本  -->\n                        <include>\n                            <groupId>xxx.xxx</groupId>\n                            <artifactId>upload-starter</artifactId>\n                        </include>\n                        <include>\n                            <groupId>xxx.xxx</groupId>\n                            <artifactId>pay</artifactId>\n                        </include>\n                        <include>\n                            <groupId>${project.parent.groupId}</groupId>\n                            <artifactId>swagger-starter</artifactId>\n                        </include>\n                    </includes>\n\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-dependency-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <id>copy-dependencies</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>copy-dependencies</goal>\n                        </goals>\n                        <configuration>\n          <!-- 输出的第三方依赖位置 -->          <outputDirectory>${project.build.directory}/lib</outputDirectory>\n                            <overWriteReleases>false</overWriteReleases>\n                            <!-- 此处排除需要打到boot jar中的本地模块依赖 -->\n                            <excludeGroupIds>\n                                ${project.parent.groupId},xxx.xxx\n                            </excludeGroupIds>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-assembly-plugin</artifactId>\n                <configuration>\n                    <descriptors>\n                        <descriptor>assembly.xml</descriptor>\n                    </descriptors>\n                </configuration>\n                <executions>\n                    <execution><!-- 配置执行器 -->\n                        <id>make-assembly</id>\n                        <phase>package</phase><!-- 绑定到package生命周期阶段上 -->\n                        <goals>\n                            <goal>single</goal><!-- 只运行一次 -->\n                        </goals>\n\n                        <!--                        <configuration>-->\n                        <!--                            <finalName>${project.name}</finalName>-->\n\n                        <!--                            <descriptor>src/main/assembly.xml</descriptor>&lt;!&ndash;配置描述文件路径&ndash;&gt;-->\n                        <!--                        </configuration>-->\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n```\n\n---\n\n在 **pom.xml** 同级目录创建 **assembly.xml**\n\n内容如下\n```xml\n<assembly>\n    <id>release</id>\n    <formats>\n        <format>zip</format><!--打包的文件格式,也可以有：war zip-->\n    </formats>\n    <!--tar.gz压缩包下是否生成和项目名相同的根目录-->\n    <includeBaseDirectory>false</includeBaseDirectory>\n    \n    <!-- 如果使用这个，也可以不使用maven-dependency插件 -->\n<!--    <dependencySets>-->\n<!--        <dependencySet>-->\n<!--            &lt;!&ndash;是否把本项目添加到依赖文件夹下&ndash;&gt;-->\n<!--            <useProjectArtifact>true</useProjectArtifact>-->\n<!--            <outputDirectory>lib</outputDirectory>-->\n<!--            &lt;!&ndash;将scope为runtime的依赖包打包&ndash;&gt;-->\n<!--            <scope>runtime</scope>-->\n<!--        </dependencySet>-->\n<!--    </dependencySets>-->\n    <fileSets>\n        <fileSet>\n            <directory>${project.build.directory}/lib</directory>\n            <outputDirectory>/lib</outputDirectory>\n        </fileSet>\n    </fileSets>\n    <files>\n        <file>\n            <source>target/${build.finalName}.jar</source>\n            <outputDirectory>/</outputDirectory>\n        </file>\n        <file>\n           <!-- 此处将脚本复制两份，分别对应类unix和windows系统，注意，maven过滤之后的文件在target目录下 -->\n            <source>${project.build.directory}/classes/start.sh</source>\n            <outputDirectory>/</outputDirectory>\n            <destName>start.bat</destName>\n        </file>\n        <file>\n            <source>${project.build.directory}/classes/start.sh</source>\n            <outputDirectory>/</outputDirectory>\n            <destName>start.sh</destName>\n        </file>\n    </files>\n</assembly>\n\n\n```\n\n### 最终效果\n\n![TIM图片20191205091306](https://user-images.githubusercontent.com/27911304/70195072-87fb6700-173f-11ea-8431-e96d6b92690e.png)\n\n\n可以很明显的看出两个方式打包的大小差异\n\n---\n\n完整版的目录结构\n![04ACB025-7C19-4a98-9351-2E6AD9007E23](https://user-images.githubusercontent.com/27911304/70195270-30113000-1740-11ea-8a3d-db9eed190719.png)\n\n\n\n---- \n\n#### 2021-04-30 补充\n\n\n\n**maven-dependency-plugin** 的**exclude**对于包的判断有些与众不同\n\n项目包名为`com.bc`，然后有个依赖包为 `com.bc.uc` 结果我发现这个依赖包**不会**被copy。\n\n因此只能放弃 copy 插件，改为使用 assembly 提供的依赖copy，这样还少了一次copy操作\n\n#### 2021-07-19 补充\n\n使用**assembly**或者**maven-dependency-plugin**有个问题，会把scope为**test**的依赖一并copy打包，指定scope=runtime也不好用，于是升级插件版本到3.3.0，就ok了\n\n但是**maven-dependency-plugin**有`<includeScpre>`可以排除test环境的包\n\n","tags":["java","后端","SpringBoot","maven"],"categories":["后端","java","SpringBoot"]},{"title":"idea无法识别SpringBoot @占位符","url":"/2020/05/13/VRVDZ9.html","content":"\n\n\nidea部分情况下出现不识别占位符\n\n<!-- more -->\n\n\n\n### 背景\n\nidea下启动SpringBoot项目\n\n配置文件中使用了@@占位符获取maven中的配置项\n\nidea启动时报错\n\n```\n'@' that cannot start any token. (Do not use @ for indentation)\n```\n\n### 解决方案\n\npom.xml中添加如下内容\n```xml\n   <resources>\n            <resource>\n                <directory>src/main/resources</directory>\n                <filtering>true</filtering>\n            </resource>\n        </resources>\n```\n\n`plugins`中添加如下内容\n\n```xml\n\n <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-resources-plugin</artifactId>\n                <version>2.7</version>\n                <configuration>\n                    <delimiters>\n                        <delimiter>@</delimiter>\n                    </delimiters>\n                    <useDefaultDelimiters>false</useDefaultDelimiters>\n                </configuration>\n            </plugin>\n\n```\n\n---\n如果上述方案不奏效，可以尝试执行`mvn spring-boot:run` 之后就不会出错了\n\n或者可以直接修改target/classes/application.yml 文件\n\n\n### 参考资料\n[原来你不是这样的BUG(1):found character '@' that cannot start any token. (Do not use @ for indentation)](https://www.jianshu.com/p/a77b48166327)","tags":["java","后端","idea"],"categories":["后端"]},{"title":"SpringBoot实现jsonp跨域","url":"/2020/05/13/20T898X.html","content":"\n\n\n优雅实现跨域通信，对代码侵入性小\n\n\n\n<!-- more -->\n\n\n\n## 实现jsonp跨域通信\n\n> 实现基于jsonp的跨域通信方案\n\n\n### 原理\n\n> 浏览器对非同源ajax请求有限制，不允许发送跨域请求  \n> 目前跨域解决方案有两种   \n> - cros配置\n> - jsonp请求\n>\n> cros为新规范，通过一个head请求询问服务器是否允许跨域，若不允许则被拦截   \n> jsonp则为利用浏览器不限制js脚本的同源性，通过动态创建script请求，服务器传递回一个js函数调用语法，浏览器端按照js函数正常调用回调函数\n>\n\n\n###  实现思路\n\n首先确定服务器端应该如何返回数据\n\n一次正确的jsonp请求，服务器端应该返回如下格式数据\n\n```javascript\n\njQuery39948237({key:3})\n\n```\n\n其中，`jQuery39948237`为浏览器端要执行的函数名，该函数由ajax库动态创建，并将函数名作为一个请求参数和该次请求的其余参数一并发送，服务器端无需对此参数做过多处理\n\n`{key:3}`为此次请求返回的数据，作为函数参数传递\n\n---\n其次，服务器端如何处理？\n\n为了兼容jsonp和cros方案，服务器端应该在请求带有函数名参数时返回函数调用，否则正常返回json数据即可\n\n---\n\n最后，为了减少代码的侵入，不应该将上述流程放入一个Controller正常逻辑中，应该考虑使用aop实现\n\n\n### 实现\n\n#### 前端\n\n前端本次使用jquery库 ~~(本来想用axios库的，但是axios不支持jsonp)~~\n\n代码如下\n\n```javascript\n\n   $.ajax({\n        url:'http://localhost:8999/boot/dto',\n        dataType:\"jsonp\",\n        success:(response)=>{\n            this.messages.push(response);\n        }\n    })\n\n```\n\nJquery默认jsonp函数名参数name为**callback**\n\n#### 后端\n\n本次采用aop实现\n\n具体思路为: 给Controller添加后切点，判断request是否有函数名参数，如果有则修改返回的数据，没有则不做处理\n\n而aop又有两种方案\n\n- 常规aop，自己定义切点\n- `ResponseBodyAdvice`，Spring提供的可直接用于数据返回的工具类\n\n本次使用第二种方案\n\n----\n\n首先是Controller的接口实现\n\n```java\n@RequestMapping(\"dto\")\npublic Position dto() {\n    return new Position(239, 43);\n}\n```\n\n返回一个复杂类型，Spring会自动对其做json序列化操作\n\n---\n\n然后的`ResponseBodyAdvice`实现\n\n该类全路径为：`org.springframework.web.servlet.mvc.method.annotation.ResponseBodyAdvice`\n\n```java\n\n/**\n * 处理controller返回值，对于有callback值的使用jsonp格式，其余不处理\n */\n@RestControllerAdvice(basePackageClasses = IndexController.class)\npublic class JsonpAdvice implements ResponseBodyAdvice {\n\n    private Logger logger = LoggerFactory.getLogger(getClass());\n    @Autowired\n    private ObjectMapper mapper;\n\n    //jquery默认是callback，其余jsonp库可能不一样\n    private final String callBackKey = \"callback\";\n\n    @Override\n    public boolean supports(MethodParameter methodParameter, Class aClass) {\n        logger.debug(\"返回的class={}\", aClass);\n        return true;\n    }\n\n    /**\n     * 在此处对返回值进行处理，需要特别注意如果是非String类型，会被Json序列化，从而添加了双引号，解决办法见\n     *\n     * @param body               返回值\n     * @param methodParameter    方法参数\n     * @param mediaType          当前contentType，非String类型为json\n     * @param aClass             convert的class\n     * @param serverHttpRequest  request，暂时支持是ServletServerHttpRequest类型，其余类型将会原样返回\n     * @param serverHttpResponse response\n     * @return 如果body是String类型，加上方法头后返回，如果是其他类型，序列化后返回\n     * @see com.inkbox.boot.demo.converter.Jackson2HttpMessageConverter\n     */\n    @Override\n    public Object beforeBodyWrite(Object body, MethodParameter methodParameter, MediaType mediaType, Class aClass, ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse) {\n\n        if (body == null)\n            return null;\n        // 如果返回String类型，media是plain，否则是json，将会经过json序列化，在下方返回纯字符串之后依然会被序列化，就会添上多余的双引号\n        logger.debug(\"body={},request={},response={},media={}\", body, serverHttpRequest, serverHttpResponse, mediaType.getSubtype());\n\n\n        if (serverHttpRequest instanceof ServletServerHttpRequest) {\n            HttpServletRequest request = ((ServletServerHttpRequest) serverHttpRequest).getServletRequest();\n\n            String callback = request.getParameter(callBackKey);\n\n            if (!StringUtils.isEmpty(callback)) {\n                //使用了jsonp\n                if (body instanceof String) {\n                    return callback + \"(\\\"\" + body + \"\\\")\";\n                } else {\n                    try {\n                        String res = mapper.writeValueAsString(body);\n                        logger.debug(\"转化后的返回值={},{}\", res, callback + \"(\" + res + \")\");\n\n                        return callback + \"(\" + res + \")\";\n                    } catch (JsonProcessingException e) {\n                        logger.warn(\"【jsonp支持】数据body序列化失败\", e);\n                        return body;\n                    }\n                }\n            }\n        } else {\n            logger.warn(\"【jsonp支持】不支持的request class  ={}\", serverHttpRequest.getClass());\n        }\n        return body;\n    }\n}\n```\n\n使用`@RestControllerAdvice`指明切点\n\n\n### bug\n\n经过此步骤，理论上即可实现jsonp调用了。\n\n然而实际测试发现，由于Spring json序列化策略的问题，如果返回jsonp字符串，json序列化之后，将会添上一对引号，如下\n\n应该返回\n\n```javascript\nJquery332({\"x\":239,\"y\":43})\n```\n实际返回\n```javascript\n\"Jquery332({\\\"x\\\":239,\\\"y\\\":43})\"\n\n```\n\n导致浏览器端无法正常运行函数\n\n---\n\n经多方查找资料后得知\n\n由于在`ResponseBodyAdvice`中修改了实际的返回值类型为`String`，而字符串类型经过`Jackson`序列化后就会加上引号\n\n解决办法为：修改默认的json序列化`MessageConverter`处理逻辑，对于实际是`String`的不做处理\n\n代码如下\n\n```java\n@Component\npublic class Jackson2HttpMessageConverter extends MappingJackson2HttpMessageConverter {\n\n    private Logger logger = LoggerFactory.getLogger(getClass());\n\n    @Override\n    protected void writeInternal(Object object, Type type, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException {\n        if (object instanceof String) {\n            //绕开实际上返回的String类型，不序列化\n            Charset charset = this.getDefaultCharset();\n            StreamUtils.copy((String) object, charset, outputMessage.getBody());\n        } else {\n            super.writeInternal(object, type, outputMessage);\n        }\n    }\n}\n\n\n@Configuration\npublic class MvcConfig implements WebMvcConfigurer {\n\n    private Logger logger = LoggerFactory.getLogger(getClass());\n\n    @Autowired\n    private MappingJackson2HttpMessageConverter converter;\n\n    @Override\n    public void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n//        MappingJackson2HttpMessageConverter converter = mappingJackson2HttpMessageConverter();\n        converter.setSupportedMediaTypes(new LinkedList<MediaType>() {{\n            add(MediaType.TEXT_HTML);\n            add(MediaType.APPLICATION_JSON_UTF8);\n        }});\n        converters.add(new StringHttpMessageConverter(StandardCharsets.UTF_8));\n        converters.add(converter);\n    }\n}\n\n```\n\n---\n\n**2021-07-23 补充**\n\n再次使用该方案实现某功能时，由于我忘了已经解决过双引号问题，于是我又想办法解决了一次，这次的方案更加简单，代码如下\n\n\n```\n @Bean\npublic MappingJackson2HttpMessageConverter jackson2HttpMessageConverter() {\n    ObjectMapper objectMapper = new ObjectMapper();\n    SimpleModule module = new SimpleModule();\n  //    处理long类型，防止前台出现精度丢失问题\n    module.addSerializer(Long.class, new JsonSerializer<Long>() {\n        @Override\n        public void serialize(Long anEnum, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {\n            jsonGenerator.writeString(String.valueOf(anEnum));\n        }\n    });\n\n    module.addSerializer(String.class, new JsonSerializer<String>() {\n        //用于处理返回一个String类型时，不加上双引号\n        @Override\n        public void serialize(String value, JsonGenerator gen, SerializerProvider serializers) throws IOException {\n            if (gen.getOutputContext().getParent() == null) {//单纯的序列化一个字符串，而非一个field对应的value\n                gen.writeRaw(value);\n            } else\n                gen.writeString(value);\n\n        }\n    });\n    objectMapper.registerModule(module);\n\n    return new MappingJackson2HttpMessageConverter(objectMapper);\n}\n\n```\n\n这次是对序列化工具`ObjectMapper`下手，该方案更加友好，而且`ObjectMapper`还可以用在别的地方，不单局限在类型转换上\n\n\n\n### 代码\n\n具体实现可查阅[github](https://github.com/inkroom/SpringBoot-study/commit/3eb6e25ecc905d8528c0d1efe11ccb818070727e)\n\n\n","tags":["java","SpringBoot","跨域"],"categories":["后端","java","SpringBoot"]},{"title":"vue纯数字input","url":"/2020/05/13/1REFGMK.html","content":"\n\n\nvue实现只能输入数字\n\n\n\n<!-- more -->\n\n\n\n最近项目中需要实现一个元和分的转换，要求存储使用分，显示使用元。意外发现了一个实现input 只能输入纯数字的方案\n\n---\n``` vue\n computed: {\n    money: {\n      //pay-content组件金额以分为单位，当前组件以元为单位，因此需要转换\n      get() {\n        //返回元为单位\n        return this.payData.totalAmount / 100;\n      },\n      set(value) {\n        this.payData.totalAmount = parseFloat(value) * 100;\n        console.log(\n          `money set ${value} ${parseFloat(value)} this.total=${\n            this.payData.totalAmount\n          }`\n        );\n        // if(value.endsWith('.')){\n        //   this.payData.totalAmount = parseFloat(value.substring()) * 100;\n        // }\n      }\n    }\n  },\n```","tags":["前端","vue"],"categories":["前端"]},{"title":"mysql事务冲突","url":"/2020/05/13/14DPE6D.html","content":"\n开启了事务的情况下mysql如何处理插入\n\n<!-- more -->\n\n\n## 背景\n\n有两个事务，流程为先查询后添加；关键字段有唯一约束\n\n\n当事务A开始执行，添加了一条数据，但是尚未提交。\n\n此时事务B进入，查询数据不存在，然后添加一条事务A添加的数据。\n\n---\n\n那么问题是，如果事务A未提交，事务B提交，事务B是否会抛违背唯一约束，具体是在什么时候抛出来的。\n\n## 事实\n\n以下是项目中相关操作的时间：\n\n> A事务开始时间  2020-04-29 14:05:03:881 \n> 第一次查询     2020-04-29 14:05:03.888\n> 第一次用户添加 2020-04-29 14:05:03.986\n> B事务开始时间  2020-04-29 14:05:03.925 \n> 第二次查询     2020-04-29 14:05:03.928\n> 第二次事务添加 2020-04-29 14:05:04.031\n> A事务结束时间  2020-04-29 14:05:05.616\n> 异常时间       2020-04-29 14:05:05.620\n> B事务结束时间  2020-04-29 14:05:05.627\n\n\n期间两次查询结果均为空\n\n---\n\n可以看出，两次事务的添加操作执行了类似串行化的逻辑，第二次添加应该是阻塞了，待事务A提交后，第二次添加就立刻抛出了异常。\n\n\n为了验证以上推测，开启实验\n\n## 验证\n\n开启两个mysql 会话，模拟上述步骤。\n| 事务A| 事务B|\n| ------------- | ---------------------------------------- |\n| start transaction |   | \n| select id from user where phone ='123'  |   | \n| insert into user (id,phone) values (90,'123') |   | \n|  | start transaction | \n|  | insert into user (id,phone) values (91,'123') | \n| commit |  | \n| | uniqe key error |\n\n![transaction](https://user-images.githubusercontent.com/27911304/80572909-a5ec9f80-8a31-11ea-9904-2cd2b2219e4b.gif)\n\n## 原理\n\n在事务A中，通过**insert**语句，给phone=123这一行添加了行锁，事务B同样操作这一行，就会出现阻塞。事务A提交之后，锁就被释放，事务B就能获取到锁\n\n","tags":["后端","mysql","数据库"],"categories":["后端","数据库"]},{"title":"使用位运算存储用户状态","url":"/2020/03/19/2N47DH6.html","content":"\n\n\n使用位运算来存储用户状态、权限；便于后期扩展\n\n\n\n<!-- more -->\n\n\n\n### 背景\n\n很多项目中都会存储用户状态，诸如用户类型、相关操作权限等等。\n\n比较常用的方案有两种。\n\n- 使用一个int类型字段存储用户状态，不同的数字代表不同的状态\n- 比较特殊的状态需要另外使用字段存储\n\n\n方案一的问题在于无法存储复合状态。例如某个用户既是普通用户又处于封禁状态，想要使用方案一存储则数字会相当的多，不利于开发记忆。\n\n因此我使用**位运算**方案来存储状态\n\n\n### 思路\n\n位运算的思路为利用一个int(或者long)的不同位来存储不同状态。\n\n例如 状态数字 **10**，换算成二进制长这样：\n> 1010\n\n这样一看，一个数字 **10** 就有四个位，可以存储四个状态。\n\n这个状态就可以这样解释：\n> 最低位的0代表这是一个普通用户\n> 第二低的1代表用户未曾登录\n> 第二高的0代表用户可以使用手机号登录\n> 最高位的1代表用户要接收消息通知\n\n\n当然，每一位代表的意义在此并不重要。重要的是，每一个bit有两种状态：0和1，需要定义的是0代表enable还是1代表disable。这影响的是每一个bit的实际意义，也和接下来的方法定义有关。\n\n---\n\n同时，为了后续扩展，在进行状态定义的时候，最好要从低位往高位定义，高位未定义时必定为0。当用户需要增加新状态时，将新状态定义为1，那么原本的用户的状态数据可以不作修改。\n\n---\n\n存储效率：\n\n> 以int类型为例，int占4个字节，共有4x8=32位，意为可以同时存储**32**种不同的状态，在实际意义上则代表**2^32**种现实意义\n\n\n### 实现\n\n#### 定义\n\n首先，\n需要对要用到的位进行定义。\n> 在此使用枚举来进行定义；\n\n同时，\n需要标明状态被定位在哪一个bit上\n> 这一点很容易实现，使用**2**的幂指数即可；比如2=2^1，代表定位到从低往高数第二位的位置上\n\n\n因此枚举定义如下：\n\n```java\n\npublic enum UserStatus {\n\n    //以下均为代表不可用状态\n\n    USERNAME(1),//是否可以使用username字段登录\n    MOBILE(2),//是否可以使用手机号登录\n    SMSCODE(4),//是否可以通过短信验证码登录\n    SIGN(8),//是否可签署合同\n    SEND(16),//是否发送合同\n    INIT_PASSWORD(32),//是否是初始密码,0代表是初始密码，一个用户刚注册或导入的情况下都是初始密码（默认密码）\n    INIT_SIGN_PASSWORD(64),//是否是默认的签署密码，0代表是默认密码\n    DIY_VERIFY(128),//是否是修改过的的身份认证信息\n    RECEIVE_SMS(256),//接收短信通知\n    RECEIVE_EMAIL(512),//接收邮件通知\n    RECEIVE_WEB_NOTICE(1024),//接收站内通知\n    ;\n\n    int code;//需要指定的位数，应该都是2的幂指数，指定位上为1代表不允许\n    boolean userDiy;//是否允许普通用户自己修改指定状态\n\n    UserStatus(int code) {\n        this.code = code;\n    }\n\n    public int code() {\n        return code;\n    }\n\n\n}\n\n```\n\n---\n\n接下来需要对于状态的一些操作函数。我一共定义了三种：**is**、**enable**、**disable**；\n\n#### is函数\n\n首先是**is**函数：\n\n方法申明如下：\n```java\n\nboolean is(int code, BitInfo status);\n```\n\n\n其中：**code**代表存储了复合状态的状态数据，status代表某种定义的状态，我再次定义了一个BitInfo接口用于扩展，简单的理解成一个2的幂指数即可。\n\n那么is函数的意义为：在code中的status对应位上是否为**1**\n\n我使用的是 对应位 为 **1**，实际上0或者1不影响方法定义，只会对使用上有影响\n\n---\n接下来就是位运算的部分了\n\n可以把这个函数实现分成两部分：一、取出指定位的数据；二、判断数字\n\n\n还是拿 **10** 举例，在此我需要判断其从低往高数第二位是否为0\n那么code传递的应该是10，status代表的幂指数应该是2\n\n**10**化为二进制如下\n> 1010\n\n**2**化为二进制如下\n> 0010\n\n很明显可以看出，只需要将两个数字进行与(&)运算，即可以拿出指定位；准确的说是将无关位置为0，指定位不变。\n\n结果是：\n\n> 0010\n\n\n再与**2**做个比对即可。\n\n---\n\n因此方法实现如下：\n```java\nboolean is(int code, BitInfo status) {\n     //和指定位进行与运算后，对应的结果为0，即为允许，status.code 为1,代表不允许\n    return (code & status.code()) != status.code();\n}\n\n```\n#### disable\ndisable函数的意义是：将指定位置为1。\n\n要求：\n- 随便一个状态数字在disable之后进行is返回false\n- 对状态数字进行反复disable，结果都不能有变化(意思是不能简单的使用取反操作)\n\n方法申明如下\n```java\nint disable(int code, BitInfo status);\n```\n\n在此将**10**的最低位置为1\n\n相关参数为\n\n- code:10\n- status:1\n\n\n1的二进制如下\n\n> 0001\n\n\n很明显可以看出，只需要将两个数字进行 或(|)运算即可\n\n---\n实现如下\n\n```java\n\nint disable(int code, int status) {\n   //将指定位数置为1 即不允许\n   return code | status;\n }\n    \n```\n\n#### enable\n\nenable函数的意义是：将指定位置为0。\n\n要求：\n- 随便一个状态数字在enable之后进行is返回true\n- 对状态数字进行反复enable，结果都不能有变化(意思是不能简单的使用取反操作)\n\n方法申明如下\n```java\nint enable(int code, BitInfo status);\n```\n\n在此将**10**的最低位置为1\n\n相关参数为\n\n- code:10\n- status:1\n\n\n\n在disable函数中，已经将指定位置为1了，那么只需要把这个1再给变回来即可，且不能影响其他位\n\n因此只需要将10和2先后进行**或**运算和**异或**运算即可\n\n---\n方法实现如下：\n```java\nint enable(int code, BitInfo status) {\n\n    //将指定位数置为0 即允许\n    //将位和1 或，则指定位一定为1，再与status异或，指定位则为0\n\n    return (code | status.code()) ^ status.code();\n}\n```\n\n### 使用\n\n那么在使用上也很简单。\n\n例如我要判断 状态 **254** 是否可以接收短信，只需要这样调用\n\n```java\n\nBitInfo.is(254,UserStatus.RECEIVE_SMS)\n\n```\n\n返回true即代表可以接收短信\n\n### 总结\n\n使用位运算存储状态有以下优点：\n\n- 节约空间\n- 易于扩展\n- 可以同时存储复合状态\n\n但是缺点也很明显：\n\n- 不够直观，必须通过程序才能看出具体状态含义\n- 逻辑复杂，过于专注底层位运算可能会搞混，但是只关注抽象层就好得多\n\n---\n\n\n上述代码中还是有一定问题的。例如同时enable多个状态，调用上就比较复杂，会出现很多括号；这可以通过链式调用来解决，我在此就不作修改了。","tags":["java","后端","位运算"],"categories":["后端","java"]},{"title":"左右两栏各自滚动","url":"/2020/03/16/29NXD3S.html","content":"\n圣杯布局？\n\n<!-- more -->\n\n\n\n## 背景\n\n项目中需要在一个div中使用一个左右两栏布局，且左右各拥有纵向滚动条。\n\n\n首先，父div占页面的下部分80%左右高度，撑满全部视图且自适应。\n\n其次，在这个div里分左右布局，且不能出现全局滚动条\n\n\n## 实现\n\n### 方案一\n\n父div设置relative，两个子div absolute，且top、bottom、left、right全部为0\n\n### 方案二\n\n方案一的缺点在于js无法获取子div的坐标。因此方案如下\n\n父div保持方案一不变。子div设置如下\n\n```css\ndiv{\n    height:100px;\n    min-height:100%;\n    max-height:100%;\n    overflow-y:scroll;\n}\n\n```\n\n其中高度具体数字不重要。其中原理不明","tags":["前端","css"],"categories":["前端"]},{"title":"json反序列化问题","url":"/2020/03/12/2WMCQ45.html","content":"\n\n\n使用fastjson反序列化数据不全；没想到设计上居然不报错\n\n\n\n<!-- more -->\n\n\n\n## 背景\n\n fastjson 在反序列化一段json数据是总会丢失某个属性。\n\n ## json数据\n\n ```json\n {\n\t\"time\":1,\n\t\"contract\":{\n\t\t\"name\":\"1212\",\n\t\t\"notifyUrl\":\"http://localhost:20001\",\n\t\t\"userId\":\"1976220424287027200\"\n\t}\n\t\n}\n ```\n\n## java\n\n```java\npublic class NotifyMqMsg {\n\n    private Contract contract;\n\n    // 这是第几次通知，从0开始\n    private int time;\n\n    public NotifyMqMsg(Contract contract) {\n        this.contract = contract;\n    }\n\n    public Contract getContract() {\n        return contract;\n    }\n\n    public void setContract(Contract contract) {\n        this.contract = contract;\n    }\n\n    public int getTime() {\n        return time;\n    }\n\n    public void setTime(int time) {\n        this.time = time;\n    }\n\n    @Override\n    public String toString() {\n        return JSON.toJSONString(this);\n    }\n}\n```\n\n每次反序列化的时候 **time** 属性始终为0.\n\n## 解决\n\n问题原因是 `NotifyMqMsg` 构造方法有问题，没有默认构造方法。但是fastjson居然不报错，jackson就会报错。大概是采用的方案不同","tags":["java","后端","json","序列化"],"categories":["后端","java"]},{"title":"SpringCache的事务管理与单元测试","url":"/2020/03/08/1B59D5C.html","content":"\n\n\n在某个项目中，使用了SpringCache redis作为缓存解决方案，jpa作为orm\n\n在单元测试时，在执行某步操作时，需要往缓存中放入数据，之后启用断言判断对应的缓存是否存在，结果全部报缓存不存在\n\n\n\n<!-- more -->\n\n\n\n## 项目背景\n\n在某个项目中，使用了SpringCache redis作为缓存解决方案，jpa作为orm\n\n在单元测试时，在执行某步操作时，需要往缓存中放入数据，之后启用断言判断对应的缓存是否存在，结果全部报缓存不存在\n\n\n\n## 项目配置\n\n### springCache\n\n```java\n @Bean\n    public CacheManager cacheManager(RedisConnectionFactory factory, RedisSerializer serializer) {\n        log.info(\"[缓存配置] - 注入缓存管理器\");\n        return RedisCacheManager.builder(factory)\n                //默认缓存时间\n                .cacheDefaults(\n                        getRedisCacheConfigurationWithTtl(300)\n                                .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))\n                                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(serializer))\n                )\n\n                .transactionAware()//注意，这里是开启了redis 事务\n                //自定义缓存时间\n                .withInitialCacheConfigurations(getRedisCacheConfigurationMap())\n                .build();\n    }\n\n```\n\n### 单元测试\n\n```java \n@RunWith(SpringJUnit4ClassRunner.class)\n@Transactional //这里和下一行代表测试用例结束后自动回滚\n@Rollback\n@SpringBootTest\npublic abstract class BasicMockControllerTest {\n}\n```\n\n### 缓存调用\n\n```java\n\n   @CachePut(key = \"#result.id\")\n    @Override\n    public User update(User user) {\n        user = userRepository.save(user);\n        return user;\n    }\n```\n\n## 相关源码\n\n### springCache事务管理逻辑\n\n在`org.springframework.cache.transaction.AbstractTransactionSupportingCacheManager#decorateCache` 中\n\n```java\n    public boolean isTransactionAware() {\n\t\treturn this.transactionAware;\n\t}\n\n\t@Override\n\tprotected Cache decorateCache(Cache cache) {\n\t\treturn (isTransactionAware() ? new TransactionAwareCacheDecorator(cache) : cache);\n\t}\n\n```\n\n其中`this.transactionAware`来自 之前配置的 `transactionAware()`方法，对应值为true\n\n因此，这里会创建一个有事务管理的Cache实现\n\n---\n\n在`TransactionAwareCacheDecorator`中，核心方法 put 中，会根据配置了事务决定逻辑\n\n代码如下\n```java \n\t@Override\n\tpublic void put(final Object key, @Nullable final Object value) {\n\t\tif (TransactionSynchronizationManager.isSynchronizationActive()) {\n\t\t\tTransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {\n\t\t\t\t@Override\n\t\t\t\tpublic void afterCommit() {\n\t\t\t\t\tTransactionAwareCacheDecorator.this.targetCache.put(key, value);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse {\n\t\t\tthis.targetCache.put(key, value);\n\t\t}\n\t}\n```\n\n---\n\n### 事务何时提交\n\n根据测试，redis事务提交时机同jdbc事务；即jdbc事务结束，提交时，redis也一起提交，相反则一起回滚\n\n\n在Spring中，redis事务总是和jdbc事务相关联。\n\n而我在单元测试中，配置了事务回滚，因此在写缓存断言的时候，事务尚未结束，redis 还不能决定提交还是回滚，此时缓存中肯定没有数据。当测试用例结束后，事务自动回滚，redis也回滚，所以手动去redis查看时，也没有数据","tags":["java","后端","事务","cache"],"categories":["后端","java","SpringBoot"]},{"title":"SpringBoot配置文件优先级","url":"/2019/11/04/1CXKHHK.html","content":"\n记录SpringBoot的配置优先级\n\n\n\n<!-- more -->\n\n\n\n### 场景\n\n项目场景为：SpringBoot本身jar中附带有application.properties配置文件，现在需要将部分配置项放到jar外面\n\n### 实现方案 \n\n\n查阅资料得知SpringBoot加载配置文件顺序如下:\n- 当前目录下的/config目录\n- 当前目录\n- classpath里的/config目录\n- classpath 根目录\n\n\n因此，将jpa相关配置存放在jar中，将eureka配置外置\n\n实验发现：\n\n**server.port**配置项在两个地方都有时，优先使用外置\n\n\n\n\n\n\n\n### 参考资料\n\n[https://www.cnblogs.com/xiaoqi/p/6955288.html](https://www.cnblogs.com/xiaoqi/p/6955288.html)","tags":["java","后端","SpringBoot"],"categories":["后端","java","SpringBoot"]},{"title":"实现swagger2不显示类名","url":"/2019/11/01/2EEH37B.html","content":"\n对swagger2进行扩展，实现自定义需求\n\n\n\n<!-- more -->\n\n\n\n#### 使用场景\n\n在使用swagger2 2.9.2时\n\n在UI上接口旁边会显示类名，我需要把这个去掉\n![](https://i.loli.net/2019/11/01/ytJOdM9PQqFwoD7.png)\n\n---\n\n经debug之后，发现这个字段是通过`springfox.documentation.spring.web.scanners.ApiListingReader`显示的\n\n\n而这个类是被自动注入到`springfox.documentation.spring.web.plugins.DocumentationPluginsManager`中的\n\n因此，只需要自己实现一个`ApiListingReader`注入到spring容器就可以了\n\n---\n#### 效果图\n![](https://i.loli.net/2019/11/01/2Xc83BoGxCaKmys.png)","tags":["java","后端","文档","swagger"],"categories":["后端","java"]},{"title":"sm2签章","url":"/2019/10/19/9ED8ZM.html","content":"\n使用itext7 实现对pdf文件的**sm2**签章和验证\n\n\n\n<!-- more -->\n\n\n\n####　流程\n\n－首先获取签名dir，再往里面填一些自定义的数据，其中很重要的是签名的公钥\n- 使用sm3对数据进行hash，sm2做签名后填充到预先位置，在此需要特别注意生成的签名的大小\n- 验证时通过byteRange获取实际被签章的的内容，做hash运算\n- 获取签名值，与上述的hash和获取的公钥进行验证操作\n\n\n#### 签名\n\n核心结构`IExternalSignatureContainer`\n----\n其中`modifySigningDictionary`方法用于存储自定的数据，itext要求必须设置`PdfName#Filter`、`PdfName#SubFilter`,\n\n一般如下填充即可\n```java\n\npublic void modifySigningDictionary(PdfDictionary signDic) {\n\n   signDic.put(PdfName.Filter, PdfName.Adobe_PPKLite);\n\n   signDic.put(PdfName.SubFilter, PdfName.Adbe_pkcs7_detached);\n}\n```\n\n其他自定义数据也可以放进去\n\n----\n`sign` 方法实际签章，参数是要签名的数据；返回签名字节，在这里面进行hash，签名操作\n\n#### 验证\n\n**获取要签名的内容**\n\n具体内容在PdfName.ByteRange中，该数据格式为[0 330387 346781 229585 ],\n实际保密的内容是0-330387和346781-229585，中间的部分为签名数据，可以不用理会。\n\n特别注意长度，如果签名不够是会进行**补0**的，所以长度可能会超过实际签名出来的长度\n\n----\n**获取签名**\n签名内容在PdfName.Content中，直接获取即可\n\n```java\nPdfReader pdfReader = new PdfReader(new ByteArrayInputStream(FileUtils.read(\"new.pdf\")));\nPdfDocument pdfDocument = new PdfDocument(pdfReader);\nSignatureUtil signatureUtil = new SignatureUtil(pdfDocument);\nList<String> signedNames = signatureUtil.getSignatureNames();\nbyte[] pdfData = IOUtils.toByteArray(new FileInputStream(\"\"));\nPdfDictionary signatureDictionary = signatureUtil.getSignatureDictionary(signedNames.get(0));\nbyte[] content = signatureDictionary.getAsString(PdfName.Contents).getValueBytes();\n```","tags":["java","加密","pdf","签名","sm2"],"categories":["后端","java"]},{"title":"aop切面类","url":"/2019/10/17/2SFDH34.html","content":"\n\n\n记录一下较为常用的aop切面\n\n\n\n<!-- more -->\n\n\n\n- org.aopalliance.intercept.MethodInterceptor 环绕切面\n\n### 通配符\n\n.. ：匹配方法定义中的任意数量的参数，此外还匹配类定义中的任意数量包\n\n＋ ：匹配给定类的任意子类\n\n＊ ：匹配任意数量的字符\n\n为了方便类型（如接口、类名、包名）过滤方法，Spring AOP 提供了within关键字。其语法格式如下：\n\nwithin(<type name>)\n\n//匹配com.zejian.dao包及其子包中所有类中的所有方法\n@Pointcut(\"within(com.zejian.dao..*)\")\n\n//匹配UserDaoImpl类中所有方法\n@Pointcut(\"within(com.zejian.dao.UserDaoImpl)\")\n\n//匹配UserDaoImpl类及其子类中所有方法\n@Pointcut(\"within(com.zejian.dao.UserDaoImpl+)\")\n\n//匹配所有实现UserDao接口的类的所有方法\n@Pointcut(\"within(com.zejian.dao.UserDao+)\")","tags":["java","后端"],"categories":["后端","java"]},{"title":"SpringBoot实现分布式session","url":"/2019/10/12/3HEJMC.html","content":"\n\n\n基于SpringBoot对session存储方案进行扩展，适用于分布式环境\n\n\n\n<!-- more -->\n\n\n\n## 实现分布式session\n\n> 实现基于redis的分布式session\n\n---\n\n\n### 原理\n\n基于HttpRequestWapper，对request获取的Session实现类进行替换，即提供一个从redis获取数据的Session实现类\n\n### 依赖\n\n引入**spring-boot-starter-data-redis**、**spring-session-data-redis**；\n引入`kryo`作为序列化方案\n\n```xml\n    <dependency>\n        <groupId>org.springframework.session</groupId>\n        <artifactId>spring-session-data-redis</artifactId>\n    </dependency>\n\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-data-redis</artifactId>\n    </dependency>\n\n     <dependency>\n        <groupId>com.esotericsoftware</groupId>\n        <artifactId>kryo</artifactId>\n        <version>4.0.0</version>\n    </dependency>\n\n    <dependency>\n        <groupId>de.javakaffee</groupId>\n        <artifactId>kryo-serializers</artifactId>\n        <version>0.41</version>\n    </dependency>\n\n```\n\n### 修改配置\n\n```properties\n\nspring.redis.host=127.0.0.1\nspring.redis.database=2\n\n```\n\nps: 如果有需要还可以修改对应的连接池配置，或者更换默认的`lettuce`框架\n\n\n### 编写序列化类\n\n该类用于数据的序列化和反序列化，本样例基于`kryo`实现，该框架具有体积小、速度快等优势。\n\n此步骤可以省略，不提供具体实现Spring默认使用Jdk序列化方案\n\n----\n\n序列化需要实现`org.springframework.data.redis.serializer.RedisSerializer`类\n\n该类可以用于不同的存储方案\n\ndemo如下\n\n```java\n\npublic class KryoRedisSerializer<T> implements RedisSerializer<T> {\n    private static final Logger logger = LoggerFactory.getLogger(KryoRedisSerializer.class);\n\n    public static final byte[] EMPTY_BYTE_ARRAY = new byte[0];\n\n    private static final ThreadLocal<Kryo> kryos = ThreadLocal.withInitial(Kryo::new);\n\n    private Class<T> clazz;\n\n    public KryoRedisSerializer(Class<T> clazz) {\n        super();\n        this.clazz = clazz;\n    }\n\n    @Override\n    public byte[] serialize(T t) throws SerializationException {\n        if (t == null) {\n            return EMPTY_BYTE_ARRAY;\n        }\n\n        logger.debug(\"序列化{}，{}\", t.getClass(), t);\n\n        Kryo kryo = kryos.get();\n        kryo.setRegistrationRequired(false);//关闭注册行为，避免相同类无法强转\n        kryo.setReferences(false);\n//        kryo.register(clazz);\n\n        try (ByteArrayOutputStream baos = new ByteArrayOutputStream();\n             Output output = new Output(baos)) {\n            kryo.writeClassAndObject(output, t);\n            output.flush();\n            return baos.toByteArray();\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        }\n\n        return EMPTY_BYTE_ARRAY;\n    }\n\n    @Override\n    public T deserialize(byte[] bytes) throws SerializationException {\n        if (bytes == null || bytes.length <= 0) {\n            return null;\n        }\n\n        Kryo kryo = kryos.get();\n        kryo.setReferences(false);\n        kryo.setRegistrationRequired(false);\n//        kryo.register(clazz);\n\n        logger.debug(\"反序列化\");\n        try (Input input = new Input(bytes)) {\n            return (T) kryo.readClassAndObject(input);\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        }\n\n        return null;\n    }\n}\n\n```\n\n**ps: 需要注意的是，虽然该类提供了一个泛型对象，但是实际运用中并没有什么用；在反序列化时并不能知道应该返回一个什么类型的对象；因此多数序列化框架都是采取的在序列化结果中存储该对象的实际类型；**\n\n再ps：由于`kryo`序列化后为二进制，因此对于List、Map等可能带有泛型，且存储对象并非同一个子类的情况还需要进行测试\n\n### 注入Spring容器\n\nSpring Session通过` org.springframework.session.data.redis.RedisOperationsSessionRepository ` 实现Session的替换，以及数据的序列化\n\n仔细查看该类可知，该类有两个较为重要的属性\n\n- `RedisSerializer<Object> defaultSerializer`\n- `RedisOperations<Object, Object> sessionRedisOperations`\n\n---\ndefaultSerializer初始化为`JdkSerializationRedisSerializer`\n\n用于`onMessage`方法，该方法可能为Redis值过期事件响应，负责对传递过来的数据做session删除和过期操作\n\n不太明白为什么不从`sessionRedisOperations`中获取序列化实例，这点有待研究\n\n---\n\nsessionRedisOperations在构造方法中传入\n\n由于Spring Bean注入顺序的原因，该值为Spring redis starter自动创建的`RedisTemplate`实例，该实例中使用了Jdk序列化方案，需要修改，但是暂时没找到办法注入自己创建的实例\n\n故采取折中方案，即获取`RedisOperationsSessionRepository`实例，手动修改里面的`RedisTemplate`里的·`RedisSerializer`\n\n---\n\n最终配置类如下\n\n```java\n@Configuration\n@EnableRedisHttpSession\npublic class RedisSessionConfig {\n\n    @Bean\n    public RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory, RedisOperationsSessionRepository repository) {\n        RedisTemplate<Object, Object> template = new RedisTemplate<>();\n        template.setConnectionFactory(redisConnectionFactory);\n\n        RedisSerializer<Object> serializer = new KryoRedisSerializer<>(Object.class);\n        // redis value使用的序列化器\n        template.setValueSerializer(serializer);\n        // redis key使用的序列化器\n        template.setKeySerializer(new StringRedisSerializer());\n\n        repository.setDefaultSerializer(serializer);\n        //由于RedisOperationsSessionRepository 要先构造，且不提供方法修改属性，只能采取这种这种的方法\n        RedisOperations<Object, Object> sessionRedisOperations = repository.getSessionRedisOperations();\n        if (sessionRedisOperations instanceof  RedisTemplate){\n            RedisTemplate<Object,Object> redisTemplate = ((RedisTemplate<Object, Object>) sessionRedisOperations);\n            redisTemplate.setValueSerializer(serializer);\n            redisTemplate.setHashValueSerializer(serializer);\n        }\n\n        template.afterPropertiesSet();\n        return template;\n    }\n}\n```\n\n\nps： 更多配置信息亦可通过`RedisOperationsSessionRepository`修改，如session有效实现，cookie name值等等\n\n\n\n### todo\n\n- 寻找更合适的注入`Serializer`方式\n\n\n### 代码\n\n具体实现可查阅[github](https://github.com/inkroom/SpringBoot-study/commit/5dafbfe8e24ecb9df001b9ae3554a5c5d216d477)","tags":["java","后端","分布式","SpringBoot"],"categories":["后端","java","SpringBoot"]},{"title":"mybatis-plus缓存配置","url":"/2019/10/12/29N9S98.html","content":"\n\n\n关闭mybatis的缓存\n\n\n\n<!-- more -->\n\n\n\n### 场景\n\n在单元测试中使用mybatis-plus查询一条数据\n\n再用jdbcTemplate修改数据\n\n再用mybatis-plus查询数据，发现数据未修改\n\n\n### 原因\n\n这是由于mybatis的一级缓存在起作用。前后两次查询之间没有使用mybatis的修改数据，缓存未被清除\n\n### 解决办法\n\n- 使用mybatis做修改操作\n- 配置mybatis-plus.configuration.local-cache-scope=statement\n    \n    > mybatis-plus.configuration.cache-enabled=false无效\n\n### 局限性\n\n- mybatis和其他orm搭配使用可能会出问题\n- 分布式条件下，如果一条修改sql被一台机器执行，而另一台机器全部执行查找，会出现不一致问题","tags":["java","后端","mybatis"],"categories":["后端","java"]}]